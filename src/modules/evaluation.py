# src/modules/evaluation.py

import os
import json
from typing import Final, Dict, Any, List, Optional # Optional ì¶”ê°€

# ì¨ë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬
from datasets import Dataset
from ragas import evaluate
from ragas.llms import LangchainLLMWrapper
from ragas.metrics import faithfulness, answer_relevancy

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
from src.modules.llm import get_solar_llm # <-- í´ë˜ìŠ¤ ëŒ€ì‹  í•¨ìˆ˜ë¥¼ ì„í¬íŠ¸ (ìˆ˜ì •)
from src.utils.utils import ensure_directory # <-- í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥ì„ ìœ„í•´ ì¶”ê°€

# --- ì„¤ì • ë° ì´ˆê¸°í™” (PEP 8: ëª¨ë“ˆ ìˆ˜ì¤€ ìƒìˆ˜ëŠ” ëŒ€ë¬¸ìë¡œ) ---
TEST_SET_PATH: Final[str] = os.path.join("data", "tests", "test_questions.json")
EVALUATION_OUTPUT_PATH: Final[str] = "evaluation_results.csv" # <-- CSV íŒŒì¼ ê²½ë¡œ ìƒìˆ˜í™”

# 1. Ragas í‰ê°€ìš© LLM ì„¤ì •: Solar API ì‚¬ìš© í™•ì •
# RagasëŠ” í‰ê°€ë¥¼ ìœ„í•´ LLMì´ í•„ìš”í•´. Solar LLM ì¸ìŠ¤í„´ìŠ¤ë¥¼ Ragas Wrapperë¡œ ê°ì‹¼ë‹¤.
EVALUATOR_LLM: Optional[LangchainLLMWrapper] = None
try:
    # í‰ê°€ì˜ ì¼ê´€ì„±ì„ ìœ„í•´ ì˜¨ë„ë¥¼ 0.0ìœ¼ë¡œ ì„¤ì • (ìˆ˜ì •)
    solar_llm = get_solar_llm(temperature=0.0) 
    EVALUATOR_LLM = LangchainLLMWrapper(solar_llm)
    print("í‰ê°€ìš© LLM (Solar) ì—°ê²° ì™„ë£Œ.")
except Exception as e:
    print(f"ê²½ê³ : í‰ê°€ìš© LLM ì´ˆê¸°í™” ì˜¤ë¥˜. í™˜ê²½ ë³€ìˆ˜ í™•ì¸ í•„ìš”: {e}")

# í‰ê°€ ì§€í‘œ ì •ì˜
METRICS_TO_EVALUATE: Final[List[Any]] = [
    faithfulness,
    answer_relevancy,
    # context_recall, # Context Recallì€ 'ground_truth' í•„ë“œê°€ í•„ìš”í•´ì„œ ì¼ë‹¨ ì œì™¸
]
# --------------------


def load_test_set(file_path: str) -> List[Dict[str, Any]]:
    """JSON íŒŒì¼ì—ì„œ í…ŒìŠ¤íŠ¸ ì…‹ ë°ì´í„°ë¥¼ ë¡œë“œí•œë‹¤."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"ì˜¤ë¥˜: í…ŒìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return []


def prepare_ragas_dataset(raw_data: List[Dict[str, Any]], rag_outputs: List[Dict[str, Any]]) -> Dataset:
    """
    Ragas í‰ê°€ì— í•„ìš”í•œ í˜•ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë³€í™˜í•œë‹¤.
    
    Args:
        raw_data: load_test_setì—ì„œ ë¡œë“œí•œ ì›ë˜ í…ŒìŠ¤íŠ¸ ì…‹ (ì§ˆë¬¸, ì •ë‹µ)
        rag_outputs: RAG íŒŒì´í”„ë¼ì¸(API)ì„ ì‹¤í–‰í•´ì„œ ì–»ì€ ê²°ê³¼ (ë‹µë³€, contexts)
    """
    
    # ë°ì´í„° ê°œìˆ˜ê°€ ë§ëŠ”ì§€ í™•ì¸
    if len(raw_data) != len(rag_outputs):
        raise ValueError(
            f"í…ŒìŠ¤íŠ¸ ë°ì´í„°({len(raw_data)}ê°œ)ì™€ RAG ì¶œë ¥ ë°ì´í„°({len(rag_outputs)}ê°œ)ì˜ ê°œìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
        )

    # Ragas Dataset êµ¬ì¡°ì— ë§ê²Œ ë°ì´í„° ì¤€ë¹„
    data_dict: Dict[str, List] = {
        'question': [],
        'answer': [],  # RAG ì±—ë´‡ì´ ìƒì„±í•œ ë‹µë³€
        'contexts': [], # RAG ì±—ë´‡ì´ ë‹µë³€ ì‹œ ê²€ìƒ‰í•œ ë¬¸ì„œ ì¡°ê° (ì²­í¬)
        'ground_truth': [], # ìš°ë¦¬ê°€ ì •ì˜í•œ ëª¨ë²” ì •ë‹µ (ì •í™•ë„ í‰ê°€ìš©)
    }

    # raw_dataì™€ rag_outputsë¥¼ ë§¤í•‘í•˜ì—¬ Ragasì— í•„ìš”í•œ í‚¤ë¥¼ ì±„ìš´ë‹¤.
    for raw_item, output_item in zip(raw_data, rag_outputs):
        data_dict['question'].append(raw_item['question'])
        data_dict['answer'].append(output_item['answer'])
        data_dict['contexts'].append(output_item['contexts'])
        data_dict['ground_truth'].append(raw_item['expected_answer'])

    return Dataset.from_dict(data_dict)


def run_evaluation(ragas_dataset: Dataset):
    """Ragasë¥¼ ì‚¬ìš©í•˜ì—¬ RAG íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³  ê²°ê³¼ë¥¼ ì¶œë ¥í•œë‹¤."""
    if EVALUATOR_LLM is None:
        print("í‰ê°€ìš© LLMì´ ì„¤ì •ë˜ì§€ ì•Šì•„ í‰ê°€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    print("--- RAG ì„±ëŠ¥ í‰ê°€ ì‹œì‘ (Solar API ì‚¬ìš©) ---")
    
    score = evaluate(
        dataset=ragas_dataset,
        metrics=METRICS_TO_EVALUATE,
        llm=EVALUATOR_LLM  # Solar LLM ë˜í¼ ì—°ê²°
    )
    
    print("\n--- RAG ìµœì¢… í‰ê°€ ê²°ê³¼ ---")
    results_df = score.to_pandas()
    print(results_df)
    
    # ìµœì¢… ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥
    # ensure_directory í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ data í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ í›„ ì €ì¥
    ensure_directory("data")
    results_df.to_csv(os.path.join("data", EVALUATION_OUTPUT_PATH), index=False)
    print(f"\ndata/{EVALUATION_OUTPUT_PATH} íŒŒì¼ì— ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    # ì´ ë¶€ë¶„ì€ íŒ€ì¥ì´ API ë°°í¬ í›„ì— ì‹¤í–‰í•´ì•¼ í•˜ëŠ” ì‹œë®¬ë ˆì´ì…˜
    
    # 1. í…ŒìŠ¤íŠ¸ ì…‹ ë¡œë“œ
    raw_test_data = load_test_set(TEST_SET_PATH)
    
    if not raw_test_data:
        print("\ní…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ì–´ í‰ê°€ë¥¼ ì§„í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    else:
        print(f"ë¡œë“œëœ ì§ˆë¬¸ ê°œìˆ˜: {len(raw_test_data)}")
        
        # 2. ğŸš¨ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œë®¬ë ˆì´ì…˜ ğŸš¨
        # ì´ 'dummy_rag_outputs'ëŠ” íŒ€ì¥ì˜ API(POST /ask)ê°€ ì‹¤ì œë¡œ ì¶œë ¥í•´ì•¼ í•  í˜•ì‹
        # ì‹¤ì œ API í˜¸ì¶œ ê²°ê³¼ (ë‹µë³€, ê²€ìƒ‰ëœ context ì¡°ê°, ì¶œì²˜ URL ë“±)ë¥¼ ì €ì¥
        dummy_rag_outputs: List[Dict[str, Any]] = [
            # ë”ë¯¸ ë°ì´í„°ëŠ” raw_test_data ê°œìˆ˜ì™€ ë§ì¶°ì•¼ í•¨ (10ê°œ)
            {"answer": "LCELì€ LangChain êµ¬ì„± ìš”ì†Œë¥¼ íŒŒì´í”„ë¼ì¸ì²˜ëŸ¼ ì—°ê²°í•˜ëŠ” ë°©ì‹ì´ë©°, ì´ë¥¼ í†µí•´ ëª¨ë“ˆì„±ê³¼ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.", "contexts": ["LCELì€ ì²´ì¸ì„ ì‰½ê²Œ ë§Œë“¤ ìˆ˜ ìˆê²Œ í•˜ëŠ” ê¸°ë³¸ êµ¬ì„± ìš”ì†Œì…ë‹ˆë‹¤.", "LCELì€ ì§€ì—° ì‹¤í–‰ ë° ìŠ¤íŠ¸ë¦¬ë° ê°™ì€ ê³ ê¸‰ ê¸°ëŠ¥ì„ ì§€ì›í•©ë‹ˆë‹¤."], "source_urls": ["url1"]},
            {"answer": "ChromaDBì— ë¬¸ì„œë¥¼ ì €ì¥í•˜ë ¤ë©´ ë¨¼ì € ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ê³ , ì„ë² ë”© ëª¨ë¸ì„ ì •ì˜í•œ í›„, Chroma.from_documentsë¥¼ í˜¸ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.", "contexts": ["Chroma.from_documentsëŠ” ì„ë² ë”© í•¨ìˆ˜ì™€ ì²­í¬ëœ ë¬¸ì„œë¥¼ ë°›ì•„ ì»¬ë ‰ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤."], "source_urls": ["url2"]},
            {"answer": "ReAct í”„ë¡¬í”„íŠ¸ëŠ” Agentê°€ ì¶”ë¡ (Thought)í•˜ê³  í–‰ë™(Action)ì„ ê²°ì •í•˜ëŠ” êµ¬ì¡°ë¥¼ ê°€ì§€ë©°, ì´ëŠ” ë³µì¡í•œ ì‘ì—… ìˆ˜í–‰ì— í•„ìˆ˜ì ì…ë‹ˆë‹¤.", "contexts": ["ReAct í”„ë¡¬í”„íŠ¸ëŠ” (Thought, Action, Action Input) íŠœí”Œì„ ë°˜ë³µí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤."], "source_urls": ["url3"]},
            {"answer": "ì½”ë“œ ë¸”ë¡ ë³´ì¡´ì„ ìœ„í•´ì„œëŠ” RecursiveCharacterTextSplitterë¥¼ ì‚¬ìš©í•˜ì—¬ ì²­í¬ í¬ê¸°(chunk_size)ë¥¼ ì¶©ë¶„íˆ í¬ê²Œ ì„¤ì •í•˜ê³ , ì²­í¬ ì˜¤ë²„ë©(chunk_overlap)ì„ ë‘ì–´ ì½”ë“œ ë¬¸ë§¥ì„ ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤.", "contexts": ["HTML ë¬¸ì„œ ë¡œë“œ ì‹œ ì½”ë“œ ë¸”ë¡ì´ ê¹¨ì§€ì§€ ì•Šê²Œ ì²­í‚¹ì„ ì¡°ì •í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤."], "source_urls": ["url4"]},
            {"answer": "WebBaseLoaderë¡œ ë¬¸ì„œë¥¼ ë¡œë“œí•œ í›„, RecursiveCharacterTextSplitterë¥¼ ìƒì„±í•˜ì—¬ split_documents ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ë©´ ë©ë‹ˆë‹¤. ì˜ˆì‹œ ì½”ë“œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤...", "contexts": ["WebBaseLoaderëŠ” URLì„ ë°›ì•„ HTML ë‚´ìš©ì„ Document ê°ì²´ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.", "RecursiveCharacterTextSplitterëŠ” ì§€ì •ëœ êµ¬ë¶„ìë¡œ ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤."], "source_urls": ["url5"]},
            {"answer": "ì½œë°± ì‹œìŠ¤í…œì€ ì²´ì¸, LLM, Retriever í˜¸ì¶œ ì „í›„ì— ì‹¤í–‰ë˜ëŠ” í›„í¬ë¥¼ ì œê³µí•˜ì—¬, ë¡œê¹…, ëª¨ë‹ˆí„°ë§, ë””ë²„ê¹… ë° ìŠ¤íŠ¸ë¦¬ë° ê¸°ëŠ¥ì„ êµ¬í˜„í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.", "contexts": ["LangChainì€ ë‹¤ì–‘í•œ ì´ë²¤íŠ¸ í›„í¬ë¥¼ ì§€ì›í•˜ëŠ” ì¤‘ì•™ ì§‘ì¤‘ì‹ ì½œë°± ì‹œìŠ¤í…œì„ ì œê³µí•©ë‹ˆë‹¤."], "source_urls": ["url6"]},
            {"answer": "ê²€ìƒ‰ ìœ í˜•ì„ 'mmr'(Maximal Marginal Relevance)ë¡œ ì„¤ì •í•˜ë©´ ê²€ìƒ‰ ê²°ê³¼ì˜ ê´€ë ¨ì„±ê³¼ ë‹¤ì–‘ì„±ì„ ë™ì‹œì— ìµœëŒ€í™”í•˜ì—¬, ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì´ ì„œë¡œ ë‹¤ë¥¸ ì •ë³´ë¥¼ í¬í•¨í•˜ë„ë¡ í•©ë‹ˆë‹¤.", "contexts": ["MMRì€ ìœ ì‚¬ë„ ì ìˆ˜ì™€ ë²¡í„° ê³µê°„ì—ì„œì˜ ê±°ë¦¬ë¥¼ ëª¨ë‘ ê³ ë ¤í•©ë‹ˆë‹¤."], "source_urls": ["url7"]},
            {"answer": "PydanticOutputParserëŠ” LLMì˜ ììœ  í˜•ì‹ í…ìŠ¤íŠ¸ ì¶œë ¥ì„ êµ¬ì¡°í™”ëœ Pydantic ëª¨ë¸ ê°ì²´ë¡œ íŒŒì‹±í•˜ì—¬, ì¶œë ¥ì„ ì•ˆì •ì ìœ¼ë¡œ ë‹¤ë£° ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. ì „ì²´ ì˜ˆì œ ì½”ë“œëŠ” ë¬¸ì„œì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.", "contexts": ["PydanticOutputParserëŠ” JSON ìŠ¤í‚¤ë§ˆë¥¼ í”„ë¡¬í”„íŠ¸ì— ì‚½ì…í•˜ì—¬ LLMì´ êµ¬ì¡°í™”ëœ ì‘ë‹µì„ ìƒì„±í•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤."], "source_urls": ["url8"]},
            {"answer": "ConversationBufferMemoryëŠ” ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ëŠ” ë©”ëª¨ë¦¬ ëª¨ë“ˆì´ë©°, RunnableWithMessageHistoryë¥¼ ì‚¬ìš©í•˜ì—¬ RAG ì²´ì¸ì— ì—°ê²°í•˜ì—¬ ì„¸ì…˜ë³„ ëŒ€í™” ê¸°ë¡ì„ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.", "contexts": ["ë©”ëª¨ë¦¬ëŠ” ì£¼ë¡œ ì±„íŒ… ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ëŒ€í™”ì˜ ì—°ì†ì„±ì„ ìœ ì§€í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤."], "source_urls": ["url9"]},
            {"answer": "RunnablePassthroughëŠ” ì…ë ¥ ê°’ì„ ë‹¤ìŒ ë‹¨ê³„ë¡œ ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ëŠ” ì—­í• ì„ í•˜ë©°, ì´ë¥¼ ì‚¬ìš©í•´ Retrieverì˜ ê²°ê³¼ë¥¼ Context í‚¤ì— í• ë‹¹í•˜ê³  Questionì„ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì—¬ LLMì— ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.", "contexts": ["RunnablePassthrough.assignì€ ê¸°ì¡´ ì…ë ¥ì— ìƒˆë¡œìš´ í‚¤ë¥¼ ì¶”ê°€í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤."], "source_urls": ["url10"]},
        ]
        
        # 3. Ragas Dataset ì¤€ë¹„
        ragas_dataset = prepare_ragas_dataset(raw_test_data, dummy_rag_outputs)
        
        # 4. í‰ê°€ ì‹¤í–‰
        run_evaluation(ragas_dataset)
        
    print("\n**ë‚¨ì€ ì‘ì—… (ìƒê¸°ì‹œí‚¤ê¸°):**")
    print("1. íŒ€ì¥(ë„ˆ)ì´ API ë°°í¬ í›„, 10ê°œ ì§ˆë¬¸ì„ APIì— ë˜ì ¸ 'answer'ì™€ 'contexts'ë¥¼ ë°›ì•„ì™€ì•¼ ì´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìµœì¢… ì‹¤í–‰í•  ìˆ˜ ìˆìŒ")
    print("2. `src/modules/llm.py`ì—ì„œ `get_solar_llm`ì˜ `temperature`ê°€ í‰ê°€ìš©ìœ¼ë¡œ 0.0ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŒ.")