import os
import json
from typing import Final, Dict, Any, List

# RAGAS í‰ê°€ ë„êµ¬ ì„í¬íŠ¸
from ragas import evaluate
from datasets import Dataset
from ragas.metrics import faithfulness, answer_relevancy
from ragas.llms import LangchainLLMWrapper

# íŒ€ì› 2ê°€ êµ¬í˜„í•  Solar LLM ëª¨ë“ˆ ì„í¬íŠ¸ (ê°€ì •)
# íŒ€ì› 2ì—ê²Œ src/modules/llm.pyì— SolarChatModelì„ êµ¬í˜„í•´ë‹¬ë¼ê³  ìš”ì²­
from src.modules.llm import SolarChatModel 
# from dotenv import load_dotenv # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œëŠ” íŒ€ì› 5 ë‹´ë‹¹

# --- ì„¤ì • ë° ì´ˆê¸°í™” ---
TEST_SET_PATH: Final[str] = os.path.join("data", "tests", "test_questions.json")

# 1. Ragas í‰ê°€ìš© LLM ì„¤ì •: Solar API ì‚¬ìš© í™•ì •
# RagasëŠ” í‰ê°€ë¥¼ ìœ„í•´ LLMì´ í•„ìš”í•´. SolarChatModel ì¸ìŠ¤í„´ìŠ¤ë¥¼ Ragas Wrapperë¡œ ê°ì‹¼ë‹¤.
try:
    # SolarChatModel ì´ˆê¸°í™” ì‹œ í™˜ê²½ ë³€ìˆ˜(SOLAR_API_KEY)ë¥¼ ì‚¬ìš©í•œë‹¤ê³  ê°€ì •
    solar_llm = SolarChatModel() 
    EVALUATOR_LLM = LangchainLLMWrapper(solar_llm)
except Exception as e:
    print(f"ê²½ê³ : SolarChatModel ì´ˆê¸°í™” ì˜¤ë¥˜. í™˜ê²½ ë³€ìˆ˜ í™•ì¸ í•„ìš”: {e}")
    EVALUATOR_LLM = None

# í‰ê°€ ì§€í‘œ ì •ì˜
METRICS_TO_EVALUATE = [
    faithfulness,
    answer_relevancy,
    # context_recall, # Context Recallì€ 'ground_truth' í•„ë“œê°€ í•„ìš”í•´ì„œ ì¼ë‹¨ ì œì™¸
]
# --------------------


def load_test_set(file_path: str) -> List[Dict[str, Any]]:
    """JSON íŒŒì¼ì—ì„œ í…ŒìŠ¤íŠ¸ ì…‹ ë°ì´í„°ë¥¼ ë¡œë“œí•œë‹¤."""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def prepare_ragas_dataset(raw_data: List[Dict[str, Any]], rag_outputs: List[Dict[str, Any]]) -> Dataset:
    """
    Ragas í‰ê°€ì— í•„ìš”í•œ í˜•ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë³€í™˜í•œë‹¤.
    
    Args:
        raw_data: load_test_setì—ì„œ ë¡œë“œí•œ ì›ë˜ í…ŒìŠ¤íŠ¸ ì…‹ (ì§ˆë¬¸, ì •ë‹µ)
        rag_outputs: RAG íŒŒì´í”„ë¼ì¸(API)ì„ ì‹¤í–‰í•´ì„œ ì–»ì€ ê²°ê³¼ (ë‹µë³€, contexts, source_urls)
    """
    
    # Ragas Dataset êµ¬ì¡°ì— ë§ê²Œ ë°ì´í„° ì¤€ë¹„
    data_dict: Dict[str, List] = {
        'question': [],
        'answer': [],  # RAG ì±—ë´‡ì´ ìƒì„±í•œ ë‹µë³€
        'contexts': [], # RAG ì±—ë´‡ì´ ë‹µë³€ ì‹œ ê²€ìƒ‰í•œ ë¬¸ì„œ ì¡°ê° (ì²­í¬)
        'ground_truth': [], # ìš°ë¦¬ê°€ ì •ì˜í•œ ëª¨ë²” ì •ë‹µ (ì •í™•ë„ í‰ê°€ìš©)
    }

    # raw_dataì™€ rag_outputsë¥¼ ë§¤í•‘í•˜ì—¬ Ragasì— í•„ìš”í•œ í‚¤ë¥¼ ì±„ìš´ë‹¤.
    for raw_item, output_item in zip(raw_data, rag_outputs):
        data_dict['question'].append(raw_item['question'])
        data_dict['answer'].append(output_item['answer'])
        data_dict['contexts'].append(output_item['contexts'])
        data_dict['ground_truth'].append(raw_item['expected_answer'])

    return Dataset.from_dict(data_dict)


def run_evaluation(ragas_dataset: Dataset):
    """Ragasë¥¼ ì‚¬ìš©í•˜ì—¬ RAG íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³  ê²°ê³¼ë¥¼ ì¶œë ¥í•œë‹¤."""
    if EVALUATOR_LLM is None:
        print("í‰ê°€ìš© LLMì´ ì„¤ì •ë˜ì§€ ì•Šì•„ í‰ê°€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    print("--- RAG ì„±ëŠ¥ í‰ê°€ ì‹œì‘ (Solar API ì‚¬ìš©) ---")
    
    score = evaluate(
        dataset=ragas_dataset,
        metrics=METRICS_TO_EVALUATE,
        llm=EVALUATOR_LLM  # Solar LLM ë˜í¼ ì—°ê²°
    )
    
    print("\n--- RAG ìµœì¢… í‰ê°€ ê²°ê³¼ ---")
    results_df = score.to_pandas()
    print(results_df)
    
    # ìµœì¢… ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥
    results_df.to_csv('evaluation_results.csv', index=False)
    print("\nevaluation_results.csv íŒŒì¼ì— ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    # ì´ ë¶€ë¶„ì€ íŒ€ì¥ì´ API ë°°í¬ í›„ì— ì‹¤í–‰í•´ì•¼ í•˜ëŠ” ì‹œë®¬ë ˆì´ì…˜
    
    # 1. í…ŒìŠ¤íŠ¸ ì…‹ ë¡œë“œ
    raw_test_data = load_test_set(TEST_SET_PATH)
    
    print(f"ë¡œë“œëœ ì§ˆë¬¸ ê°œìˆ˜: {len(raw_test_data)}")
    
    # 2. ğŸš¨ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œë®¬ë ˆì´ì…˜ ğŸš¨
    # ì´ 'dummy_rag_outputs'ëŠ” íŒ€ì¥ì˜ API(POST /ask)ê°€ ì‹¤ì œë¡œ ì¶œë ¥í•´ì•¼ í•  í˜•ì‹
    # íŒ€ì¥(ë„ˆ)ì€ API ì™„ì„± í›„, ì´ 10ê°œ ì§ˆë¬¸ì„ APIì— ë˜ì ¸ì„œ ì‹¤ì œ ê²°ê³¼ë¥¼ ì—¬ê¸°ì— ì±„ì›Œ ë„£ì–´ì•¼ í•¨
    
    dummy_rag_outputs: List[Dict[str, Any]] = [
        # ì‹¤ì œ API í˜¸ì¶œ ê²°ê³¼ (ë‹µë³€, ê²€ìƒ‰ëœ context ì¡°ê°, ì¶œì²˜ URL ë“±)ë¥¼ ì €ì¥
        # contextsëŠ” ê²€ìƒ‰ëœ ë¬¸ì„œì˜ 'í…ìŠ¤íŠ¸' ë‚´ìš© ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•¨
        {"answer": "...", "contexts": ["... ê²€ìƒ‰ëœ ì²­í¬ ë‚´ìš© 1 ...", "... ê²€ìƒ‰ëœ ì²­í¬ ë‚´ìš© 2 ..."], "source_urls": ["url1", "url2"]},
        # ... 9ê°œ í•­ëª© ë” ...
    ]
    
    # 3. Ragas Dataset ì¤€ë¹„
    # ragas_dataset = prepare_ragas_dataset(raw_test_data, dummy_rag_outputs)
    
    # 4. í‰ê°€ ì‹¤í–‰
    # run_evaluation(ragas_dataset)
    
    print("\n**ë‚¨ì€ ì‘ì—…:**")
    print("1. íŒ€ì› 2ì—ê²Œ src/modules/llm.pyì— SolarChatModel í´ë˜ìŠ¤ë¥¼ êµ¬í˜„í•˜ë„ë¡ ìš”ì²­")
    print("2. íŒ€ì¥(ë„ˆ)ì´ API ë°°í¬ í›„, 10ê°œ ì§ˆë¬¸ì„ APIì— ë˜ì ¸ 'answer'ì™€ 'contexts'ë¥¼ ë°›ì•„ì™€ì•¼ ì´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìµœì¢… ì‹¤í–‰í•  ìˆ˜ ìˆìŒ")