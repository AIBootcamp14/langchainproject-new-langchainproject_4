from typing import List, Dict, Any

from langchain_core.runnables import Runnable, RunnablePassthrough, RunnableLambda
from langchain_core.output_parsers import StrOutputParser
from langchain_core.vectorstores import VectorStore
from langchain_core.documents import Document

from .llm import get_solar_llm
from .prompts import RAG_PROMPT
from langchain_core.language_models import BaseChatModel

# íƒ€ì… íŒíŠ¸ë¥¼ ìœ„í•œ ë³„ì¹­
RAGChain = Runnable[str, Dict[str, Any]]
ContextAwareChain = Runnable[str, str]

def format_docs(docs: List[Document]) -> str:
    """
    ê²€ìƒ‰ëœ Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ LLMì˜ Context ì…ë ¥ì— ì í•©í•œ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…
    """
    return "\n\n".join(doc.page_content for doc in docs)

def get_source_aware_rag_chain(vectorstore: VectorStore) -> RAGChain:
    """
    LCELì„ ì‚¬ìš©í•˜ì—¬ ìµœì¢… ë‹µë³€ê³¼ ê²€ìƒ‰ëœ ì¶œì²˜ ì •ë³´ë¥¼ í•¨ê»˜ ë°˜í™˜í•˜ëŠ” RAG ì²´ì¸ì„ êµ¬ì„±
    
    Args:
        vectorstore: ë°ì´í„°ê°€ ì ì¬ëœ ë²¡í„° ì €ì¥ì†Œ ê°ì²´

    Returns:
        RAGChain: ì‚¬ìš©ì ì§ˆë¬¸(str)ì„ ë°›ì•„ {'answer': str, 'docs': List[Document]}ë¥¼ ë°˜í™˜í•˜ëŠ” ì²´ì¸
    """
    llm: BaseChatModel = get_solar_llm()
    # íŒ€ì› 5ì™€ í˜‘ì˜í•˜ì—¬ k ê°’(ê²€ìƒ‰ ë¬¸ì„œ ê°œìˆ˜)ì„ ì„¤ì •í•˜ê¸°. ì¼ë‹¨ 3ê°œë¡œ ì„¤ì •
    retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

    # 1. ê²€ìƒ‰ ë‹¨ê³„ (Retrieval): ì§ˆë¬¸ì„ ë°›ì•„ Document ë¦¬ìŠ¤íŠ¸ë¥¼ ê²€ìƒ‰í•˜ê³ , Contextë¡œ í¬ë§·íŒ…í•´
    # RunnablePassthrough.assignì„ ì‚¬ìš©í•´ ìµœì¢… ì¶œë ¥ì— 'docs'ì™€ 'context'ë¥¼ í¬í•¨ì‹œí‚´
    setup_and_retrieval = RunnablePassthrough.assign(
        docs=retriever, # ê²€ìƒ‰ëœ Document ë¦¬ìŠ¤íŠ¸
    ).assign(
        context=lambda x: format_docs(x["docs"]), # ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©ì„ Context ë¬¸ìì—´ë¡œ í¬ë§·íŒ…
        question=RunnablePassthrough(), # ì§ˆë¬¸ ì›ë³¸ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬
    )

    # 2. ìƒì„± ë‹¨ê³„ (Generation): ê²€ìƒ‰ ê²°ê³¼ì™€ ì§ˆë¬¸ì„ í”„ë¡¬í”„íŠ¸ì— ë„£ì–´ LLMì—ê²Œ ë‹µë³€ì„ ìš”ì²­
    answer_generation = (
        RAG_PROMPT
        | llm
        | StrOutputParser()
    )

    # 3. ìµœì¢… ì²´ì¸: ê²€ìƒ‰ ê²°ê³¼ì™€ ë‹µë³€ ê²°ê³¼ë¥¼ í•©ì³ì„œ ë°˜í™˜
    # setup_and_retrievalì˜ ì¶œë ¥ì— 'answer' í‚¤ë¥¼ ì¶”ê°€í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ìµœì¢… ê²°ê³¼ë¥¼ êµ¬ì„±
    final_chain: RAGChain = setup_and_retrieval.assign(
        answer=answer_generation,
    ).assign(
        # ğŸ’¡ğŸ’¡ğŸ’¡ 'docs' í‚¤ë¥¼ 'source_documents'ë¡œ ì´ë¦„ ë³€ê²½í•˜ì—¬ main.pyì™€ ë§ì¶¤ ğŸ’¡ğŸ’¡ğŸ’¡
        source_documents=lambda x: x["docs"],
    ).with_config(
        output_keys=["answer", "source_documents"] # ë¶ˆí•„ìš”í•œ í‚¤ ì œê±°
    )
    
    return final_chain