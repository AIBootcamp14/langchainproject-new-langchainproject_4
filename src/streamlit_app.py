# src/streamlit_app.py

"""
Streamlit ê¸°ë°˜ì˜ RAG ì›¹ ì¸í„°í˜ì´ìŠ¤
"""

import os
import json
import requests
from typing import List, Dict, Any, Optional

# ì¨ë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬
import streamlit as st
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (ë¡œì»¬ ê°œë°œ í™˜ê²½ìš©)
load_dotenv()

# --- ì„¤ì • ë° ìƒìˆ˜ (PEP 8) ---
FASTAPI_URL: str = os.getenv("FASTAPI_URL", "http://localhost:8000") 
API_HEALTH_ENDPOINT: str = f"{FASTAPI_URL}/health"
API_ASK_STREAM_ENDPOINT: str = f"{FASTAPI_URL}/ask/stream" # ğŸ’¡ [í•µì‹¬ ìˆ˜ì •]: ìŠ¤íŠ¸ë¦¬ë° ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©


# --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---

def health_check() -> bool:
    """FastAPI ì„œë²„ì˜ í—¬ìŠ¤ ì²´í¬ ìƒíƒœë¥¼ í™•ì¸"""
    try:
        response = requests.get(API_HEALTH_ENDPOINT, timeout=5)
        response.raise_for_status()
        data = response.json()
        
        if data.get("rag_status") == "ready" and data.get("chroma_status") == "ok":
             return True
        else:
             st.warning(f"FastAPI ì„œë²„ ì¤€ë¹„ ì¤‘: {data.get('detail', 'ìƒì„¸ ì •ë³´ ì—†ìŒ')}")
             return False
             
    except requests.exceptions.RequestException as e:
        st.error(f"FastAPI ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. URL: {FASTAPI_URL}")
        st.error(f"ì˜¤ë¥˜: {e}")
        return False
        
def ask_query_stream(question: str) -> Dict[str, Any]:
    """
    FastAPI /ask/stream ì—”ë“œí¬ì¸íŠ¸ì— ì§ˆë¬¸ì„ ë³´ë‚´ê³  ê²°ê³¼ë¥¼ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë°›ëŠ”ë‹¤.
    
    Yields: ë‹µë³€ ì²­í¬ (str)
    Returns: ìµœì¢… ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬
    """
    payload: Dict[str, str] = {"question": question}
    
    try:
        # stream=Trueë¡œ ì„¤ì •í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë° ì—°ê²°
        response = requests.post(API_ASK_STREAM_ENDPOINT, json=payload, stream=True, timeout=60)
        response.raise_for_status()
        
        full_answer = ""
        metadata: Dict[str, Any] = {}
        
        # FastAPIì—ì„œ ì •ì˜í•œ íŠ¹ìˆ˜ êµ¬ë¶„ì
        METADATA_DELIMITER = "\n<END_OF_STREAM_METADATA>"

        # ìŠ¤íŠ¸ë¦¼ì„ ì²­í¬ ë‹¨ìœ„ë¡œ ì½ìŒ
        for chunk in response.iter_content(chunk_size=None, decode_unicode=True):
            if not chunk:
                continue
            
            # ë©”íƒ€ë°ì´í„° êµ¬ë¶„ìê°€ ìˆëŠ”ì§€ í™•ì¸
            if METADATA_DELIMITER in chunk:
                # ë³¸ë¬¸ê³¼ ë©”íƒ€ë°ì´í„° ë¶„ë¦¬
                answer_chunk, metadata_json_str = chunk.split(METADATA_DELIMITER, 1)
                full_answer += answer_chunk
                yield answer_chunk # ë§ˆì§€ë§‰ ë‹µë³€ ì²­í¬ ì „ë‹¬
                
                # ë©”íƒ€ë°ì´í„° íŒŒì‹±
                try:
                    metadata = json.loads(metadata_json_str)
                    metadata["answer"] = full_answer # ìµœì¢… ë‹µë³€ì„ ë©”íƒ€ë°ì´í„°ì— í¬í•¨
                except json.JSONDecodeError:
                    st.error("ë©”íƒ€ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ. ì„œë²„ ì‘ë‹µ í™•ì¸ í•„ìš”.")
                    metadata = {"error": "Metadata parsing failed."}
                    
                # ë©”íƒ€ë°ì´í„°ë¥¼ ë°›ì•˜ìœ¼ë¯€ë¡œ ìµœì¢… ê²°ê³¼ ë°˜í™˜
                return metadata
            else:
                full_answer += chunk
                yield chunk # Streamlitì—ê²Œ ì²­í¬ë¥¼ ë°˜í™˜í•˜ì—¬ UIì— ì—…ë°ì´íŠ¸ë˜ë„ë¡ í•¨
        
        # ìŠ¤íŠ¸ë¦¼ì´ ì •ìƒì ìœ¼ë¡œ ë‹«í˜”ìœ¼ë‚˜ ë©”íƒ€ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°
        return {"answer": full_answer, "source_urls": [], "execution_time_ms": 0}
        
    except requests.exceptions.HTTPError as e:
        st.error(f"API ìš”ì²­ ì˜¤ë¥˜ ({e.response.status_code}): {e.response.json().get('detail', 'ìƒì„¸ ì˜¤ë¥˜ ì—†ìŒ')}")
    except requests.exceptions.RequestException as e:
        st.error(f"FastAPI ì„œë²„ í†µì‹  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
    return {"answer": "ì„œë²„ í†µì‹  ì˜¤ë¥˜ë¡œ ë‹µë³€ì„ ë°›ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "source_urls": [], "execution_time_ms": 0}


# --- Streamlit UI êµ¬ì„± ---

st.set_page_config(
    page_title="LangChain RAG ì±—ë´‡",
    layout="wide"
)

def main_ui():
    """ë©”ì¸ UIë¥¼ êµ¬ì„±í•˜ê³  ëŒ€í™” ë¡œì§ì„ ì²˜ë¦¬í•œë‹¤."""
    st.title("ğŸ“š LangChain ë¬¸ì„œ RAG ì±—ë´‡")
    st.caption(f"Powered by Solar LLM & ChromaDB via FastAPI ({FASTAPI_URL})")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ëŒ€í™” ê¸°ë¡)
    if "messages" not in st.session_state:
        st.session_state.messages = []
        
    # 1. í—¬ìŠ¤ ì²´í¬
    if not health_check():
        st.warning("FastAPI ë°±ì—”ë“œê°€ ì¤€ë¹„ë  ë•Œê¹Œì§€ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”.")
        return

    # 2. ì´ì „ ëŒ€í™” ê¸°ë¡ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            if message["role"] == "assistant" and "time" in message:
                st.info(f"â±ï¸ ì‘ë‹µ ì‹œê°„: {message['time']:.2f}ì´ˆ")


    # 3. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if prompt := st.chat_input("LangChain ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”..."):
        
        # ì‚¬ìš©ì ì§ˆë¬¸ í‘œì‹œ ë° ì €ì¥
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
            
        # ì±—ë´‡ ë‹µë³€ ìƒì„± ë° í‘œì‹œ
        with st.chat_message("assistant"):
            # ğŸ’¡ [í•µì‹¬ ìˆ˜ì •]: Streamlitì˜ empty ì»¨í…Œì´ë„ˆë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
            message_placeholder = st.empty()
            full_response = ""
            
            # 1. ìŠ¤íŠ¸ë¦¼ ìš”ì²­ ë° ì‹¤ì‹œê°„ ë‹µë³€ ì—…ë°ì´íŠ¸
            stream_generator = ask_query_stream(prompt)
            
            for chunk in stream_generator:
                if isinstance(chunk, str):
                    full_response += chunk
                    message_placeholder.markdown(full_response + "â–Œ") # ì»¤ì„œ íš¨ê³¼
                
            # 2. ìµœì¢… ë©”íƒ€ë°ì´í„° ì²˜ë¦¬ ë° UI ì—…ë°ì´íŠ¸
            # stream_generatorê°€ ìµœì¢…ì ìœ¼ë¡œ ë°˜í™˜í•˜ëŠ” ë©”íƒ€ë°ì´í„°ë¥¼ ë°›ëŠ”ë‹¤.
            # Generatorì˜ return ê°’ì€ StopIteration ì˜ˆì™¸ì˜ valueë¡œ ì „ë‹¬ë˜ì§€ë§Œ, 
            # ì—¬ê¸°ì„œëŠ” ask_query_stream í•¨ìˆ˜ì˜ ë°˜í™˜ ê°’ì„ ëª…ì‹œì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ,
            # stream_generator ì‹¤í–‰ í›„ full_responseì™€ ë³„ë„ë¡œ ì €ì¥ëœ ë©”íƒ€ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ì•¼ í•œë‹¤.
            
            # [ìˆ˜ì • í•„ìš”]: stream_generatorê°€ ëë‚œ í›„ ìµœì¢… ë©”íƒ€ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ëª…ì‹œì  ë°©ë²•ì´ í•„ìš”í•¨.
            # ask_query_stream í•¨ìˆ˜ë¥¼ yieldë¡œ ë§Œë“¤ê³ , ë§ˆì§€ë§‰ì— return ëŒ€ì‹  ì˜ˆì™¸ë¥¼ í™œìš©í•˜ê±°ë‚˜,
            # ì•„ë‹ˆë©´ main_uiì—ì„œ generatorë¥¼ ì‹¤í–‰í•˜ê³  ë§ˆì§€ë§‰ return ê°’ì„ ëª…ì‹œì ìœ¼ë¡œ ë°›ë„ë¡ ì½”ë“œë¥¼ ìˆ˜ì •í•´ì•¼ í•¨.
            
            # [ì„ì‹œ ìˆ˜ì •]: stream_generatorê°€ ëë‚œ í›„, generator ê°ì²´ê°€ ë°˜í™˜í•œ ë”•ì…”ë„ˆë¦¬ë¥¼ ì§ì ‘ ë°›ëŠ”ë‹¤.
            try:
                # generatorì˜ ìµœì¢… ë”•ì…”ë„ˆë¦¬ë¥¼ ë°›ìŒ
                final_metadata = next(stream_generator) 
            except StopIteration as e:
                # StopIterationì˜ valueì— return ê°’ì´ ë‹´ê²¨ ìˆìŒ
                final_metadata = e.value if e.value is not None else {}
            except TypeError:
                 # ask_query_streamì´ ì˜ˆì™¸ë¡œ ëë‚¬ì„ ë•Œ ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ì²˜ë¦¬
                 final_metadata = {} 
            
            
            # 3. ìµœì¢… ë‹µë³€ ë° ì»¤ì„œ ì œê±°
            message_placeholder.markdown(full_response)
            
            if final_metadata and not final_metadata.get("error"):
                source_urls: List[str] = final_metadata.get("source_urls", [])
                execution_time_ms: int = final_metadata.get("execution_time_ms", 0)
                execution_time_sec: float = execution_time_ms / 1000.0
                
                # ì¶œì²˜ ì •ë³´ í‘œì‹œ
                if source_urls:
                    st.markdown("---")
                    st.markdown("**ì°¸ì¡°ëœ ì¶œì²˜:**")
                    for url in set(source_urls):
                        st.markdown(f"- [{url.split('/')[-1]}]({url})")
                
                # ì‘ë‹µ ì‹œê°„ ì¶œë ¥
                st.info(f"â±ï¸ ì‘ë‹µ ì‹œê°„: {execution_time_sec:.2f}ì´ˆ (ìŠ¤íŠ¸ë¦¬ë° í¬í•¨)")

                # ì„¸ì…˜ ìƒíƒœì— ë‹µë³€ ë° ë©”íƒ€ë°ì´í„° ì €ì¥
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": full_response, 
                    "sources": source_urls,
                    "time": execution_time_sec
                })
            elif final_metadata.get("error"):
                 st.error(f"ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {final_metadata['error']}")
            else:
                 # ì˜¤ë¥˜ê°€ ë°œìƒí–ˆê±°ë‚˜ ë©”íƒ€ë°ì´í„°ë¥¼ ë°›ì§€ ëª»í•œ ê²½ìš° (ask_query_streamì—ì„œ ì´ë¯¸ ì—ëŸ¬ë¥¼ í‘œì‹œí–ˆì„ ìˆ˜ ìˆìŒ)
                 pass 


if __name__ == "__main__":
    main_ui()