"""
Streamlit ê¸°ë°˜ì˜ RAG ì›¹ ì¸í„°í˜ì´ìŠ¤
"""

import os
import json
import requests
import sys
from typing import List, Dict, Any, Optional

# ì¨ë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬
import streamlit as st
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (ë¡œì»¬ ê°œë°œ í™˜ê²½ìš©)
load_dotenv()

# --- ì„¤ì • ë° ìƒìˆ˜ (PEP 8) ---
FASTAPI_URL: str = os.getenv("FASTAPI_URL", "http://localhost:8000")
API_HEALTH_ENDPOINT: str = f"{FASTAPI_URL}/health"
API_ASK_STREAM_ENDPOINT: str = f"{FASTAPI_URL}/ask/stream"

# ìƒìˆ˜ ì •ì˜ (PEP 8: ëŒ€ë¬¸ì ì‚¬ìš©)
METADATA_DELIMITER: str = "\n<END_OF_STREAM_METADATA>"

# --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---

def health_check() -> bool:
    """FastAPI ì„œë²„ì˜ í—¬ìŠ¤ ì²´í¬ ìƒíƒœë¥¼ í™•ì¸"""
    try:
        response: requests.Response = requests.get(API_HEALTH_ENDPOINT, timeout=5)
        response.raise_for_status()
        data: Dict[str, Any] = response.json()

        # OpenAPI ì„œë²„ê°€ ì¤€ë¹„ë˜ì—ˆëŠ”ì§€ í™•ì¸
        if data.get("rag_status") == "ready" and data.get("chroma_status") == "ok":
            return True
        else:
            st.toast(f"FastAPI ì„œë²„ ì¤€ë¹„ ì¤‘: {data.get('detail', 'ìƒì„¸ ì •ë³´ ì—†ìŒ')}", icon="â³")
            return False

    except requests.exceptions.RequestException as e:
        # st.error(f"FastAPI ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. URL: {FASTAPI_URL}")
        st.toast("ì„œë²„ ì—°ê²° ì˜¤ë¥˜. FastAPI ì„œë²„ê°€ ì¼œì ¸ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.", icon="âŒ")
        return False

def ask_query_stream(question: str) -> Any:
    """
    FastAPI /ask/stream ì—”ë“œí¬ì¸íŠ¸ì— ì§ˆë¬¸ì„ ë³´ë‚´ê³  ê²°ê³¼ë¥¼ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë°›ëŠ”ë‹¤.
    
    Args:
        question: ì‚¬ìš©ì ì§ˆë¬¸ ë¬¸ìì—´.
    
    Yields:
        ì‘ë‹µ ì²­í¬ ë¬¸ìì—´.
        
    Returns:
        ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” ì—ëŸ¬ ë”•ì…”ë„ˆë¦¬.
    """
    payload: Dict[str, str] = {"question": question}

    try:
        # ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­
        response: requests.Response = requests.post(
            API_ASK_STREAM_ENDPOINT, 
            json=payload, 
            stream=True, 
            timeout=60
        )
        response.raise_for_status()

        full_answer: str = ""
        
        # Streamlit ë©”ì‹œì§€ í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì‚¬ìš©í•œ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥
        for chunk in response.iter_content(chunk_size=None, decode_unicode=True):
            if not chunk:
                continue

            # ë©”íƒ€ë°ì´í„° êµ¬ë¶„ìê°€ í¬í•¨ëœ ê²½ìš°
            if METADATA_DELIMITER in chunk:
                answer_chunk, metadata_json_str = chunk.split(METADATA_DELIMITER, 1)
                full_answer += answer_chunk
                yield answer_chunk # ë‹µë³€ì˜ ë§ˆì§€ë§‰ ì²­í¬

                try:
                    # ë©”íƒ€ë°ì´í„° íŒŒì‹± í›„ ë°˜í™˜
                    metadata: Dict[str, Any] = json.loads(metadata_json_str)
                    return metadata
                except json.JSONDecodeError:
                    st.toast("ë©”íƒ€ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ.", icon="âš ï¸")
                    return {"error": "Metadata parsing failed."}
            else:
                # ì¼ë°˜ ë‹µë³€ ì²­í¬
                full_answer += chunk
                yield chunk

        # ë©”íƒ€ë°ì´í„° ì—†ì´ ìŠ¤íŠ¸ë¦¼ì´ ëë‚œ ê²½ìš° (ì˜ˆì™¸ ì²˜ë¦¬)
        return {"answer": full_answer, "source_urls": [], "execution_time_ms": 0}

    except requests.exceptions.HTTPError as e:
        # HTTP ì—ëŸ¬ ë°œìƒ ì‹œ ì²˜ë¦¬
        error_detail: str = e.response.json().get('detail', 'ìƒì„¸ ì˜¤ë¥˜ ì—†ìŒ')
        return {"error": f"API ìš”ì²­ ì˜¤ë¥˜ ({e.response.status_code}): {error_detail}"}
    except requests.exceptions.RequestException as e:
        # ê¸°íƒ€ í†µì‹  ì˜¤ë¥˜ ì²˜ë¦¬
        return {"error": f"FastAPI ì„œë²„ í†µì‹  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"}


# --- ì„¸ì…˜ ì´ˆê¸°í™” í•¨ìˆ˜ ---

def initialize_session_state() -> None:
    """ì„¸ì…˜ ìƒíƒœë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤. (messagesë§Œ ì—†ìœ¼ë©´ ì´ˆê¸°í™”)"""
    # ğŸ’¡ [í•µì‹¬ ìˆ˜ì •]: ì„¸ì…˜ì´ ë¹„ì–´ìˆì„ ë•Œë§Œ ì´ˆê¸°í™”í•˜ì—¬ ë¶ˆí•„ìš”í•œ ë¦¬ì…‹ ë°©ì§€
    if "messages" not in st.session_state:
        st.session_state.messages = []
        # ë””ë²„ê¹… ì¶œë ¥ì€ ì´ì œ í•„ìš” ì—†ì–´, ë¶ˆí•„ìš”í•œ ë©”ì‹œì§€ ìƒì„±ì„ ë§‰ê¸° ìœ„í•´ ì œê±°
        st.toast("ìƒˆë¡œìš´ ì±„íŒ… ì„¸ì…˜ ì‹œì‘.", icon="ğŸ‘‹")


# --- Streamlit UI êµ¬ì„± ---

st.set_page_config(
    page_title="LangChain RAG ì±—ë´‡",
    layout="wide",
    page_icon="ğŸ¤–",
    initial_sidebar_state="collapsed"
)

def main_ui() -> None:
    """ë©”ì¸ UIë¥¼ êµ¬ì„±í•˜ê³  ëŒ€í™” ë¡œì§ì„ ì²˜ë¦¬í•œë‹¤."""
    # ğŸ’¡ CSS ìŠ¤íƒ€ì¼ë§ì€ HTML ë§ˆí¬ë‹¤ìš´ ëŒ€ì‹  st.markdownìœ¼ë¡œ ìœ ì§€
    st.markdown(
        """
        <style>
        /* ì „ì²´ í˜ì´ì§€ ë°°ê²½ ë° í°íŠ¸ */
        .stApp {
            background-color: #f4f7f9; /* ì˜…ì€ íšŒìƒ‰ ë°°ê²½ */
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }
        /* ë‚˜ë¨¸ì§€ CSSëŠ” ë™ì¼í•˜ê²Œ ìœ ì§€ */
        .stChatMessage {
            border-radius: 12px;
            padding: 10px 15px;
            margin-bottom: 10px;
        }
        .stChatMessage[data-testid="stChatMessage"][data-element-type="chat-message"][data-is-user="true"] {
            background-color: #e6f7ff;
            border-left: 5px solid #007bff;
        }
        .stChatMessage[data-testid="stChatMessage"][data-element-type="chat-message"][data-is-user="false"] {
            background-color: #ffffff;
            border-right: 5px solid #007bff;
            box-shadow: 0 1px 3px rgba(0,0,0,0.05);
        }
        .stChatInput {
            position: fixed;
            bottom: 0;
            left: 0;
            right: 0;
            padding: 10px;
            background: #f4f7f9;
            z-index: 1000;
            border-top: 1px solid #ddd;
        }
        .chat-history-container {
            height: 75vh;
            overflow-y: auto;
            padding-bottom: 80px;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

    st.title("ğŸ¤– LangChain ë¬¸ì„œ RAG ì±—ë´‡")
    st.caption(f"Powered by Solar LLM & ChromaDB via FastAPI ({FASTAPI_URL})")

    # 0. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    initialize_session_state()

    # 1. í—¬ìŠ¤ ì²´í¬ ë° ì„œë²„ ìƒíƒœ í‘œì‹œ
    if not health_check():
        st.stop()

    # 2. ëŒ€í™” ê¸°ë¡ í‘œì‹œ ì»¨í…Œì´ë„ˆ
    chat_history_container = st.container(height=500, border=False)

    with chat_history_container:
        # ëŒ€í™” ê¸°ë¡ì„ í™”ë©´ì— í‘œì‹œ
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

                # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ì—ë§Œ ì†ŒìŠ¤ ë° ì‹œê°„ ì •ë³´ í‘œì‹œ
                if message["role"] == "assistant":
                    if "time" in message:
                        st.info(f"â±ï¸ ì‘ë‹µ ì‹œê°„: {message['time']:.2f}ì´ˆ")

                    if "sources" in message and message["sources"]:
                        with st.expander("ì°¸ì¡°ëœ ì¶œì²˜ ë³´ê¸°"):
                            # ì¤‘ë³µ URL ì œê±° ë° í‘œì‹œ
                            for url in sorted(list(set(message["sources"]))):
                                file_name: str = url.split('/')[-1] if url.split('/')[-1] else url
                                st.markdown(f"- [{file_name}]({url})")


    # 3. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if prompt := st.chat_input("LangChain ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”..."):

        # 1ì°¨: ì§ˆë¬¸ ì €ì¥
        st.session_state.messages.append({"role": "user", "content": prompt})

        # ë‹µë³€ ìƒì„±ì„ ìœ„í•´ ì¦‰ì‹œ rerun
        st.rerun()


    # 4. ë‹µë³€ ìƒì„± ë° ì €ì¥ (RERUN 2: ë‹µë³€ ìƒì„±)
    # ë§ˆì§€ë§‰ ë©”ì‹œì§€ê°€ ì‚¬ìš©ì ë©”ì‹œì§€ì´ê³ , ë‹µë³€ì´ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ì„ ë•Œë§Œ ì‹¤í–‰
    if (st.session_state.messages and 
        st.session_state.messages[-1]["role"] == "user"):

        current_prompt: str = st.session_state.messages[-1]["content"]

        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response: str = ""
            final_metadata: Dict[str, Any] = {}
            
            # ë‹µë³€ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
            stream_generator = ask_query_stream(current_prompt)

            try:
                for chunk in stream_generator:
                    if isinstance(chunk, str):
                        full_response += chunk
                        message_placeholder.markdown(full_response + "â–Œ")
                
                # ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í›„ ë©”íƒ€ë°ì´í„° ë°˜í™˜ ë°›ê¸°
                if isinstance(stream_generator, dict):
                    final_metadata = stream_generator
                else:
                    # Generatorê°€ ì •ìƒ ì¢…ë£Œë˜ì–´ ë©”íƒ€ë°ì´í„°ë¥¼ ë°˜í™˜
                    final_metadata = next(stream_generator, {}) # Generatorì˜ ë§ˆì§€ë§‰ ë°˜í™˜ ê°’ì„ ê°€ì ¸ì˜´
                    
            except Exception as e:
                # ğŸ’¡ API í†µì‹  ì˜¤ë¥˜ ë°œìƒ ì‹œ ì²˜ë¦¬
                print(f"--- ERROR: Streaming failed. Exception: {e}", file=sys.stderr)
                st.error(f"ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

            # ìµœì¢… ì‘ë‹µ ì¶œë ¥
            message_placeholder.markdown(full_response)

            # ë‹µë³€ ì €ì¥
            if "error" not in final_metadata:
                source_urls: List[str] = final_metadata.get("source_urls", [])
                execution_time_ms: int = final_metadata.get("execution_time_ms", 0)
                execution_time_sec: float = execution_time_ms / 1000.0

                st.info(f"â±ï¸ ì‘ë‹µ ì‹œê°„: {execution_time_sec:.2f}ì´ˆ (ìŠ¤íŠ¸ë¦¬ë° í¬í•¨)")
                st.toast("ë‹µë³€ ìƒì„± ì™„ë£Œ!", icon="âœ…")

                st.session_state.messages.append({
                    "role": "assistant",
                    "content": full_response,
                    "sources": source_urls,
                    "time": execution_time_sec
                })
            else:
                # ì˜¤ë¥˜ ë©”ì‹œì§€ ì €ì¥
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": f"ì£„ì†¡í•©ë‹ˆë‹¤. API í†µì‹  ì˜¤ë¥˜ë¡œ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ({final_metadata.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')})",
                    "sources": [],
                    "time": 0
                })
                st.error(f"API í†µì‹  ì˜¤ë¥˜ë¡œ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {final_metadata.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")

        # ğŸ’¡ [í•µì‹¬ ìˆ˜ì •]: st.rerun() ì œê±°!
        # ë‹µë³€ì´ ì €ì¥ëœ í›„ ë‹¤ì‹œ ë Œë”ë§í•  í•„ìš” ì—†ìŒ. Streamlitì´ ì•Œì•„ì„œ ë‹¤ìŒ ì…ë ¥ì„ ê¸°ë‹¤ë¦¼.


if __name__ == "__main__":
    main_ui()