[
    {
        "title": "File structure",
        "type": "text",
        "content": "Below are examples of directory structures for applications:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/application-structure",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Application structure"
    },
    {
        "title": "Custom stores",
        "type": "text",
        "content": "You can also implement your own custom store by extending the BaseStore class. See the store interface documentation for more details.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/stores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Key-value stores"
    },
    {
        "title": "Log to a project",
        "type": "code",
        "content": "export LANGSMITH_PROJECT=my-agent-project\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/observability",
        "head_menu_name": "LangChain",
        "side_menu_name": "Observability"
    },
    {
        "title": "langchain-classic",
        "type": "code",
        "content": "uv pip install langchain-classic\n",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "ScaNN (Local Index)",
        "type": "code",
        "content": "pip install scann langchain-community # Requires langchain-community\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Prebuilt middleware",
        "type": "code",
        "content": "HumanInTheLoopMiddleware",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Memory Store",
        "type": "text",
        "content": "A state schema specifies a set of keys that are populated as a graph is executed. As discussed above, state can be written by a checkpointer to a thread at each graph step, enabling state persistence.\n\nBut, what if we want to retain some information across threads ? Consider the case of a chatbot where we want to retain specific information about the user across all chat conversations (e.g., threads) with that user!\n\nWith checkpointers alone, we cannot share information across threads. This motivates the need for the Store interface. As an illustration, we can define an InMemoryStore to store information about a user across threads. We simply compile our graph with a checkpointer, as before, and with our new in_memory_store variable.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Dynamic runtime context",
        "type": "text",
        "content": "Dynamic runtime context represents mutable data that can evolve during a single run and is managed through the LangGraph state object. This includes conversation history, intermediate results, and values derived from tools or LLM outputs. In LangGraph, the state object acts as short-term memory during a run.\n\nExample shows how to incorporate state into an agent prompt .\n\nState can also be accessed by the agent’s tools , which can read or update the state as needed. See tool calling guide for details.",
        "side_link": "https://docs.langchain.com/oss/python/concepts/context",
        "head_menu_name": "Learn",
        "side_menu_name": "Context"
    },
    {
        "title": "System prompt",
        "type": "text",
        "content": "Deep agents come with a built-in system prompt inspired by Claude Code’s system prompt. The default system prompt contains detailed instructions for using the built-in planning tool, file system tools, and subagents.\n\nEach deep agent tailored to a use case should include a custom system prompt specific to that use case.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/customization",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Customization"
    },
    {
        "title": "Defining formats",
        "type": "text",
        "content": "Schema definitions guide the model. Field names, types, and descriptions specify exactly what format the output should adhere to.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Choosing a pattern",
        "type": "text",
        "content": "You can mix both patterns — use handoffs for agent switching, and have each agent call subagents as tools for specialized tasks.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/multi-agent",
        "head_menu_name": "LangChain",
        "side_menu_name": "Multi-agent"
    },
    {
        "title": "Encryption",
        "type": "code",
        "content": "from_pycryptodome_aes",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Standard content",
        "type": "text",
        "content": "In v1, messages gain provider-agnostic standard content blocks. Access them via @[ message.content_blocks ][content_blocks] for a consistent, typed view across providers. The existing message.content field remains unchanged for strings or provider-native structures.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "6. View your agent in Studio",
        "type": "text",
        "content": "Studio makes each step of your agent easily observable. Replay any input and inspect the exact prompt, tool arguments, return values, and token/latency metrics. If a tool throws an exception, Studio records it with surrounding state so you can spend less time debugging.\n\nKeep your dev server running, edit prompts or tool signatures, and watch Studio hot-reload. Re-run the conversation thread from any step to verify behavior changes. See Manage threads for more details.\n\nAs your agent grows, the same view scales from a single-tool demo to multi-node graphs, keeping decisions legible and reproducible.\n\nFor an in-depth look at Studio, check out the overview page .\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/studio",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Studio"
    },
    {
        "title": "Cloud Storage",
        "type": "code",
        "content": "from langchain_google_community import GCSDirectoryLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Persistence",
        "type": "text",
        "content": "LangGraph API handles checkpointing automatically When using the LangGraph API, you don’t need to implement or configure checkpointers manually. The API handles all persistence infrastructure for you behind the scenes.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Store is required",
        "type": "text",
        "content": "You must provide a Store when enabling long-term memory:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Minimize tool sets",
        "type": "text",
        "content": "Only give subagents the tools they need. This improves focus and security:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Gemma local from Kaggle",
        "type": "code",
        "content": "from langchain_google_vertexai.gemma import GemmaChatLocalKaggle\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "View subgraph state",
        "type": "text",
        "content": "When you enable persistence , you can inspect the graph state (checkpoint) via the appropriate method. To view the subgraph state, you can use the subgraphs option.\n\nYou can inspect the graph state via graph.get_state(config) . To view the subgraph state, you can use graph.get_state(config, subgraphs=True) .",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-subgraphs",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Subgraphs"
    },
    {
        "title": "PowerBI individual tools",
        "type": "text",
        "content": "You can use individual tools from the Azure PowerBI Toolkit:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Large tool result eviction",
        "type": "text",
        "content": "The harness automatically dumps large tool results to the file system when they exceed a token threshold, preventing context window saturation.\n\nHow it works:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/harness",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Agent harness"
    },
    {
        "title": "ProviderStrategy",
        "type": "text",
        "content": "To learn about structured output, see Structured output .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Context editing",
        "type": "text",
        "content": "Manage conversation context by trimming, summarizing, or clearing tool uses.\n\nPerfect for:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Deprecations",
        "type": "code",
        "content": "AgentStateWithStructuredResponsePydantic",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langgraph-v1",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Spanner",
        "type": "text",
        "content": "Vector store using Cloud Spanner .\n\nInstall the python package:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Google Trends",
        "type": "text",
        "content": "Query Google Trends data. Requires google-search-results package and SerpApi key.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Invoke",
        "type": "code",
        "content": "from langchain.messages import HumanMessage, AIMessage, SystemMessage\n\nconversation = [\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant that translates English to French.\"},\n    {\"role\": \"user\", \"content\": \"Translate: I love programming.\"},\n    {\"role\": \"assistant\", \"content\": \"J'adore la programmation.\"},\n    {\"role\": \"user\", \"content\": \"Translate: I love building applications.\"}\n]\n\nresponse = model.invoke(conversation)\nprint(response)  # AIMessage(\"J'adore créer des applications.\")\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Structured outputs",
        "type": "code",
        "content": "with_structured_output",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Backends",
        "type": "text",
        "content": "This page explains how to choose a backend , route different paths to different backends , implement your own virtual filesystem (e.g., S3 or Postgres), add policy hooks , and comply with the backend protocol .",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "5. Install dependencies",
        "type": "text",
        "content": "In the root of your new LangGraph app, install the dependencies:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/studio",
        "head_menu_name": "LangChain",
        "side_menu_name": "Studio"
    },
    {
        "title": "Memorystore for Redis",
        "type": "text",
        "content": "Vector store using Memorystore for Redis .\n\nInstall the python package:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Google Generative AI (Gemini API & AI Studio)",
        "type": "text",
        "content": "Start for free and get your API key from Google AI Studio .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Context editing",
        "type": "text",
        "content": "Token counting method. Options: \"approximate\" or \"model\"",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Handle errors appropriately",
        "type": "text",
        "content": "Add a retry policy to automatically retry network issues and rate limits:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "import getpass\nimport os\n\nif not os.environ.get(\"COHERE_API_KEY\"):\n  os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Enter API key for Cohere: \")\n\nfrom langchain_cohere import CohereEmbeddings\n\nembeddings = CohereEmbeddings(model=\"embed-english-v3.0\")\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Amazon Comprehend Moderation Chain",
        "type": "code",
        "content": "pip install boto3 nltk\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Agents",
        "type": "text",
        "content": "An LLM Agent runs tools in a loop to achieve a goal .\nAn agent runs until a stop condition is met - i.e., when the model emits a final output or an iteration limit is reached.\n\ncreate_agent builds a graph -based agent runtime using LangGraph . A graph consists of nodes (steps) and edges (connections) that define how your agent processes information. The agent moves through this graph, executing nodes like the model node (which calls the model), the tools node (which executes tools), or middleware.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Memorystore for Redis",
        "type": "code",
        "content": "pip install langchain-google-memorystore-redis\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Tool Message",
        "type": "text",
        "content": "See the RAG tutorial for an end-to-end example of building retrieval agents with LangChain.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "HuggingFaceEndpointEmbeddings",
        "type": "code",
        "content": "from langchain_huggingface import HuggingFaceEndpointEmbeddings\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "El Carro for Oracle Workloads",
        "type": "code",
        "content": "from langchain_google_el_carro import ElCarroLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Quick fix: submit a bugfix",
        "type": "text",
        "content": "You will need to install uv if you haven’t previously.",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "High-level API",
        "type": "text",
        "content": "The compiled Pregel instance will be associated with a list of nodes and channels. You can inspect the nodes and channels by printing them.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/pregel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Runtime"
    },
    {
        "title": "Azure OpenAI",
        "type": "text",
        "content": "Microsoft Azure , often referred to as Azure is a cloud computing platform run by Microsoft , which offers access, management, and development of applications and services through global data centers. It provides a range of capabilities, including software as a service (SaaS), platform as a service (PaaS), and infrastructure as a service (IaaS). Microsoft Azure supports many programming languages, tools, and frameworks, including Microsoft-specific and third-party software and systems.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Vertex AI",
        "type": "text",
        "content": "Access chat models like Gemini via the Vertex AI platform.\n\nSee a usage example .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Prompt caching",
        "type": "text",
        "content": "Many providers offer prompt caching features to reduce latency and cost on repeat processing of the same tokens. These features can be implicit or explicit :",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Quick fix: submit a bugfix",
        "type": "code",
        "content": "make lint\nmake test\n\n# For bugfixes involving integrations, also run:\nmake integration_tests\n",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "ToolRuntime",
        "type": "text",
        "content": "Use ToolRuntime to access all runtime information in a single parameter. Simply add runtime: ToolRuntime to your tool signature, and it will be automatically injected without being exposed to the LLM.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "ScaNN (Local Index)",
        "type": "text",
        "content": "Google ScaNN (Scalable Nearest Neighbors) is a python package.\n\nScaNN is a method for efficient vector similarity search at scale.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "LangSmith Integration",
        "type": "text",
        "content": "Results will be automatically logged to LangSmith.\n\nAlternatively, you can create a dataset in LangSmith and use the evaluate function:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Messages",
        "type": "text",
        "content": "Messages are the fundamental unit of context for models in LangChain. They represent the input and output of models, carrying both the content and metadata needed to represent the state of a conversation when interacting with an LLM.\n\nMessages are objects that contain:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Environment variables",
        "type": "text",
        "content": "For a production deployment, you will typically want to configure the environment variables in the deployment environment.\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/application-structure",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Application structure"
    },
    {
        "title": "Hugging Face model loader",
        "type": "text",
        "content": "Load model information from Hugging Face Hub , including README content.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "HuggingFaceEndpointEmbeddings",
        "type": "code",
        "content": "HuggingFaceEndpointEmbeddings",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Runtime context",
        "type": "code",
        "content": "from dataclasses import dataclass\n\nfrom langchain.agents import create_agent\n\n\n@dataclass\nclass Context:\n    user_id: str\n    session_id: str\n\nagent = create_agent(\n    model=model,\n    tools=tools,\n    context_schema=Context  \n)\n\nresult = agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}]},\n    context=Context(user_id=\"123\", session_id=\"abc\")  \n)\n",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Static model",
        "type": "text",
        "content": "For more control over the model configuration, initialize a model instance directly using the provider package. In this example, we use ChatOpenAI . See Chat models for other available chat model classes.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Integration Platforms",
        "type": "text",
        "content": "The following platforms provide access to multiple tools and services through a unified interface:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/tools",
        "head_menu_name": "Integrations",
        "side_menu_name": "Tools and toolkits"
    },
    {
        "title": "SearchApi",
        "type": "text",
        "content": "See usage examples and authorization instructions .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Using tasks in nodes",
        "type": "code",
        "content": "from typing import NotRequired\nfrom typing_extensions import TypedDict\nimport uuid\n\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.graph import StateGraph, START, END\nimport requests\n\n# Define a TypedDict to represent the state\nclass State(TypedDict):\n    url: str\n    result: NotRequired[str]\n\ndef call_api(state: State):\n    \"\"\"Example node that makes an API request.\"\"\"\n    result = requests.get(state['url']).text[:100]  # Side-effect  #\n    return {\n        \"result\": result\n    }\n\n# Create a StateGraph builder and add a node for the call_api function\nbuilder = StateGraph(State)\nbuilder.add_node(\"call_api\", call_api)\n\n# Connect the start and end nodes to the call_api node\nbuilder.add_edge(START, \"call_api\")\nbuilder.add_edge(\"call_api\", END)\n\n# Specify a checkpointer\ncheckpointer = InMemorySaver()\n\n# Compile the graph with the checkpointer\ngraph = builder.compile(checkpointer=checkpointer)\n\n# Define a config with a thread ID.\nthread_id = uuid.uuid4()\nconfig = {\"configurable\": {\"thread_id\": thread_id}}\n\n# Invoke the graph\ngraph.invoke({\"url\": \"https://www.example.com\"}, config)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/durable-execution",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Durable execution"
    },
    {
        "title": "Additional resources",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/guardrails",
        "head_menu_name": "LangChain",
        "side_menu_name": "Guardrails"
    },
    {
        "title": "Quickstart",
        "type": "code",
        "content": "agent = create_deep_agent(backend=FilesystemBackend(root_dir=\"/Users/nh/Desktop/\"))",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Context engineering",
        "type": "text",
        "content": "Learn methods for providing AI applications the right information and tools to accomplish a task.",
        "side_link": "https://docs.langchain.com/oss/python/learn",
        "head_menu_name": "Learn",
        "side_menu_name": "Learn"
    },
    {
        "title": "Basic Usage",
        "type": "code",
        "content": "(<user_id>, \"memories\")",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Co-locate Python and JavaScript/TypeScript content",
        "type": "text",
        "content": "We don’t want a lack of parity to block contributions. If a feature is only available in one language, it’s okay to have documentation only in that language until the other language catches up. In such cases, please include a note indicating that the feature is not yet available in the other language.\n\nIf you need help translating content between Python and JavaScript/TypeScript, please ask in the community slack or tag a maintainer in your PR.",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "pip install -qU langchain-mistralai\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Overview",
        "type": "text",
        "content": "LangChain’s streaming system lets you surface live feedback from agent runs to your application.\n\nWhat’s possible with LangChain streaming:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/streaming",
        "head_menu_name": "LangChain",
        "side_menu_name": "Streaming"
    },
    {
        "title": "5. Test the API",
        "type": "code",
        "content": "pip install langgraph-sdk\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/deploy",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Deploy"
    },
    {
        "title": "Choose models by task",
        "type": "code",
        "content": "subagents = [\n    {\n        \"name\": \"contract-reviewer\",\n        \"description\": \"Reviews legal documents and contracts\",\n        \"system_prompt\": \"You are an expert legal reviewer...\",\n        \"tools\": [read_document, analyze_contract],\n        \"model\": \"claude-sonnet-4-5-20250929\",  # Large context for long documents\n    },\n    {\n        \"name\": \"financial-analyst\",\n        \"description\": \"Analyzes financial data and market trends\",\n        \"system_prompt\": \"You are an expert financial analyst...\",\n        \"tools\": [get_stock_price, analyze_fundamentals],\n        \"model\": \"openai:gpt-4o\",  # Better for numerical analysis\n    },\n]\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Google Trends",
        "type": "code",
        "content": "pip install google-search-results langchain-community # Requires langchain-community\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Migrate tocreate_agent",
        "type": "code",
        "content": "langgraph.prebuilt.create_react_agent",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Amazon Kendra",
        "type": "code",
        "content": "from langchain_aws import AmazonKendraRetriever\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Setup",
        "type": "text",
        "content": "Sign up for LangSmith to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-time-travel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Time travel"
    },
    {
        "title": "Model call limit",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import ModelCallLimitMiddleware\n\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[...],\n    middleware=[\n        ModelCallLimitMiddleware(\n            thread_limit=10,  # Max 10 calls per thread (across runs)\n            run_limit=5,  # Max 5 calls per run (single invocation)\n            exit_behavior=\"end\",  # Or \"error\" to raise exception\n        ),\n    ],\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "How it works",
        "type": "text",
        "content": "When long-term memory is enabled, deep agents maintain two separate filesystems :",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Custom tool message content",
        "type": "text",
        "content": "Without tool_message_content , our final ToolMessage would be:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Bedrock Chat",
        "type": "code",
        "content": "Retrieval Augmented Generation",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Tool retry",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import ToolRetryMiddleware\n\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[search_tool, database_tool],\n    middleware=[\n        ToolRetryMiddleware(\n            max_retries=3,  # Retry up to 3 times\n            backoff_factor=2.0,  # Exponential backoff multiplier\n            initial_delay=1.0,  # Start with 1 second delay\n            max_delay=60.0,  # Cap delays at 60 seconds\n            jitter=True,  # Add random jitter to avoid thundering herd\n        ),\n    ],\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Use descriptive paths",
        "type": "code",
        "content": "# ✅ Good: Organized and descriptive\n/memories/user_preferences/language.txt\n/memories/projects/project_alpha/status.txt\n/memories/research/quantum_computing/sources.txt\n\n# ❌ Bad: Generic and unorganized\n/memories/temp.txt\n/memories/data.txt\n/memories/file1.txt\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Execution order",
        "type": "code",
        "content": "middleware1.after_model()",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Vertex AI image captioning",
        "type": "text",
        "content": "Implementation of the Image Captioning model as an LLM. Requires langchain-google-vertexai .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Cloud Vision loader",
        "type": "code",
        "content": "from langchain_google_community.vision import CloudVisionLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Customizing agent context",
        "type": "text",
        "content": "At the heart of multi-agent design is context engineering - deciding what information each agent sees. LangChain gives you fine-grained control over:\n\nThe quality of your system heavily depends on context engineering. The goal is to ensure that each agent has access to the correct data it needs to perform its task, whether it’s acting as a tool or as an active agent.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/multi-agent",
        "head_menu_name": "LangChain",
        "side_menu_name": "Multi-agent"
    },
    {
        "title": "Building a knowledge base",
        "type": "text",
        "content": "A knowledge base is a repository of documents or structured data used during retrieval.\n\nIf you need a custom knowledge base, you can use LangChain’s document loaders and vector stores to build one from your own data.\n\nIf you already have a knowledge base (e.g., a SQL database, CRM, or internal documentation system), you do not need to rebuild it. You can:\n\nSee the following tutorial to build a searchable knowledge base and minimal RAG workflow:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/retrieval",
        "head_menu_name": "LangChain",
        "side_menu_name": "Retrieval"
    },
    {
        "title": "Build a real-world agent",
        "type": "code",
        "content": "agent = create_agent(\n    model=model,\n    system_prompt=SYSTEM_PROMPT,\n    tools=[get_user_location, get_weather_for_location],\n    context_schema=Context,\n    response_format=ResponseFormat,\n    checkpointer=checkpointer\n)\n\n# `thread_id` is a unique identifier for a given conversation.\nconfig = {\"configurable\": {\"thread_id\": \"1\"}}\n\nresponse = agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather outside?\"}]},\n    config=config,\n    context=Context(user_id=\"1\")\n)\n\nprint(response['structured_response'])\n# ResponseFormat(\n#     punny_response=\"Florida is still having a 'sun-derful' day! The sunshine is playing 'ray-dio' hits all day long! I'd say it's the perfect weather for some 'solar-bration'! If you were hoping for rain, I'm afraid that idea is all 'washed up' - the forecast remains 'clear-ly' brilliant!\",\n#     weather_conditions=\"It's always sunny in Florida!\"\n# )\n\n\n# Note that we can continue the conversation using the same `thread_id`.\nresponse = agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"thank you!\"}]},\n    config=config,\n    context=Context(user_id=\"1\")\n)\n\nprint(response['structured_response'])\n# ResponseFormat(\n#     punny_response=\"You're 'thund-erfully' welcome! It's always a 'breeze' to help you stay 'current' with the weather. I'm just 'cloud'-ing around waiting to 'shower' you with more forecasts whenever you need them. Have a 'sun-sational' day in the Florida sunshine!\",\n#     weather_conditions=None\n# )\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/quickstart",
        "head_menu_name": "LangChain",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Example: Summarization",
        "type": "text",
        "content": "One of the most common life-cycle patterns is automatically condensing conversation history when it gets too long. Unlike the transient message trimming shown in Model Context , summarization persistently updates state - permanently replacing old messages with a summary that’s saved for all future turns.\n\nLangChain offers built-in middleware for this:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Trim messages",
        "type": "text",
        "content": "Most LLMs have a maximum supported context window (denominated in tokens).\n\nOne way to decide when to truncate messages is to count the tokens in the message history and truncate whenever it approaches that limit. If you’re using LangChain, you can use the trim messages utility and specify the number of tokens to keep from the list, as well as the strategy (e.g., keep the last max_tokens ) to use for handling the boundary.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Microsoft PowerPoint",
        "type": "text",
        "content": "Microsoft PowerPoint is a presentation program by Microsoft.\n\nSee a usage example .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Planning",
        "type": "text",
        "content": "Add todo list management capabilities for complex multi-step tasks.\n\nThis middleware automatically provides agents with a write_todos tool and system prompts to guide effective task planning.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "High-level API",
        "type": "code",
        "content": "from typing import TypedDict\n\nfrom langgraph.constants import START\nfrom langgraph.graph import StateGraph\n\nclass Essay(TypedDict):\n    topic: str\n    content: str | None\n    score: float | None\n\ndef write_essay(essay: Essay):\n    return {\n        \"content\": f\"Essay about {essay['topic']}\",\n    }\n\ndef score_essay(essay: Essay):\n    return {\n        \"score\": 10\n    }\n\nbuilder = StateGraph(Essay)\nbuilder.add_node(write_essay)\nbuilder.add_node(score_essay)\nbuilder.add_edge(START, \"write_essay\")\nbuilder.add_edge(\"write_essay\", \"score_essay\")\n\n# Compile the graph.\n# This will return a Pregel instance.\ngraph = builder.compile()\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/pregel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Runtime"
    },
    {
        "title": "Content block reference",
        "type": "text",
        "content": "An identifier associated with the tool call.\n\nThe name of the tool to be called.\n\nPartial tool arguments (may be incomplete JSON)\n\nPurpose: Streaming server-side tool call fragments\n\nAlways \"server_tool_call_chunk\"",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Custom MCP servers",
        "type": "code",
        "content": "from mcp.server.fastmcp import FastMCP\n\nmcp = FastMCP(\"Math\")\n\n@mcp.tool()\ndef add(a: int, b: int) -> int:\n    \"\"\"Add two numbers\"\"\"\n    return a + b\n\n@mcp.tool()\ndef multiply(a: int, b: int) -> int:\n    \"\"\"Multiply two numbers\"\"\"\n    return a * b\n\nif __name__ == \"__main__\":\n    mcp.run(transport=\"stdio\")\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/mcp",
        "head_menu_name": "LangChain",
        "side_menu_name": "Model Context Protocol (MCP)"
    },
    {
        "title": "Playwright URL Loader",
        "type": "code",
        "content": "pip install playwright unstructured\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Invocation",
        "type": "text",
        "content": "For streaming steps and / or tokens from the agent, refer to the streaming guide.\n\nOtherwise, the agent follows the LangGraph Graph API and supports all associated methods.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Interface",
        "type": "text",
        "content": "The interface allows queries and documents to be embedded with different strategies, though most providers handle them the same way in practice.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/text_embedding",
        "head_menu_name": "Integrations",
        "side_menu_name": "Embedding models"
    },
    {
        "title": "Interrupts in tools",
        "type": "text",
        "content": "This approach is useful when you want the approval logic to live with the tool itself, making it reusable across different parts of your graph. The LLM can call the tool naturally, and the interrupt will pause execution whenever the tool is invoked, allowing you to approve, edit, or cancel the action.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Tool calling",
        "type": "code",
        "content": "gathered = None\nfor chunk in model_with_tools.stream(\"What's the weather in Boston?\"):\n    gathered = chunk if gathered is None else gathered + chunk\n    print(gathered.tool_calls)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Step 2: Identify what each step needs to do",
        "type": "text",
        "content": "For each node in your graph, determine what type of operation it represents and what context it needs to work properly.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Basic configuration",
        "type": "code",
        "content": "from langchain_core.tools import tool\nfrom deepagents import create_deep_agent\nfrom langgraph.checkpoint.memory import MemorySaver\n\n@tool\ndef delete_file(path: str) -> str:\n    \"\"\"Delete a file from the filesystem.\"\"\"\n    return f\"Deleted {path}\"\n\n@tool\ndef read_file(path: str) -> str:\n    \"\"\"Read a file from the filesystem.\"\"\"\n    return f\"Contents of {path}\"\n\n@tool\ndef send_email(to: str, subject: str, body: str) -> str:\n    \"\"\"Send an email.\"\"\"\n    return f\"Sent email to {to}\"\n\n# Checkpointer is REQUIRED for human-in-the-loop\ncheckpointer = MemorySaver()\n\nagent = create_deep_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    tools=[delete_file, read_file, send_email],\n    interrupt_on={\n        \"delete_file\": True,  # Default: approve, edit, reject\n        \"read_file\": False,   # No interrupts needed\n        \"send_email\": {\"allowed_decisions\": [\"approve\", \"reject\"]},  # No editing\n    },\n    checkpointer=checkpointer  # Required!\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/human-in-the-loop",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Test writing guidelines",
        "type": "code",
        "content": "def test_document_processor_handles_empty_input():\n    \"\"\"Test processor gracefully handles empty document list.\"\"\"\n    processor = DocumentProcessor()\n\n    result = processor.process([])\n\n    assert result.success\n    assert result.processed_count == 0\n    assert len(result.errors) == 0\n",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Channels",
        "type": "text",
        "content": "Channels are used to communicate between actors (PregelNodes). Each channel has a value type, an update type, and an update function – which takes a sequence of updates and modifies the stored value. Channels can be used to send data from one chain to another, or to send data from a chain to itself in a future step. LangGraph provides a number of built-in channels:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/pregel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Runtime"
    },
    {
        "title": "SearchApi",
        "type": "text",
        "content": "SearchApi provides API access to Google search, YouTube, etc. Requires langchain-community .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "ToolStrategy",
        "type": "text",
        "content": "ToolStrategy uses artificial tool calling to generate structured output. This works with any model that supports tool calling:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Trim messages",
        "type": "text",
        "content": "Remove first or last N messages (before calling LLM)",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "LLM-as-Judge Evaluator",
        "type": "code",
        "content": "create_trajectory_llm_as_judge",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "6. View your agent in Studio",
        "type": "code",
        "content": "http://127.0.0.1:2024",
        "side_link": "https://docs.langchain.com/oss/python/langchain/studio",
        "head_menu_name": "LangChain",
        "side_menu_name": "Studio"
    },
    {
        "title": "Memory (Store)",
        "type": "text",
        "content": "Access persistent data across conversations using the store. The store is accessed via runtime.store and allows you to save and retrieve user-specific or application-specific data.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "Ollama",
        "type": "text",
        "content": "For a complete list of supported models and variants, see the Ollama model library .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/ollama",
        "head_menu_name": "Integrations",
        "side_menu_name": "Ollama"
    },
    {
        "title": "Configurable models",
        "type": "code",
        "content": "first_model = init_chat_model(\n        model=\"gpt-4.1-mini\",\n        temperature=0,\n        configurable_fields=(\"model\", \"model_provider\", \"temperature\", \"max_tokens\"),\n        config_prefix=\"first\",  # Useful when you have a chain with multiple models\n)\n\nfirst_model.invoke(\"what's your name\")\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Control the input to the subagent",
        "type": "code",
        "content": "from langchain.agents import AgentState\nfrom langchain.tools import tool, ToolRuntime\n\nclass CustomState(AgentState):\n    example_state_key: str\n\n@tool(\n    \"subagent1_name\",\n    description=\"subagent1_description\"\n)\ndef call_subagent1(query: str, runtime: ToolRuntime[None, CustomState]):\n    # Apply any logic needed to transform the messages into a suitable input\n    subagent_input = some_logic(query, runtime.state[\"messages\"])\n    result = subagent1.invoke({\n        \"messages\": subagent_input,\n        # You could also pass other state keys here as needed.\n        # Make sure to define these in both the main and subagent's\n        # state schemas.\n        \"example_state_key\": runtime.state[\"example_state_key\"]\n    })\n    return result[\"messages\"][-1].content\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/multi-agent",
        "head_menu_name": "LangChain",
        "side_menu_name": "Multi-agent"
    },
    {
        "title": "Anthropic",
        "type": "text",
        "content": "Claude models for advanced reasoning and conversation.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/all_providers",
        "head_menu_name": "Integrations",
        "side_menu_name": "All providers"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "CouchbaseSearchVectorStore",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "The general-purpose subagent",
        "type": "text",
        "content": "In addition to any user-defined subagents, deep agents have access to a general-purpose subagent at all times. This subagent:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Subagent middleware",
        "type": "text",
        "content": "A subagent is defined with a name , description , system prompt , and tools . You can also provide a subagent with a custom model , or with additional middleware . This can be particularly useful when you want to give the subagent an additional state key to share with the main agent.\n\nFor more complex use cases, you can also provide your own pre-built LangGraph graph as a subagent.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/middleware",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Google Translate",
        "type": "code",
        "content": "pip install langchain-google-community[translate]\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Azure AI Services",
        "type": "code",
        "content": "pip install azure-ai-formrecognizer azure-cognitiveservices-speech azure-ai-vision-imageanalysis\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Execution order",
        "type": "code",
        "content": "middleware1.after_agent()",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Hugging Face dataset",
        "type": "text",
        "content": "Hugging Face Hub is home to over 75,000 datasets in more than 100 languages\nthat can be used for a broad range of tasks across NLP, Computer Vision, and Audio.\nThey used for a diverse range of tasks such as translation, automatic speech\nrecognition, and image classification.\n\nWe need to install datasets python package.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Interrupts in tools",
        "type": "code",
        "content": "from langchain.tools import tool\nfrom langgraph.types import interrupt\n\n@tool\ndef send_email(to: str, subject: str, body: str):\n    \"\"\"Send an email to a recipient.\"\"\"\n\n    # Pause before sending; payload surfaces in result[\"__interrupt__\"]\n    response = interrupt({\n        \"action\": \"send_email\",\n        \"to\": to,\n        \"subject\": subject,\n        \"body\": body,\n        \"message\": \"Approve sending this email?\"\n    })\n\n    if response.get(\"action\") == \"approve\":\n        # Resume value can override inputs before executing\n        final_to = response.get(\"to\", to)\n        final_subject = response.get(\"subject\", subject)\n        final_body = response.get(\"body\", body)\n        return f\"Email sent to {final_to} with subject '{final_subject}'\"\n    return \"Email cancelled by user\"\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Modify",
        "type": "text",
        "content": "Transform prompts, tool selection, and output formatting",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Read short-term memory in a tool",
        "type": "text",
        "content": "The tool_runtime parameter is hidden from the tool signature (so the model doesn’t see it), but the tool can access the state through it.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "langchain-classic",
        "type": "text",
        "content": "Legacy functionality has moved to langchain-classic to keep the core packages lean and focused.",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Page structure",
        "type": "text",
        "content": "Every documentation page must begin with YAML frontmatter:",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "Azure ML",
        "type": "code",
        "content": "from langchain_community.llms.azureml_endpoint import AzureMLOnlineEndpoint\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "LangChain Academy",
        "type": "text",
        "content": "Courses and exercises to level up your LangChain skills.",
        "side_link": "https://docs.langchain.com/oss/python/learn",
        "head_menu_name": "Learn",
        "side_menu_name": "Learn"
    },
    {
        "title": "Document AI Warehouse",
        "type": "text",
        "content": "Requires installation of relevant Document AI packages (check specific docs).",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Connect to your agent",
        "type": "text",
        "content": "Agent Chat UI can connect to both local and deployed agents .\n\nAfter starting Agent Chat UI, you’ll need to configure it to connect to your agent:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/ui",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Agent Chat UI"
    },
    {
        "title": "Content block reference",
        "type": "text",
        "content": "The reasoning content\n\nAdditional provider-specific data\n\nExample:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Firestore (Native Mode)",
        "type": "code",
        "content": "from langchain_google_firestore import FirestoreLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Setup",
        "type": "code",
        "content": "pip install langchain_core langchain-anthropic langgraph\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/workflows-agents",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Workflows + agents"
    },
    {
        "title": "Retrievers",
        "type": "text",
        "content": "A retriever is an interface that returns documents given an unstructured query.\nIt is more general than a vector store.\nA retriever does not need to be able to store documents, only to return (or retrieve) them.\nRetrievers can be created from vector stores, but are also broad enough to include Wikipedia search and Amazon Kendra .\n\nRetrievers accept a string query as input and return a list of Documents as output.\n\nNote that all vector stores can be cast to retrievers. Refer to the vector store integration docs for available vector stores.\nThis page lists custom retrievers, implemented via subclassing BaseRetriever.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/retrievers",
        "head_menu_name": "Integrations",
        "side_menu_name": "Retrievers"
    },
    {
        "title": "Content block reference",
        "type": "text",
        "content": "The text content\n\nList of annotations for the text\n\nAdditional provider-specific data\n\nExample:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Quick edit: fix a typo",
        "type": "code",
        "content": "fix(docs): summary of change",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "Rate limiting",
        "type": "text",
        "content": "The provided rate limiter can only limit the number of requests per unit time. It will not help if you need to also limit based on the size of the requests.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "import getpass\nimport os\n\nif not os.environ.get(\"DEEPSEEK_API_KEY\"):\n  os.environ[\"DEEPSEEK_API_KEY\"] = getpass.getpass(\"Enter API key for DeepSeek: \")\n\nfrom langchain.chat_models import init_chat_model\n\nmodel = init_chat_model(\"deepseek-chat\", model_provider=\"deepseek\")\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Database",
        "type": "text",
        "content": "The following table shows tools that can be used to automate tasks in databases:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/tools",
        "head_menu_name": "Integrations",
        "side_menu_name": "Tools and toolkits"
    },
    {
        "title": "How to make your first Pull Request",
        "type": "text",
        "content": "If you start working on an issue, please assign it to yourself or ask a maintainer to do so. This helps avoid duplicate work.\n\nIf you are looking for something to work on, check out the issues labeled “good first issue” or “help wanted” in our repos:",
        "side_link": "https://docs.langchain.com/oss/python/contributing/overview",
        "head_menu_name": "Contribute",
        "side_menu_name": "Overview"
    },
    {
        "title": "Azure OpenAI",
        "type": "code",
        "content": "from langchain_openai import AzureOpenAI\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Why do agents fail?",
        "type": "text",
        "content": "When agents fail, it’s usually because the LLM call inside the agent took the wrong action / didn’t do what we expected. LLMs fail for one of two reasons:\n\nMore often than not - it’s actually the second reason that causes agents to not be reliable.\n\nContext engineering is providing the right information and tools in the right format so the LLM can accomplish a task. This is the number one job of AI Engineers. This lack of “right” context is the number one blocker for more reliable agents, and LangChain’s agent abstractions are uniquely designed to facilitate context engineering.\n\nNew to context engineering? Start with the conceptual overview to understand the different types of context and when to use them.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "How it works",
        "type": "text",
        "content": "See the astream_events() reference for event types and other details.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Local development",
        "type": "text",
        "content": "For customization or local development, you can run Agent Chat UI locally:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/ui",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agent Chat UI"
    },
    {
        "title": "Microsoft OneDrive",
        "type": "code",
        "content": "from langchain_community.document_loaders import OneDriveLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Human-in-the-loop",
        "type": "text",
        "content": "Static string or callable function for custom description\n\nImportant: Human-in-the-loop middleware requires a checkpointer to maintain state across interruptions.\n\nSee the human-in-the-loop documentation for complete examples and integration patterns.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Initialize a model",
        "type": "code",
        "content": "response = model.invoke(\"Why do parrots talk?\")\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Monitor",
        "type": "text",
        "content": "Track agent behavior with logging, analytics, and debugging",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "DatabricksVectorSearch",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Google Jobs",
        "type": "code",
        "content": "from langchain_community.tools.google_jobs import GoogleJobsQueryRun\n# Note: Utilities might be shared, e.g., GoogleFinanceAPIWrapper was listed, verify correct utility\n# from langchain_community.utilities.google_jobs import GoogleJobsAPIWrapper # If exists\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Case Studies",
        "type": "text",
        "content": "See how teams are using LangChain and LangGraph in production.\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/learn",
        "head_menu_name": "Learn",
        "side_menu_name": "Learn"
    },
    {
        "title": "Document AI",
        "type": "text",
        "content": "Google Cloud Document AI is a Google Cloud\nservice that transforms unstructured data from documents into structured data, making it easier\nto understand, analyze, and consume.\n\nWe need to set up a GCS bucket and create your own OCR processor The GCS_OUTPUT_PATH should be a path to a folder on GCS (starting with gs:// )\nand a processor name should look like projects/PROJECT_NUMBER/locations/LOCATION/processors/PROCESSOR_ID .\nWe can get it either programmatically or copy from the Prediction endpoint section of the Processor details tab in the Google Cloud Console.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "LangSmith Integration",
        "type": "text",
        "content": "Results will be automatically logged to LangSmith.\n\nTo learn more about evaluating your agent, see the LangSmith docs .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Dynamically selecting tools",
        "type": "code",
        "content": "from dataclasses import dataclass\nfrom typing import Literal, Callable\n\nfrom langchain.agents import create_agent\nfrom langchain.agents.middleware import AgentMiddleware, ModelRequest, ModelResponse\nfrom langchain_core.tools import tool\n\n\n@tool\ndef github_create_issue(repo: str, title: str) -> dict:\n    \"\"\"Create an issue in a GitHub repository.\"\"\"\n    return {\"url\": f\"https://github.com/{repo}/issues/1\", \"title\": title}\n\n@tool\ndef gitlab_create_issue(project: str, title: str) -> dict:\n    \"\"\"Create an issue in a GitLab project.\"\"\"\n    return {\"url\": f\"https://gitlab.com/{project}/-/issues/1\", \"title\": title}\n\nall_tools = [github_create_issue, gitlab_create_issue]\n\n@dataclass\nclass Context:\n    provider: Literal[\"github\", \"gitlab\"]\n\nclass ToolSelectorMiddleware(AgentMiddleware):\n    def wrap_model_call(\n        self,\n        request: ModelRequest,\n        handler: Callable[[ModelRequest], ModelResponse],\n    ) -> ModelResponse:\n        \"\"\"Select tools based on the VCS provider.\"\"\"\n        provider = request.runtime.context.provider\n\n        if provider == \"gitlab\":\n            selected_tools = [t for t in request.tools if t.name == \"gitlab_create_issue\"]\n        else:\n            selected_tools = [t for t in request.tools if t.name == \"github_create_issue\"]\n\n        request.tools = selected_tools\n        return handler(request)\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=all_tools,\n    middleware=[ToolSelectorMiddleware()],\n    context_schema=Context,\n)\n\n# Invoke with GitHub context\nagent.invoke(\n    {\n        \"messages\": [{\"role\": \"user\", \"content\": \"Open an issue titled 'Bug: where are the cats' in the repository `its-a-cats-game`\"}]\n    },\n    context=Context(provider=\"github\"),\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Standard content blocks",
        "type": "code",
        "content": "[{'type': 'reasoning',\n  'reasoning': '...',\n  'extras': {'signature': 'WaUjzkyp...'}},\n {'type': 'text', 'text': '...'}]\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Google Finance",
        "type": "code",
        "content": "from langchain_community.tools.google_finance import GoogleFinanceQueryRun\nfrom langchain_community.utilities.google_finance import GoogleFinanceAPIWrapper\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "MongoDBAtlasVectorSearch",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "SystemMessageto string",
        "type": "code",
        "content": "from langchain.agents import create_agent\n\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    tools=[check_weather],\n    system_prompt=\"You are a helpful assistant\"\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Microsoft OneDrive",
        "type": "text",
        "content": "Microsoft OneDrive (formerly SkyDrive ) is a file-hosting service operated by Microsoft.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Deep Agents overview",
        "type": "text",
        "content": "deepagents is a standalone library for building agents that can tackle complex, multi-step tasks. Built on LangGraph and inspired by applications like Claude Code, Deep Research, and Manus, deep agents come with planning capabilities, file systems for context management, and the ability to spawn subagents.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/overview",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Overview"
    },
    {
        "title": "Log to a project",
        "type": "text",
        "content": "You can set a custom project name for your entire application by setting the LANGSMITH_PROJECT environment variable:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/observability",
        "head_menu_name": "LangChain",
        "side_menu_name": "Observability"
    },
    {
        "title": "Use in production",
        "type": "code",
        "content": "from langchain.chat_models import init_chat_model\nfrom langgraph.graph import StateGraph, MessagesState, START\nfrom langgraph.checkpoint.redis import RedisSaver  \n\nmodel = init_chat_model(model=\"claude-haiku-4-5-20251001\")\n\nDB_URI = \"redis://localhost:6379\"\nwith RedisSaver.from_conn_string(DB_URI) as checkpointer:  \n    # checkpointer.setup()\n\n    def call_model(state: MessagesState):\n        response = model.invoke(state[\"messages\"])\n        return {\"messages\": response}\n\n    builder = StateGraph(MessagesState)\n    builder.add_node(call_model)\n    builder.add_edge(START, \"call_model\")\n\n    graph = builder.compile(checkpointer=checkpointer)  \n\n    config = {\n        \"configurable\": {\n            \"thread_id\": \"1\"\n        }\n    }\n\n    for chunk in graph.stream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"hi! I'm bob\"}]},\n        config,  \n        stream_mode=\"values\"\n    ):\n        chunk[\"messages\"][-1].pretty_print()\n\n    for chunk in graph.stream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what's my name?\"}]},\n        config,  \n        stream_mode=\"values\"\n    ):\n        chunk[\"messages\"][-1].pretty_print()\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Testing and validation",
        "type": "code",
        "content": "make lint\nmake format\n",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "Configurable models",
        "type": "text",
        "content": "We can create a configurable model with default model values, specify which parameters are configurable, and add prefixes to configurable params:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Featured providers",
        "type": "code",
        "content": "langchain-google-genai",
        "side_link": "https://docs.langchain.com/oss/python/integrations/chat",
        "head_menu_name": "Integrations",
        "side_menu_name": "Chat models"
    },
    {
        "title": "Error handling strategies",
        "type": "code",
        "content": "ToolStrategy(\n    schema=ProductRating,\n    handle_errors=(ValueError, TypeError)  # Retry on ValueError and TypeError\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Short-term vs. long-term filesystem",
        "type": "text",
        "content": "By default, these tools write to a local “filesystem” in your graph state. If you provide a Store object to your agent runtime, you can also enable saving to long-term memory, which persists across different threads of your agent.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/middleware",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Evaluator-optimizer",
        "type": "text",
        "content": "In evaluator-optimizer workflows, one LLM call creates a response and the other evaluates that response. If the evaluator or a human-in-the-loop determines the response needs refinement, feedback is provided and the response is recreated. This loop continues until an acceptable response is generated.\n\nEvaluator-optimizer workflows are commonly used when there’s particular success criteria for a task, but iteration is required to meet that criteria. For example, there’s not always a perfect match when translating text between two languages. It might take a few iterations to generate a translation with the same meaning across the two languages.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/workflows-agents",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Workflows + agents"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "pip install -qU langchain-voyageai\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Anthropic prompt caching",
        "type": "text",
        "content": "Time to live for cached content. Valid values: \"5m\" or \"1h\"",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Response Format",
        "type": "code",
        "content": "ProviderStrategy[StructuredResponseT]",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Invoke",
        "type": "text",
        "content": "A list of messages can be provided to a model to represent conversation history. Each message has a role that models use to indicate who sent the message in the conversation. See the messages guide for more detail on roles, types, and content.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "LLM tokens",
        "type": "code",
        "content": "from langchain.agents import create_agent\n\n\ndef get_weather(city: str) -> str:\n    \"\"\"Get weather for a given city.\"\"\"\n\n    return f\"It's always sunny in {city}!\"\n\nagent = create_agent(\n    model=\"gpt-5-nano\",\n    tools=[get_weather],\n)\nfor token, metadata in agent.stream(  \n    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n    stream_mode=\"messages\",\n):\n    print(f\"node: {metadata['langgraph_node']}\")\n    print(f\"content: {token.content_blocks}\")\n    print(\"\\n\")\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/streaming",
        "head_menu_name": "LangChain",
        "side_menu_name": "Streaming"
    },
    {
        "title": "System prompt",
        "type": "code",
        "content": "agent = create_agent(\n    model,\n    tools,\n    system_prompt=\"You are a helpful assistant. Be concise and accurate.\"\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Writes",
        "type": "text",
        "content": "See Tools for comprehensive examples of accessing state, store, and runtime context in tools.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Tools",
        "type": "text",
        "content": "The tools argument to create_agent accepts a list of:",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Determinism and Consistent Replay",
        "type": "text",
        "content": "When you resume a workflow run, the code does NOT resume from the same line of code where execution stopped; instead, it will identify an appropriate starting point from which to pick up where it left off. This means that the workflow will replay all steps from the starting point until it reaches the point where it was stopped.\n\nAs a result, when you are writing a workflow for durable execution, you must wrap any non-deterministic operations (e.g., random number generation) and any operations with side effects (e.g., file writes, API calls) inside tasks or nodes .\n\nTo ensure that your workflow is deterministic and can be consistently replayed, follow these guidelines:\n\nFor some examples of pitfalls to avoid, see the Common Pitfalls section in the functional API, which shows\nhow to structure your code using tasks to avoid these issues. The same principles apply to the StateGraph (Graph API) .",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/durable-execution",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Durable execution"
    },
    {
        "title": "Testing requirements",
        "type": "code",
        "content": "make integration_tests\n",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "create_react_agent→create_agent",
        "type": "text",
        "content": "LangGraph v1 deprecates the create_react_agent prebuilt. Use LangChain’s create_agent , which runs on LangGraph and adds a flexible middleware system.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langgraph-v1",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Persistent context",
        "type": "text",
        "content": "What gets saved in state across turns. Life-cycle hooks and tool writes modify this permanently.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "6. Build and compile the agent",
        "type": "text",
        "content": "To learn how to trace your agent with LangSmith, see the LangSmith documentation .\n\nCongratulations! You’ve built your first agent using the LangGraph Graph API.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/quickstart",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "import getpass\nimport os\n\nif not os.environ.get(\"NOMIC_API_KEY\"):\n  os.environ[\"NOMIC_API_KEY\"] = getpass.getpass(\"Enter API key for Nomic: \")\n\nfrom langchain_nomic import NomicEmbeddings\n\nembeddings = NomicEmbeddings(model=\"nomic-embed-text-v1.5\")\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "5. Test the API",
        "type": "text",
        "content": "LangSmith offers additional hosting options, including self-hosted and hybrid. For more information, please see the Platform setup overview .\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/deploy",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Deploy"
    },
    {
        "title": "Custom state schema",
        "type": "code",
        "content": "from langchain.agents.middleware import AgentState, AgentMiddleware\nfrom typing_extensions import NotRequired\nfrom typing import Any\n\nclass CustomState(AgentState):\n    model_call_count: NotRequired[int]\n    user_id: NotRequired[str]\n\nclass CallCounterMiddleware(AgentMiddleware[CustomState]):\n    state_schema = CustomState\n\n    def before_model(self, state: CustomState, runtime) -> dict[str, Any] | None:\n        # Access custom state properties\n        count = state.get(\"model_call_count\", 0)\n\n        if count > 10:\n            return {\"jump_to\": \"end\"}\n\n        return None\n\n    def after_model(self, state: CustomState, runtime) -> dict[str, Any] | None:\n        # Update custom state\n        return {\"model_call_count\": state.get(\"model_call_count\", 0) + 1}\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Running tests locally",
        "type": "text",
        "content": "All type hints must be valid\n\nPush your branch and open a pull request. Follow the provided form template. Note related issues using a closing keyword . After submitting, wait, and check to ensure the CI checks pass. If any checks fail, address the issues promptly - maintainers may close PRs that do not pass CI within a reasonable timeframe.",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Chat models",
        "type": "text",
        "content": "The image_url can be a public URL, a GCS URI ( gs://... ), a local file path, a base64 encoded image string ( data:image/png;base64,... ), or a PIL Image object.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Invocation config",
        "type": "text",
        "content": "These configuration values are particularly useful when:\n\nIdentifies this specific invocation in logs and traces. Not inherited by sub-calls.\n\nLabels inherited by all sub-calls for filtering and organization in debugging tools.\n\nCustom key-value pairs for tracking additional context, inherited by all sub-calls.\n\nControls the maximum number of parallel calls when using batch() or batch_as_completed() .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Amazon Textract",
        "type": "text",
        "content": "Amazon Textract is a machine\nlearning (ML) service that automatically extracts text, handwriting, and data from scanned documents.\n\nSee a usage example .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Text content",
        "type": "code",
        "content": "response = model.invoke([\n  HumanMessage(\"What is machine learning?\")\n])\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Implementation (Coming soon)",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/multi-agent",
        "head_menu_name": "LangChain",
        "side_menu_name": "Multi-agent"
    },
    {
        "title": "No automatic cleanup",
        "type": "text",
        "content": "Long-term files persist indefinitely. There’s no built-in TTL or automatic cleanup. You’ll need to implement cleanup strategies if needed.\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Cloud SQL for MySQL",
        "type": "code",
        "content": "from langchain_google_cloud_sql_mysql import MySQLLoader # MySQLEngine also available\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Human-in-the-loop",
        "type": "text",
        "content": "See the human-in-the-loop documentation for complete details on implementing approval workflows.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/guardrails",
        "head_menu_name": "LangChain",
        "side_menu_name": "Guardrails"
    },
    {
        "title": "Tutorials (Learn)",
        "type": "text",
        "content": "Lessons that guide users through practical activities to build understanding",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "Vertex AI image editor",
        "type": "code",
        "content": "from langchain_google_vertexai.vision_models import VertexAIImageEditorChat\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Memory",
        "type": "text",
        "content": "Second, checkpointers allow for “memory” between interactions. In the case of repeated human interactions (like conversations) any follow up messages can be sent to that thread, which will retain its memory of previous ones. See Add memory for information on how to add and manage conversation memory using checkpointers.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Use in production",
        "type": "code",
        "content": "pip install -U pymongo langgraph langgraph-checkpoint-mongodb\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Quickstart",
        "type": "code",
        "content": "agent = create_deep_agent()",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Subagent middleware",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom deepagents.middleware.subagents import SubAgentMiddleware\nfrom deepagents import CompiledSubAgent\nfrom langgraph.graph import StateGraph\n\n# Create a custom LangGraph graph\ndef create_weather_graph():\n    workflow = StateGraph(...)\n    # Build your custom graph\n    return workflow.compile()\n\nweather_graph = create_weather_graph()\n\n# Wrap it in a CompiledSubAgent\nweather_subagent = CompiledSubAgent(\n    name=\"weather\",\n    description=\"This subagent can get weather in cities.\",\n    runnable=weather_graph\n)\n\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    middleware=[\n        SubAgentMiddleware(\n            default_model=\"claude-sonnet-4-5-20250929\",\n            default_tools=[],\n            subagents=[weather_subagent],\n        )\n    ],\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/middleware",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Azure AI Services individual tools",
        "type": "code",
        "content": "AzureCogsImageAnalysisTool",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Dynamic model selection",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import (\n    AgentMiddleware, ModelRequest, ModelRequestHandler\n)\nfrom langchain.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\n\nbasic_model = ChatOpenAI(model=\"gpt-5-nano\")\nadvanced_model = ChatOpenAI(model=\"gpt-5\")\n\nclass DynamicModelMiddleware(AgentMiddleware):\n\n    def wrap_model_call(self, request: ModelRequest, handler: ModelRequestHandler) -> AIMessage:\n        if len(request.state.messages) > self.messages_threshold:\n            model = advanced_model\n        else:\n            model = basic_model\n\n        return handler(request.replace(model=model))\n\n    def __init__(self, messages_threshold: int) -> None:\n        self.messages_threshold = messages_threshold\n\nagent = create_agent(\n    model=basic_model,\n    tools=tools,\n    middleware=[DynamicModelMiddleware(messages_threshold=10)]\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Protocol reference",
        "type": "code",
        "content": "WriteResult(error=...)",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Microsoft Excel",
        "type": "code",
        "content": "from langchain_community.document_loaders import UnstructuredExcelLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Integration packages",
        "type": "text",
        "content": "LangChain Python offers an extensive ecosystem with 1000+ integrations across chat & embedding models, tools & toolkits, document loaders, vector stores, and more.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/overview",
        "head_menu_name": "Integrations",
        "side_menu_name": "Overview"
    },
    {
        "title": "Deploy",
        "type": "text",
        "content": "LangSmith is the fastest way to turn agents into production systems. Traditional hosting platforms are built for stateless, short-lived web apps, while LangGraph is purpose-built for stateful, long-running agents , so you can go from repo to reliable cloud deployment in minutes.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/deploy",
        "head_menu_name": "LangChain",
        "side_menu_name": "Deploy"
    },
    {
        "title": "Build a real-world agent",
        "type": "code",
        "content": "from langgraph.checkpoint.memory import InMemorySaver\n\ncheckpointer = InMemorySaver()\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/quickstart",
        "head_menu_name": "LangChain",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "LangGraph",
        "type": "code",
        "content": "This issue is blocked by #123 and related to #456.\n",
        "side_link": "https://docs.langchain.com/oss/python/contributing/overview",
        "head_menu_name": "Contribute",
        "side_menu_name": "Overview"
    },
    {
        "title": "Stream subgraph outputs",
        "type": "code",
        "content": "for chunk in graph.stream(\n    {\"foo\": \"foo\"},\n    subgraphs=True, \n    stream_mode=\"updates\",\n):\n    print(chunk)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-subgraphs",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Subgraphs"
    },
    {
        "title": "Token usage",
        "type": "text",
        "content": "Some provider APIs, notably OpenAI and Azure OpenAI chat completions, require users opt-in to receiving token usage data in streaming contexts. See the streaming usage metadata section of the integration guide for details.\n\nYou can track aggregate token counts across models in an application using either a callback or context manager, as shown below:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Bring-your-own documents",
        "type": "code",
        "content": "langchain-google-community",
        "side_link": "https://docs.langchain.com/oss/python/integrations/retrievers",
        "head_menu_name": "Integrations",
        "side_menu_name": "Retrievers"
    },
    {
        "title": "Keep state raw, format prompts on-demand",
        "type": "text",
        "content": "A key principle: your state should store raw data, not formatted text. Format prompts inside nodes when you need them.\n\nThis separation means:\n\nLet’s define our state:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Examples",
        "type": "code",
        "content": "from langgraph.channels import EphemeralValue\nfrom langgraph.pregel import Pregel, NodeBuilder\n\nnode1 = (\n    NodeBuilder().subscribe_only(\"a\")\n    .do(lambda x: x + x)\n    .write_to(\"b\")\n)\n\napp = Pregel(\n    nodes={\"node1\": node1},\n    channels={\n        \"a\": EphemeralValue(str),\n        \"b\": EphemeralValue(str),\n    },\n    input_channels=[\"a\"],\n    output_channels=[\"b\"],\n)\n\napp.invoke({\"a\": \"foo\"})\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/pregel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Runtime"
    },
    {
        "title": "Reference",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/overview",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Overview"
    },
    {
        "title": "Setup",
        "type": "text",
        "content": "Next, we need to set API keys for Anthropic (the LLM we will use)",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-time-travel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Time travel"
    },
    {
        "title": "Threads",
        "type": "text",
        "content": "A thread’s current and historical state can be retrieved. To persist state, a thread must be created prior to executing a run. The LangSmith API provides several endpoints for creating and managing threads and thread state. See the API reference for more details.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Co-marketing",
        "type": "text",
        "content": "With over 60 million monthly downloads, LangChain has a large audience of developers building LLM applications. Beyond just listing integrations, we aim to highlight high-quality, educational examples that inspire developers and advance the ecosystem.\n\nWhile we occasionally share integrations, we prioritize content that provides\nmeaningful insights and best practices. Our main social channels are Twitter and LinkedIn , where we highlight the best examples.",
        "side_link": "https://docs.langchain.com/oss/python/contributing/comarketing",
        "head_menu_name": "Contribute",
        "side_menu_name": "Co-marketing"
    },
    {
        "title": "Invoke a graph from a node",
        "type": "code",
        "content": "((), {'parent_1': {'my_key': 'hi Bob'}})\n(('child:2e26e9ce-602f-862c-aa66-1ea5a4655e3b', 'child_1:781bb3b1-3971-84ce-810b-acf819a03f9c'), {'grandchild_1': {'my_grandchild_key': 'hi Bob, how are you'}})\n(('child:2e26e9ce-602f-862c-aa66-1ea5a4655e3b',), {'child_1': {'my_child_key': 'hi Bob, how are you today?'}})\n((), {'child': {'my_key': 'hi Bob, how are you today?'}})\n((), {'parent_2': {'my_key': 'hi Bob, how are you today? bye!'}})\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-subgraphs",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Subgraphs"
    },
    {
        "title": "Gemma on Vertex AI Model Garden",
        "type": "code",
        "content": "langchain-google-vertexai",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Manage short-term memory",
        "type": "text",
        "content": "Conversation history is the most common form of short-term memory, and long conversations pose a challenge to today’s LLMs. A full history may not fit inside an LLM’s context window, resulting in an irrecoverable error. Even if your LLM supports the full context length, most LLMs still perform poorly over long contexts. They get “distracted” by stale or off-topic content, all while suffering from slower response times and higher costs.\n\nChat models accept context using messages, which include developer provided instructions (a system message) and user inputs (human messages). In chat applications, messages alternate between human inputs and model responses, resulting in a list of messages that grows longer over time. Because context windows are limited and token-rich message lists can be costly, many applications can benefit from using techniques to manually remove or forget stale information.\n\nFor more information on common techniques for managing messages, see the Add and manage memory guide.",
        "side_link": "https://docs.langchain.com/oss/python/concepts/memory",
        "head_menu_name": "Learn",
        "side_menu_name": "Memory"
    },
    {
        "title": "Delete messages",
        "type": "text",
        "content": "When deleting messages, make sure that the resulting message history is valid. Check the limitations of the LLM provider you’re using. For example:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Isolate storage by assistant ID",
        "type": "code",
        "content": "config = {\n    \"configurable\": {\n        \"thread_id\": \"thread-123\",\n    },\n    \"metadata\": {\n        \"assistant_id\": \"user-456\"  # Namespace isolation\n    }\n}\n\nagent.invoke({\"messages\": [...]}, config=config)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Planning",
        "type": "text",
        "content": "Custom system prompt for guiding todo usage. Uses built-in prompt if not specified.\n\nCustom description for the write_todos tool. Uses built-in description if not specified.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Post-model hook",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import HumanInTheLoopMiddleware\n\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    tools=[read_email, send_email],\n    middleware=[HumanInTheLoopMiddleware(\n        interrupt_on={\n            \"send_email\": True,\n            \"description\": \"Please review this email before sending\"\n        },\n    )]\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Built on LangGraph",
        "type": "text",
        "content": "Because create_agent is built on LangGraph , you automatically get built in support for long running and reliable agents via:",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Observability",
        "type": "text",
        "content": "Add observability with LangSmith for debugging and monitoring",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Custom state",
        "type": "text",
        "content": "Defining custom state via middleware is preferred over defining it via state_schema on create_agent because it allows you to keep state extensions conceptually scoped to the relevant middleware and tools.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Office 365 individual tools",
        "type": "code",
        "content": "from langchain_community.tools.office365 import O365CreateDraftMessage\nfrom langchain_community.tools.office365 import O365SearchEmails\nfrom langchain_community.tools.office365 import O365SearchEvents\nfrom langchain_community.tools.office365 import O365SendEvent\nfrom langchain_community.tools.office365 import O365SendMessage\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Use in production",
        "type": "code",
        "content": "from langgraph.checkpoint.postgres import PostgresSaver\n\nDB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\nwith PostgresSaver.from_conn_string(DB_URI) as checkpointer:  \n    builder = StateGraph(...)\n    graph = builder.compile(checkpointer=checkpointer)  \n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Deprecations",
        "type": "code",
        "content": "AgentStateWithStructuredResponse",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langgraph-v1",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Streaming and chunks",
        "type": "text",
        "content": "During streaming, you’ll receive AIMessageChunk objects that can be combined into a full message object:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Microsoft Word",
        "type": "code",
        "content": "from langchain_community.document_loaders import UnstructuredWordDocumentLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Amazon Neptune with SPARQL",
        "type": "code",
        "content": "from langchain_aws.graphs import NeptuneRdfGraph\nfrom langchain_aws.chains import create_neptune_sparql_qa_chain\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Try out your agent",
        "type": "text",
        "content": "Let’s run our agent with an urgent billing issue that needs human review:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Tool calls",
        "type": "text",
        "content": "Other structured data, such as reasoning or citations, can also appear in message content .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Wrong subagent being selected",
        "type": "code",
        "content": "subagents = [\n    {\n        \"name\": \"quick-researcher\",\n        \"description\": \"For simple, quick research questions that need 1-2 searches. Use when you need basic facts or definitions.\",\n    },\n    {\n        \"name\": \"deep-researcher\",\n        \"description\": \"For complex, in-depth research requiring multiple searches, synthesis, and analysis. Use for comprehensive reports.\",\n    }\n]\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Stream",
        "type": "text",
        "content": "The resulting message can be treated the same as a message that was generated with invoke() - for example, it can be aggregated into a message history and passed back to the model as conversational context.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Messages",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\nfrom typing import Callable\n\n@wrap_model_call\ndef inject_file_context(\n    request: ModelRequest,\n    handler: Callable[[ModelRequest], ModelResponse]\n) -> ModelResponse:\n    \"\"\"Inject context about files user has uploaded this session.\"\"\"\n    # Read from State: get uploaded files metadata\n    uploaded_files = request.state.get(\"uploaded_files\", [])  \n\n    if uploaded_files:\n        # Build context about available files\n        file_descriptions = []\n        for file in uploaded_files:\n            file_descriptions.append(\n                f\"- {file['name']} ({file['type']}): {file['summary']}\"\n            )\n\n        file_context = f\"\"\"Files you have access to in this conversation:\n{chr(10).join(file_descriptions)}\n\nReference these files when answering questions.\"\"\"\n\n        # Inject file context before recent messages\n        messages = [  \n            *request.messages,\n            {\"role\": \"user\", \"content\": file_context},\n        ]\n        request = request.override(messages=messages)  \n\n    return handler(request)\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[...],\n    middleware=[inject_file_context]\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "ChatGPTPluginRetriever",
        "type": "text",
        "content": "Retrieve real-time information; e.g., sports scores, stock prices, the latest news, etc.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/openai",
        "head_menu_name": "Integrations",
        "side_menu_name": "OpenAI"
    },
    {
        "title": "ProviderStrategy",
        "type": "code",
        "content": "from langchain.agents.structured_output import ProviderStrategy\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    response_format=ProviderStrategy(ContactInfo)\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Cloud SQL for MySQL",
        "type": "text",
        "content": "Google Cloud SQL for MySQL is a fully-managed MySQL database service.\n\nInstall the python package:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Tool calling",
        "type": "code",
        "content": "model_with_tools = model.bind_tools([tool_1], tool_choice=\"any\")\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Deprecations",
        "type": "code",
        "content": "langchain.agents.create_agent",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langgraph-v1",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Chat Completions API",
        "type": "code",
        "content": "from langchain_openai import ChatOpenAI\n\nmodel = ChatOpenAI(\n    model=\"...\",  # Specify a model available on OpenRouter\n    api_key=\"OPENROUTER_API_KEY\",\n    base_url=\"https://openrouter.ai/api/v1\",\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/chat",
        "head_menu_name": "Integrations",
        "side_menu_name": "Chat models"
    },
    {
        "title": "Deprecations",
        "type": "code",
        "content": "langchain.agents.middleware.human_in_the_loop.InterruptOnConfig",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langgraph-v1",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Pause usinginterrupt",
        "type": "code",
        "content": "from langgraph.types import interrupt\n\ndef approval_node(state: State):\n    # Pause and ask for approval\n    approved = interrupt(\"Do you approve this action?\")\n\n    # When you resume, Command(resume=...) returns that value here\n    return {\"approved\": approved}\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Use the same thread ID",
        "type": "code",
        "content": "# First call\nconfig = {\"configurable\": {\"thread_id\": \"my-thread\"}}\nresult = agent.invoke(input, config=config)\n\n# Resume (use same config)\nresult = agent.invoke(Command(resume={...}), config=config)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/human-in-the-loop",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Handle interrupts",
        "type": "text",
        "content": "When an interrupt is triggered, the agent pauses execution and returns control. Check for interrupts in the result and handle them accordingly.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/human-in-the-loop",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Recording & Replaying HTTP Calls",
        "type": "text",
        "content": "Integration tests that call real LLM APIs can be slow and expensive, especially when run frequently in CI/CD pipelines. We recommend using a library for recording HTTP requests and responses, then replaying them in subsequent runs without making actual network calls.\n\nYou can use vcrpy to achieve this. If you’re using pytest , the pytest-recording plugin provides a simple way to enable this with minimal configuration. Request/responses are recorded in cassettes, which are then used to mock the real network calls in subsequent runs.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Gmail",
        "type": "code",
        "content": "# Load the whole toolkit\nfrom langchain_google_community import GmailToolkit\n\n# Or use individual tools\nfrom langchain_google_community.gmail.create_draft import GmailCreateDraft\nfrom langchain_google_community.gmail.get_message import GmailGetMessage\nfrom langchain_google_community.gmail.get_thread import GmailGetThread\nfrom langchain_google_community.gmail.search import GmailSearch\nfrom langchain_google_community.gmail.send_message import GmailSendMessage\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Agent progress",
        "type": "code",
        "content": "stream_mode=\"updates\"",
        "side_link": "https://docs.langchain.com/oss/python/langchain/streaming",
        "head_menu_name": "LangChain",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Google Search",
        "type": "code",
        "content": "from langchain_google_community import GoogleSearchAPIWrapper\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Provider strategy",
        "type": "code",
        "content": "create_agent.response_format",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Google Drive",
        "type": "code",
        "content": "from langchain_google_community import GoogleDriveLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Vertex AI Search",
        "type": "text",
        "content": "Install the google-cloud-discoveryengine package for underlying access.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Zotero",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/retrievers",
        "head_menu_name": "Integrations",
        "side_menu_name": "Retrievers"
    },
    {
        "title": "Use MCP tools",
        "type": "code",
        "content": "from langchain_mcp_adapters.client import MultiServerMCPClient  \nfrom langchain.agents import create_agent\n\n\nclient = MultiServerMCPClient(  \n    {\n        \"math\": {\n            \"transport\": \"stdio\",  # Local subprocess communication\n            \"command\": \"python\",\n            # Absolute path to your math_server.py file\n            \"args\": [\"/path/to/math_server.py\"],\n        },\n        \"weather\": {\n            \"transport\": \"streamable_http\",  # HTTP-based remote server\n            # Ensure you start your weather server on port 8000\n            \"url\": \"http://localhost:8000/mcp\",\n        }\n    }\n)\n\ntools = await client.get_tools()  \nagent = create_agent(\n    \"claude-sonnet-4-5-20250929\",\n    tools  \n)\nmath_response = await agent.ainvoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what's (3 + 5) x 12?\"}]}\n)\nweather_response = await agent.ainvoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in nyc?\"}]}\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/mcp",
        "head_menu_name": "LangChain",
        "side_menu_name": "Model Context Protocol (MCP)"
    },
    {
        "title": "Memory storage",
        "type": "text",
        "content": "LangGraph stores long-term memories as JSON documents in a store .\n\nEach memory is organized under a custom namespace (similar to a folder) and a distinct key (like a file name). Namespaces often include user or org IDs or other labels that makes it easier to organize information.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/long-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Start with the process you want to automate",
        "type": "text",
        "content": "Imagine that you need to build an AI agent that handles customer support emails. Your product team has given you these requirements:\n\nThe agent should:\n\nExample scenarios to handle:\n\nTo implement an agent in LangGraph, you will usually follow the same five steps.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "VertexStringEvaluator",
        "type": "text",
        "content": "Evaluate a single prediction string using Vertex AI models.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Defining state viastate_schema",
        "type": "text",
        "content": "Use the state_schema parameter when your custom state needs to be accessed by tools:",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "LLM tool selector",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import LLMToolSelectorMiddleware\n\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[tool1, tool2, tool3, tool4, tool5, ...],  # Many tools\n    middleware=[\n        LLMToolSelectorMiddleware(\n            model=\"gpt-4o-mini\",  # Use cheaper model for selection\n            max_tools=3,  # Limit to 3 most relevant tools\n            always_include=[\"search\"],  # Always include certain tools\n        ),\n    ],\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Basic Usage",
        "type": "code",
        "content": "from langgraph.store.memory import InMemoryStore\nin_memory_store = InMemoryStore()\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Firestore (Datastore Mode)",
        "type": "code",
        "content": "from langchain_google_datastore import DatastoreLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "LangChain overview",
        "type": "text",
        "content": "LangChain v1.0 is now available!\n\nFor a complete list of changes and instructions on how to upgrade your code, see the release notes and migration guide .\n\nIf you encounter any issues or have feedback, please open an issue so we can improve. To view v0.x documentation, go to the archived content .\n\nLangChain is the easiest way to start building agents and applications powered by LLMs. With under 10 lines of code, you can connect to OpenAI, Anthropic, Google, and more . LangChain provides a pre-built agent architecture and model integrations to help you get started quickly and seamlessly incorporate LLMs into your agents and applications.\n\nWe recommend you use LangChain if you want to quickly build agents and autonomous applications. Use LangGraph , our low-level agent orchestration framework and runtime, when you have more advanced needs that require a combination of deterministic and agentic workflows, heavy customization, and carefully controlled latency.\n\nLangChain agents are built on top of LangGraph in order to provide durable execution, streaming, human-in-the-loop, persistence, and more. You do not need to know LangGraph for basic LangChain agent usage.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/overview",
        "head_menu_name": "LangChain",
        "side_menu_name": "Overview"
    },
    {
        "title": "Invoke a graph from a node",
        "type": "code",
        "content": "from typing_extensions import TypedDict\nfrom langgraph.graph.state import StateGraph, START\n\n# Define subgraph\nclass SubgraphState(TypedDict):\n    # note that none of these keys are shared with the parent graph state\n    bar: str\n    baz: str\n\ndef subgraph_node_1(state: SubgraphState):\n    return {\"baz\": \"baz\"}\n\ndef subgraph_node_2(state: SubgraphState):\n    return {\"bar\": state[\"bar\"] + state[\"baz\"]}\n\nsubgraph_builder = StateGraph(SubgraphState)\nsubgraph_builder.add_node(subgraph_node_1)\nsubgraph_builder.add_node(subgraph_node_2)\nsubgraph_builder.add_edge(START, \"subgraph_node_1\")\nsubgraph_builder.add_edge(\"subgraph_node_1\", \"subgraph_node_2\")\nsubgraph = subgraph_builder.compile()\n\n# Define parent graph\nclass ParentState(TypedDict):\n    foo: str\n\ndef node_1(state: ParentState):\n    return {\"foo\": \"hi! \" + state[\"foo\"]}\n\ndef node_2(state: ParentState):\n    # Transform the state to the subgraph state\n    response = subgraph.invoke({\"bar\": state[\"foo\"]})\n    # Transform response back to the parent state\n    return {\"foo\": response[\"bar\"]}\n\n\nbuilder = StateGraph(ParentState)\nbuilder.add_node(\"node_1\", node_1)\nbuilder.add_node(\"node_2\", node_2)\nbuilder.add_edge(START, \"node_1\")\nbuilder.add_edge(\"node_1\", \"node_2\")\ngraph = builder.compile()\n\nfor chunk in graph.stream({\"foo\": \"foo\"}, subgraphs=True):\n    print(chunk)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-subgraphs",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Subgraphs"
    },
    {
        "title": "Build a real-world agent",
        "type": "code",
        "content": "SYSTEM_PROMPT = \"\"\"You are an expert weather forecaster, who speaks in puns.\n\nYou have access to two tools:\n\n- get_weather_for_location: use this to get the weather for a specific location\n- get_user_location: use this to get the user's location\n\nIf a user asks you for the weather, make sure you know the location. If you can tell from the question that they mean wherever they are, use the get_user_location tool to find their location.\"\"\"\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/quickstart",
        "head_menu_name": "LangChain",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Amazon OpenSearch Service",
        "type": "code",
        "content": "OpenSearch Dashboards",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Mocking Chat Model",
        "type": "text",
        "content": "If we invoke the model again, it will return the next item in the iterator:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "After agent guardrails",
        "type": "text",
        "content": "Use “after agent” hooks to validate final outputs once before returning to the user. This is useful for model-based safety checks, quality validation, or final compliance scans on the complete agent response.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/guardrails",
        "head_menu_name": "LangChain",
        "side_menu_name": "Guardrails"
    },
    {
        "title": "Durability modes",
        "type": "code",
        "content": "checkpoint_during=True",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/durable-execution",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Durable execution"
    },
    {
        "title": "Configuring interrupts",
        "type": "text",
        "content": "To use HITL, add the middleware to the agent’s middleware list when creating the agent.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/human-in-the-loop",
        "head_menu_name": "LangChain",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Stream graph state",
        "type": "text",
        "content": "Use the stream modes updates and values to stream the state of the graph as it executes.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Middleware",
        "type": "text",
        "content": "Middleware provides powerful extensibility for customizing agent behavior at different stages of execution. You can use middleware to:\n\nMiddleware integrates seamlessly into the agent’s execution graph, allowing you to intercept and modify data flow at key points without changing the core agent logic.\n\nFor comprehensive middleware documentation including decorators like @before_model , @after_model , and @wrap_tool_call , see Middleware .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "YouTube Audio Loader",
        "type": "text",
        "content": "Download audio from YouTube videos. Requires yt_dlp , pydub , librosa .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Context overview",
        "type": "text",
        "content": "Context engineering is the practice of building dynamic systems that provide the right information and tools, in the right format, so that an AI application can accomplish a task. Context can be characterized along two key dimensions:\n\nRuntime context refers to local context: data and dependencies your code needs to run. It does not refer to:\n\nRuntime context can be used to optimize the LLM context. For example, you can use user metadata\nin the runtime context to fetch user preferences and feed them into the context window.\n\nLangGraph provides three ways to manage context, which combines the mutability and lifetime dimensions:",
        "side_link": "https://docs.langchain.com/oss/python/concepts/context",
        "head_menu_name": "Learn",
        "side_menu_name": "Context"
    },
    {
        "title": "HuggingFaceInstructEmbeddings",
        "type": "code",
        "content": "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "ProviderStrategy",
        "type": "text",
        "content": "As of langchain 1.0 , simply passing a schema (e.g., response_format=ContactInfo ) is no longer supported. You must explicitly use ToolStrategy or ProviderStrategy .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Static runtime context",
        "type": "code",
        "content": "from dataclasses import dataclass\nfrom langchain.agents import create_agent\nfrom langchain.agents.middleware import dynamic_prompt, ModelRequest\n\n\n@dataclass\nclass ContextSchema:\n    user_name: str\n\n@dynamic_prompt\ndef personalized_prompt(request: ModelRequest) -> str:  \n    user_name = request.runtime.context.user_name\n    return f\"You are a helpful assistant. Address the user as {user_name}.\"\n\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    tools=[get_weather],\n    middleware=[personalized_prompt],\n    context_schema=ContextSchema\n)\n\nagent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\n    context=ContextSchema(user_name=\"John Smith\")  \n)\n",
        "side_link": "https://docs.langchain.com/oss/python/concepts/context",
        "head_menu_name": "Learn",
        "side_menu_name": "Context"
    },
    {
        "title": "Agentic RAG",
        "type": "code",
        "content": "import requests\nfrom langchain.tools import tool\nfrom langchain.chat_models import init_chat_model\nfrom langchain.agents import create_agent\n\n\n@tool\ndef fetch_url(url: str) -> str:\n    \"\"\"Fetch text content from a URL\"\"\"\n    response = requests.get(url, timeout=10.0)\n    response.raise_for_status()\n    return response.text\n\nsystem_prompt = \"\"\"\\\nUse fetch_url when you need to fetch information from a web-page; quote relevant snippets.\n\"\"\"\n\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    tools=[fetch_url], # A tool for retrieval\n    system_prompt=system_prompt,\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/retrieval",
        "head_menu_name": "LangChain",
        "side_menu_name": "Retrieval"
    },
    {
        "title": "MCP Toolbox",
        "type": "text",
        "content": "MCP Toolbox provides a simple and efficient way to connect to your databases, including those on Google Cloud like Cloud SQL and AlloyDB . With MCP Toolbox, you can seamlessly integrate your database with LangChain to build powerful, data-driven applications.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Short-term vs. long-term filesystem",
        "type": "text",
        "content": "If you enable use_longterm_memory=True and provide a Store in your agent runtime, then any files prefixed with /memories/ are saved to the long-term memory store. Note that any agents deployed on LangGraph Platform are automatically provided with a long-term memory store.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/middleware",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Middleware"
    },
    {
        "title": "create_agent",
        "type": "text",
        "content": "The new standard for building agents in LangChain, replacing langgraph.prebuilt.create_react_agent .",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Learn",
        "type": "text",
        "content": "In the Learn section of the documentation, you’ll find a collection of tutorials, conceptual overviews, and additional resources to help you build powerful applications with LangChain and LangGraph.",
        "side_link": "https://docs.langchain.com/oss/python/learn",
        "head_menu_name": "Learn",
        "side_menu_name": "Learn"
    },
    {
        "title": "Route to different backends",
        "type": "code",
        "content": "\"/memories/projects/\"",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Hybrid RAG",
        "type": "text",
        "content": "Hybrid RAG combines characteristics of both 2-Step and Agentic RAG. It introduces intermediate steps such as query preprocessing, retrieval validation, and post-generation checks. These systems offer more flexibility than fixed pipelines while maintaining some control over execution.\n\nTypical components include:\n\nThe architecture often supports multiple iterations between these steps:\n\nThis architecture is suitable for:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/retrieval",
        "head_menu_name": "LangChain",
        "side_menu_name": "Retrieval"
    },
    {
        "title": "Add metadata to traces",
        "type": "code",
        "content": "with ls.tracing_context(\n    project_name=\"email-agent-test\",\n    enabled=True,\n    tags=[\"production\", \"email-assistant\", \"v1.0\"],\n    metadata={\"user_id\": \"user_123\", \"session_id\": \"session_456\", \"environment\": \"production\"}):\n    response = agent.invoke(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"Send a welcome email\"}]}\n    )\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/observability",
        "head_menu_name": "LangChain",
        "side_menu_name": "Observability"
    },
    {
        "title": "Interface",
        "type": "code",
        "content": "from langchain_community.document_loaders.csv_loader import CSVLoader\n\nloader = CSVLoader(\n    ...  # Integration-specific parameters here\n)\n\n# Load all documents\ndocuments = loader.load()\n\n# For large datasets, lazily load documents\nfor document in loader.lazy_load():\n    print(document)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/document_loaders",
        "head_menu_name": "Integrations",
        "side_menu_name": "Document loaders"
    },
    {
        "title": "Gmail",
        "type": "code",
        "content": "pip install langchain-google-community[gmail]\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "3. Install dependencies",
        "type": "code",
        "content": "cd path/to/your/app\npip install -e .\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/local-server",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Local server"
    },
    {
        "title": "Azure AI Document Intelligence",
        "type": "text",
        "content": "Azure AI Document Intelligence (formerly known\nas Azure Form Recognizer ) is machine-learning\nbased service that extracts texts (including handwriting), tables, document structures,\nand key-value-pairs\nfrom digital or scanned PDFs, images, Office and HTML files.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Tailor configurations by risk",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/human-in-the-loop",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Execution order",
        "type": "code",
        "content": "middleware1.before_model()",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Tool calling strategy",
        "type": "code",
        "content": "Callable[[Exception], str]",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "How it works",
        "type": "code",
        "content": "Input: Hello\nToken: Hi\nToken:  there\nToken: !\nToken:  How\nToken:  can\nToken:  I\n...\nFull message: Hi there! How can I help today?\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Review and edit state",
        "type": "code",
        "content": "from langgraph.types import interrupt\n\ndef review_node(state: State):\n    # Pause and show the current content for review (surfaces in result[\"__interrupt__\"])\n    edited_content = interrupt({\n        \"instruction\": \"Review and edit this content\",\n        \"content\": state[\"generated_text\"]\n    })\n\n    # Update the state with the edited version\n    return {\"generated_text\": edited_content}\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Multimodal",
        "type": "text",
        "content": "See the integrations page for details on specific providers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Subagent interrupts",
        "type": "code",
        "content": "agent = create_deep_agent(\n    tools=[delete_file, read_file],\n    interrupt_on={\n        \"delete_file\": True,\n        \"read_file\": False,\n    },\n    subagents=[{\n        \"name\": \"file-manager\",\n        \"description\": \"Manages file operations\",\n        \"system_prompt\": \"You are a file management assistant.\",\n        \"tools\": [delete_file, read_file],\n        \"interrupt_on\": {\n            # Override: require approval for reads in this subagent\n            \"delete_file\": True,\n            \"read_file\": True,  # Different from main agent!\n        }\n    }],\n    checkpointer=checkpointer\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/human-in-the-loop",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Cross-thread persistence",
        "type": "code",
        "content": "import uuid\n\n# Thread 1: Write to long-term memory\nconfig1 = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\nagent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"Save my preferences to /memories/preferences.txt\"}]\n}, config=config1)\n\n# Thread 2: Read from long-term memory (different conversation!)\nconfig2 = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\nagent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"What are my preferences?\"}]\n}, config=config2)\n# Agent can read /memories/preferences.txt from the first thread\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Pre-bound models",
        "type": "code",
        "content": "# No longer supported\nmodel_with_tools = ChatOpenAI().bind_tools([some_tool])\nagent = create_agent(model_with_tools, tools=[])\n\n# Use instead\nagent = create_agent(\"gpt-4o-mini\", tools=[some_tool])\n",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Responding to interrupts",
        "type": "code",
        "content": "from langgraph.types import Command\n\n# Human-in-the-loop leverages LangGraph's persistence layer.\n# You must provide a thread ID to associate the execution with a conversation thread,\n# so the conversation can be paused and resumed (as is needed for human review).\nconfig = {\"configurable\": {\"thread_id\": \"some_id\"}} \n# Run the graph until the interrupt is hit.\nresult = agent.invoke(\n    {\n        \"messages\": [\n            {\n                \"role\": \"user\",\n                \"content\": \"Delete old records from the database\",\n            }\n        ]\n    },\n    config=config \n)\n\n# The interrupt contains the full HITL request with action_requests and review_configs\nprint(result['__interrupt__'])\n# > [\n# >    Interrupt(\n# >       value={\n# >          'action_requests': [\n# >             {\n# >                'name': 'execute_sql',\n# >                'arguments': {'query': 'DELETE FROM records WHERE created_at < NOW() - INTERVAL \\'30 days\\';'},\n# >                'description': 'Tool execution pending approval\\n\\nTool: execute_sql\\nArgs: {...}'\n# >             }\n# >          ],\n# >          'review_configs': [\n# >             {\n# >                'action_name': 'execute_sql',\n# >                'allowed_decisions': ['approve', 'reject']\n# >             }\n# >          ]\n# >       }\n# >    )\n# > ]\n\n\n# Resume with approval decision\nagent.invoke(\n    Command( \n        resume={\"decisions\": [{\"type\": \"approve\"}]}  # or \"edit\", \"reject\"\n    ), \n    config=config # Same thread ID to resume the paused conversation\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/human-in-the-loop",
        "head_menu_name": "LangChain",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Cloud SQL for SQL Server",
        "type": "code",
        "content": "from langchain_google_cloud_sql_mssql import MSSQLLoader # MSSQLEngine also available\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Install LangGraph",
        "type": "text",
        "content": "To work with specific LLM provider packages, you will need install them separately.\n\nRefer to the integrations page for provider-specific installation instructions.\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/install",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Install"
    },
    {
        "title": "Using in LangGraph",
        "type": "text",
        "content": "If we create a new thread, we can still access the same memories so long as the user_id is the same.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Cloud SQL for PostgreSQL",
        "type": "text",
        "content": "Google Cloud SQL for PostgreSQL is a fully-managed PostgreSQL database service.\n\nInstall the python package:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "LLM tool emulator",
        "type": "text",
        "content": "Model to use for generating emulated tool responses. Can be a model identifier string or BaseChatModel instance.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "SageMaker Tracking",
        "type": "code",
        "content": "pip install google-search-results sagemaker\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Checkpointer libraries",
        "type": "code",
        "content": "langgraph-checkpoint-postgres",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Edit tool arguments",
        "type": "text",
        "content": "When \"edit\" is in the allowed decisions, you can modify the tool arguments before execution:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/human-in-the-loop",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Vertex AI Search",
        "type": "code",
        "content": "pip install google-cloud-discoveryengine langchain-google-community\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Examples",
        "type": "code",
        "content": "{\n  \"dependencies\": [\"langchain_openai\", \"./your_package\"],\n  \"graphs\": {\n    \"my_agent\": \"./your_package/your_file.py:agent\"\n  },\n  \"env\": \"./.env\"\n}\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/application-structure",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Application structure"
    },
    {
        "title": "Use a virtual filesystem",
        "type": "text",
        "content": "Build a custom backend to project a remote or database filesystem (e.g., S3 or Postgres) into the tools namespace.\n\nDesign guidelines:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Azure AI Services individual tools",
        "type": "code",
        "content": "from langchain_community.tools.azure_cognitive_services import (\n    AzureCogsFormRecognizerTool,\n    AzureCogsImageAnalysisTool,\n    AzureCogsSpeech2TextTool,\n    AzureCogsText2SpeechTool,\n    AzureCogsTextAnalyticsHealthTool,\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Document AI",
        "type": "code",
        "content": "projects/PROJECT_NUMBER/locations/LOCATION/processors/PROCESSOR_ID",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Bing Search",
        "type": "code",
        "content": "BING_SUBSCRIPTION_KEY",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Firestore (Datastore Mode)",
        "type": "text",
        "content": "Google Cloud Firestore in Datastore mode .\n\nInstall the python package:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Install",
        "type": "text",
        "content": "Install the langchain-mcp-adapters library to use MCP tools in LangGraph:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/mcp",
        "head_menu_name": "LangChain",
        "side_menu_name": "Model Context Protocol (MCP)"
    },
    {
        "title": "2. Prepare your agent",
        "type": "text",
        "content": "We’ll use the following simple agent as an example:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/studio",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Studio"
    },
    {
        "title": "Checkpointer libraries",
        "type": "text",
        "content": "Under the hood, checkpointing is powered by checkpointer objects that conform to BaseCheckpointSaver interface. LangGraph provides several checkpointer implementations, all implemented via standalone, installable libraries:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Memory",
        "type": "text",
        "content": "AI applications need memory to share context across multiple interactions. In LangGraph, you can add two types of memory:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Anthropic prompt caching",
        "type": "code",
        "content": "from langchain_anthropic import ChatAnthropic\nfrom langchain_anthropic.middleware import AnthropicPromptCachingMiddleware\nfrom langchain.agents import create_agent\n\n\nLONG_PROMPT = \"\"\"\nPlease be a helpful assistant.\n\n<Lots more context ...>\n\"\"\"\n\nagent = create_agent(\n    model=ChatAnthropic(model=\"claude-sonnet-4-5-20250929\"),\n    system_prompt=LONG_PROMPT,\n    middleware=[AnthropicPromptCachingMiddleware(ttl=\"5m\")],\n)\n\n# cache store\nagent.invoke({\"messages\": [HumanMessage(\"Hi, my name is Bob\")]})\n\n# cache hit, system prompt is cached\nagent.invoke({\"messages\": [HumanMessage(\"What's my name?\")]})\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Dependencies",
        "type": "text",
        "content": "A LangGraph application may depend on other Python packages.\n\nYou will generally need to specify the following information for dependencies to be set up correctly:\n\nA file in the directory that specifies the dependencies (e.g. requirements.txt , pyproject.toml , or package.json ).",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/application-structure",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Application structure"
    },
    {
        "title": "Time Travel",
        "type": "text",
        "content": "Third, checkpointers allow for “time travel” , allowing users to replay prior graph executions to review and / or debug specific graph steps. In addition, checkpointers make it possible to fork the graph state at arbitrary checkpoints to explore alternative trajectories.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "How it works",
        "type": "text",
        "content": "This simplifies filtering based on event types and other metadata, and will aggregate the full message in the background. See below for an example.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Firestore (Native Mode)",
        "type": "text",
        "content": "Google Cloud Firestore is a NoSQL document database.\n\nInstall the python package:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Overview",
        "type": "text",
        "content": "This overview covers text-based embedding models . LangChain does not currently support multimodal embeddings.\n\nEmbedding models transform raw text—such as a sentence, paragraph, or tweet—into a fixed-length vector of numbers that captures its semantic meaning . These vectors allow machines to compare and search text based on meaning rather than exact words.\n\nIn practice, this means that texts with similar ideas are placed close together in the vector space. For example, instead of matching only the phrase “machine learning” , embeddings can surface documents that discuss related concepts even when different wording is used.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/text_embedding",
        "head_menu_name": "Integrations",
        "side_menu_name": "Embedding models"
    },
    {
        "title": "Model Context",
        "type": "text",
        "content": "Control what goes into each model call - instructions, available tools, which model to use, and output format. These decisions directly impact reliability and cost.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Short-term memory",
        "type": "text",
        "content": "Short-term memory lets your application remember previous interactions within a single thread or conversation. A thread organizes multiple interactions in a session, similar to the way email groups messages in a single conversation.\n\nLangGraph manages short-term memory as part of the agent’s state, persisted via thread-scoped checkpoints. This state can normally include the conversation history along with other stateful data, such as uploaded files, retrieved documents, or generated artifacts. By storing these in the graph’s state, the bot can access the full context for a given conversation while maintaining separation between different threads.",
        "side_link": "https://docs.langchain.com/oss/python/concepts/memory",
        "head_menu_name": "Learn",
        "side_menu_name": "Memory"
    },
    {
        "title": "3. Define model node",
        "type": "code",
        "content": "from langchain.messages import SystemMessage\n\n\ndef llm_call(state: dict):\n    \"\"\"LLM decides whether to call a tool or not\"\"\"\n\n    return {\n        \"messages\": [\n            model_with_tools.invoke(\n                [\n                    SystemMessage(\n                        content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\"\n                    )\n                ]\n                + state[\"messages\"]\n            )\n        ],\n        \"llm_calls\": state.get('llm_calls', 0) + 1\n    }\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/quickstart",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Middleware",
        "type": "text",
        "content": "Middleware provides a way to more tightly control what happens inside the agent.\n\nThe core agent loop involves calling a model, letting it choose tools to execute, and then finishing when it calls no more tools:\n\nMiddleware exposes hooks before and after each of those steps:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Debugging with interrupts",
        "type": "code",
        "content": "graph = builder.compile(\n    interrupt_before=[\"node_a\"],  \n    interrupt_after=[\"node_b\", \"node_c\"],  \n    checkpointer=checkpointer,\n)\n\n# Pass a thread ID to the graph\nconfig = {\n    \"configurable\": {\n        \"thread_id\": \"some_thread\"\n    }\n}\n\n# Run the graph until the breakpoint\ngraph.invoke(inputs, config=config)  \n\n# Resume the graph\ngraph.invoke(None, config=config)  \n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Hugging Face Hub Tools",
        "type": "code",
        "content": "load_huggingface_tool",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Using in LangGraph",
        "type": "code",
        "content": "def call_model(state: MessagesState, config: RunnableConfig, *, store: BaseStore):\n    # Get the user id from the config\n    user_id = config[\"configurable\"][\"user_id\"]\n\n    # Namespace the memory\n    namespace = (user_id, \"memories\")\n\n    # Search based on the most recent message\n    memories = store.search(\n        namespace,\n        query=state[\"messages\"][-1].content,\n        limit=3\n    )\n    info = \"\\n\".join([d.value[\"memory\"] for d in memories])\n\n    # ... Use memories in the model call\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Tool calling",
        "type": "code",
        "content": "for chunk in model_with_tools.stream(\n    \"What's the weather in Boston and Tokyo?\"\n):\n    # Tool call chunks arrive progressively\n    for tool_chunk in chunk.tool_call_chunks:\n        if name := tool_chunk.get(\"name\"):\n            print(f\"Tool: {name}\")\n        if id_ := tool_chunk.get(\"id\"):\n            print(f\"ID: {id_}\")\n        if args := tool_chunk.get(\"args\"):\n            print(f\"Args: {args}\")\n\n# Output:\n# Tool: get_weather\n# ID: call_SvMlU1TVIZugrFLckFE2ceRE\n# Args: {\"lo\n# Args: catio\n# Args: n\": \"B\n# Args: osto\n# Args: n\"}\n# Tool: get_weather\n# ID: call_QMZdy6qInx13oWKE7KhuhOLR\n# Args: {\"lo\n# Args: catio\n# Args: n\": \"T\n# Args: okyo\n# Args: \"}\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Azure AI",
        "type": "code",
        "content": "export AZURE_AI_CREDENTIAL=your-api-key\nexport AZURE_AI_ENDPOINT=your-endpoint\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Trajectory Match Evaluator",
        "type": "code",
        "content": "tool_args_match_overrides",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Stream",
        "type": "text",
        "content": "Streaming only works if all steps in the program know how to process a stream of chunks. For instance, an application that isn’t streaming-capable would be one that needs to store the entire output in memory before it can be processed.\n\nLangChain simplifies streaming from chat models by automatically enabling streaming mode in certain cases, even when you’re not explicitly calling the streaming methods. This is particularly useful when you use the non-streaming invoke method but still want to stream the entire application, including intermediate results from the chat model.\n\nIn LangGraph agents , for example, you can call model.invoke() within nodes, but LangChain will automatically delegate to streaming if running in a streaming mode.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Getting Started",
        "type": "code",
        "content": "from toolbox_langchain import ToolboxClient\n\nasync with ToolboxClient(\"http://127.0.0.1:5000\") as client:\n\n    tools = client.load_toolset()\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Configurable models",
        "type": "text",
        "content": "We can call declarative operations like bind_tools , with_structured_output , with_configurable , etc. on a configurable model and chain a configurable model in the same way that we would a regularly instantiated chat model object.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Human-in-the-loop",
        "type": "text",
        "content": "List of allowed decisions: \"approve\" , \"edit\" , or \"reject\"",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "4. Create a LangGraph config file",
        "type": "code",
        "content": "{\n  \"dependencies\": [\".\"],\n  \"graphs\": {\n    \"agent\": \"./src/agent.py:agent\"\n  },\n  \"env\": \".env\"\n}\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/studio",
        "head_menu_name": "LangChain",
        "side_menu_name": "Studio"
    },
    {
        "title": "SageMaker Tracking",
        "type": "text",
        "content": "Amazon SageMaker is a fully managed service that is used to quickly\nand easily build, train and deploy machine learning (ML) models.\n\nAmazon SageMaker Experiments is a capability\nof Amazon SageMaker that lets you organize, track,\ncompare and evaluate ML experiments and model versions.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Additional resources",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/mcp",
        "head_menu_name": "LangChain",
        "side_menu_name": "Model Context Protocol (MCP)"
    },
    {
        "title": "Defining state via middleware",
        "type": "code",
        "content": "from langchain.agents import AgentState\nfrom langchain.agents.middleware import AgentMiddleware\n\n\nclass CustomState(AgentState):\n    user_preferences: dict\n\nclass CustomMiddleware(AgentMiddleware):\n    state_schema = CustomState\n    tools = [tool1, tool2]\n\n    def before_model(self, state: CustomState, runtime) -> dict[str, Any] | None:\n        ...\n\nagent = create_agent(\n    model,\n    tools=tools,\n    middleware=[CustomMiddleware()]\n)\n\n# The agent can now track additional state beyond messages\nresult = agent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"I prefer technical explanations\"}],\n    \"user_preferences\": {\"style\": \"technical\", \"verbosity\": \"detailed\"},\n})\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Tools",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/customization",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Customization"
    },
    {
        "title": "Trajectory Match Evaluator",
        "type": "text",
        "content": "The strict mode ensures trajectories contain identical messages in the same order with the same tool calls, though it allows for differences in message content. This is useful when you need to enforce a specific sequence of operations, such as requiring a policy lookup before authorizing an action.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Run a local server",
        "type": "text",
        "content": "This guide shows you how to run a LangGraph application locally.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/local-server",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Local server"
    },
    {
        "title": "Trim messages",
        "type": "code",
        "content": "from langchain_core.messages.utils import (  \n    trim_messages,  \n    count_tokens_approximately  \n)  \n\ndef call_model(state: MessagesState):\n    messages = trim_messages(  \n        state[\"messages\"],\n        strategy=\"last\",\n        token_counter=count_tokens_approximately,\n        max_tokens=128,\n        start_on=\"human\",\n        end_on=(\"human\", \"tool\"),\n    )\n    response = model.invoke(messages)\n    return {\"messages\": [response]}\n\nbuilder = StateGraph(MessagesState)\nbuilder.add_node(call_model)\n...\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Dynamic model",
        "type": "text",
        "content": "For model configuration details, see Models . For dynamic model selection patterns, see Dynamic model in middleware .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "HuggingFaceInstructEmbeddings",
        "type": "text",
        "content": "We can use the HuggingFaceInstructEmbeddings class to run open source embedding models locally.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Configurable models",
        "type": "text",
        "content": "You can also create a runtime-configurable model by specifying configurable_fields . If you don’t specify a model value, then 'model' and 'model_provider' will be configurable by default.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Azure Blob Storage",
        "type": "text",
        "content": "See usage examples for the Azure Blob Storage Loader .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Invoke a graph from a node",
        "type": "text",
        "content": "This is an example with two levels of subgraphs: parent -> child -> grandchild.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-subgraphs",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Subgraphs"
    },
    {
        "title": "Data Steps",
        "type": "text",
        "content": "Use when you need to retrieve information from external sources",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Add a graph as a node",
        "type": "code",
        "content": "{'node_1': {'foo': 'hi! foo'}}\n{'node_2': {'foo': 'hi! foobar'}}\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-subgraphs",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Subgraphs"
    },
    {
        "title": "Multimodal",
        "type": "text",
        "content": "OpenAI and AWS Bedrock Converse ,\nfor example, require a filename for PDFs. See the provider page for your chosen model for specifics.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Message prompts",
        "type": "code",
        "content": "from langchain.messages import SystemMessage, HumanMessage, AIMessage\n\nmessages = [\n    SystemMessage(\"You are a poetry expert\"),\n    HumanMessage(\"Write a haiku about spring\"),\n    AIMessage(\"Cherry blossoms bloom...\")\n]\nresponse = model.invoke(messages)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Execution order",
        "type": "code",
        "content": "middleware3.after_model()",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "State type restrictions",
        "type": "code",
        "content": "from langchain.agents import AgentState, create_agent\n\n# AgentState is a TypedDict\nclass CustomAgentState(AgentState):  \n    user_id: str\n\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    tools=tools,\n    state_schema=CustomAgentState  \n)\n",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Azure AI Data",
        "type": "code",
        "content": "pip install azureml-fsspec, azure-ai-generative\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Get state history",
        "type": "text",
        "content": "You can get the full history of the graph execution for a given thread by calling graph.get_state_history(config) . This will return a list of StateSnapshot objects associated with the thread ID provided in the config. Importantly, the checkpoints will be ordered chronologically with the most recent checkpoint / StateSnapshot being the first in the list.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Basic tool definition",
        "type": "text",
        "content": "The simplest way to create a tool is with the @tool decorator. By default, the function’s docstring becomes the tool’s description that helps the model understand when to use it:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "Gemma on Vertex AI Model Garden",
        "type": "code",
        "content": "from langchain_google_vertexai.gemma import GemmaChatVertexAIModelGarden\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "as_node",
        "type": "text",
        "content": "The final thing you can optionally specify when calling update_state is as_node . If you provided it, the update will be applied as if it came from node as_node . If as_node is not provided, it will be set to the last node that updated the state, if not ambiguous. The reason this matters is that the next steps to execute depend on the last node to have given an update, so this can be used to control which node executes next. See this how to guide on time-travel to learn more about forking state .",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Content block reference",
        "type": "text",
        "content": "An identifier associated with the tool call.\n\nName of the tool being called\n\nPartial tool arguments (may be incomplete JSON)\n\nPosition of this chunk in the stream\n\nPurpose: Search results\n\nAlways \"server_tool_result\"",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "3. Update the state",
        "type": "text",
        "content": "update_state will create a new checkpoint. The new checkpoint will be associated with the same thread, but a new checkpoint ID.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-time-travel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Time travel"
    },
    {
        "title": "SQL Agent",
        "type": "text",
        "content": "Build a SQL agent to interact with databases with human-in-the-loop review.",
        "side_link": "https://docs.langchain.com/oss/python/learn",
        "head_menu_name": "Learn",
        "side_menu_name": "Learn"
    },
    {
        "title": "Stream subgraph outputs",
        "type": "code",
        "content": "((), {'node_1': {'foo': 'hi! foo'}})\n(('node_2:e58e5673-a661-ebb0-70d4-e298a7fc28b7',), {'subgraph_node_1': {'bar': 'bar'}})\n(('node_2:e58e5673-a661-ebb0-70d4-e298a7fc28b7',), {'subgraph_node_2': {'foo': 'hi! foobar'}})\n((), {'node_2': {'foo': 'hi! foobar'}})\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-subgraphs",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Subgraphs"
    },
    {
        "title": "Next steps",
        "type": "text",
        "content": "Now that you’ve built your first deep agent:\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/quickstart",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Build a real-world agent",
        "type": "text",
        "content": "Next, build a practical weather forecasting agent that demonstrates key production concepts:\n\nLet’s walk through each step:\n\nThe system prompt defines your agent’s role and behavior. Keep it specific and actionable:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/quickstart",
        "head_menu_name": "LangChain",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Bedrock token usage",
        "type": "code",
        "content": "from langchain_community.callbacks.bedrock_anthropic_callback import BedrockAnthropicTokenUsageCallbackHandler\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Delete messages",
        "type": "code",
        "content": "from langchain.messages import RemoveMessage  \n\ndef delete_messages(state):\n    messages = state[\"messages\"]\n    if len(messages) > 2:\n        # remove the earliest two messages\n        return {\"messages\": [RemoveMessage(id=m.id) for m in messages[:2]]}  \n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Error handling strategies",
        "type": "code",
        "content": "def custom_error_handler(error: Exception) -> str:\n    if isinstance(error, StructuredOutputValidationError):\n        return \"There was an issue with the format. Try again.\n    elif isinstance(error, MultipleStructuredOutputsError):\n        return \"Multiple structured outputs were returned. Pick the most relevant one.\"\n    else:\n        return f\"Error: {str(error)}\"\n\nToolStrategy(\n    schema=ToolStrategy(Union[ContactInfo, EventDetails]),\n    handle_errors=custom_error_handler\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Defining state via middleware",
        "type": "code",
        "content": "from langchain.agents.middleware import AgentState, AgentMiddleware\nfrom typing_extensions import NotRequired\nfrom typing import Any\n\nclass CustomState(AgentState):\n    model_call_count: NotRequired[int]\n\nclass CallCounterMiddleware(AgentMiddleware[CustomState]):\n    state_schema = CustomState  \n\n    def before_model(self, state: CustomState, runtime) -> dict[str, Any] | None:\n        count = state.get(\"model_call_count\", 0)\n        if count > 10:\n            return {\"jump_to\": \"end\"}\n        return None\n\n    def after_model(self, state: CustomState, runtime) -> dict[str, Any] | None:\n        return {\"model_call_count\": state.get(\"model_call_count\", 0) + 1}\n\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    tools=[...],\n    middleware=[CallCounterMiddleware()]  \n)\n",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Minimize tool sets",
        "type": "code",
        "content": "# ✅ Good: Focused tool set\nemail_agent = {\n    \"name\": \"email-sender\",\n    \"tools\": [send_email, validate_email],  # Only email-related\n}\n\n# ❌ Bad: Too many tools\nemail_agent = {\n    \"name\": \"email-sender\",\n    \"tools\": [send_email, web_search, database_query, file_upload],  # Unfocused\n}\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Vertex AI Vector Search",
        "type": "code",
        "content": "VectorSearchVectorStore",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Example: Summarization",
        "type": "text",
        "content": "When the conversation exceeds the token limit, SummarizationMiddleware automatically:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Batch",
        "type": "text",
        "content": "It is distinct from batch APIs supported by inference providers, such as OpenAI or Anthropic .\n\nBy default, batch() will only return the final output for the entire batch. If you want to receive the output for each individual input as it finishes generating, you can stream results with batch_as_completed() :",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Use in subgraphs",
        "type": "code",
        "content": "from langgraph.graph import START, StateGraph\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom typing import TypedDict\n\nclass State(TypedDict):\n    foo: str\n\n# Subgraph\n\ndef subgraph_node_1(state: State):\n    return {\"foo\": state[\"foo\"] + \"bar\"}\n\nsubgraph_builder = StateGraph(State)\nsubgraph_builder.add_node(subgraph_node_1)\nsubgraph_builder.add_edge(START, \"subgraph_node_1\")\nsubgraph = subgraph_builder.compile()  \n\n# Parent graph\n\nbuilder = StateGraph(State)\nbuilder.add_node(\"node_1\", subgraph)  \nbuilder.add_edge(START, \"node_1\")\n\ncheckpointer = InMemorySaver()\ngraph = builder.compile(checkpointer=checkpointer)  \n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Microsoft Excel",
        "type": "text",
        "content": "Microsoft Excel is a spreadsheet editor developed by\nMicrosoft for Windows, macOS, Android, iOS and iPadOS.\nIt features calculation or computation capabilities, graphing tools, pivot tables, and a macro programming\nlanguage called Visual Basic for Applications (VBA). Excel forms part of the Microsoft 365 suite of software.\n\nThe UnstructuredExcelLoader is used to load Microsoft Excel files. The loader works with both .xlsx and .xls files.\nThe page content will be the raw text of the Excel file. If you use the loader in \"elements\" mode, an HTML\nrepresentation of the Excel file will be available in the document metadata under the text_as_html key.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Deterministic guardrails",
        "type": "text",
        "content": "Use rule-based logic like regex patterns, keyword matching, or explicit checks. Fast, predictable, and cost-effective, but may miss nuanced violations.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/guardrails",
        "head_menu_name": "LangChain",
        "side_menu_name": "Guardrails"
    },
    {
        "title": "LLM-as-Judge Evaluator",
        "type": "code",
        "content": "TRAJECTORY_ACCURACY_PROMPT_WITH_REFERENCE",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "StateBackend (ephemeral)",
        "type": "code",
        "content": "# By default we provide a StateBackend\nagent = create_deep_agent()\n\n# Under the hood, it looks like\nfrom deepagents.backends import StateBackend\n\nagent = create_deep_agent(\n    backend=(lambda rt: StateBackend(rt))   # Note that the tools access State through the runtime.state\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Invocation config",
        "type": "text",
        "content": "Handlers for monitoring and responding to events during execution.\n\nMaximum recursion depth for chains to prevent infinite loops in complex pipelines.\n\nSee full RunnableConfig reference for all supported attributes.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Multi-agent",
        "type": "text",
        "content": "Multi-agent systems break a complex application into multiple specialized agents that work together to solve problems.\nInstead of relying on a single agent to handle every step, multi-agent architectures allow you to compose smaller, focused agents into a coordinated workflow.\n\nMulti-agent systems are useful when:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/multi-agent",
        "head_menu_name": "LangChain",
        "side_menu_name": "Multi-agent"
    },
    {
        "title": "LLM tokens",
        "type": "text",
        "content": "To stream tokens as they are produced by the LLM, use stream_mode=\"messages\" . Below you can see the output of the agent streaming tool calls and the final response.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/streaming",
        "head_menu_name": "LangChain",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Using in LangGraph",
        "type": "text",
        "content": "As we showed above, we can also access the store in any node and use the store.search method to get memories. Recall the memories are returned as a list of objects that can be converted to a dictionary.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Hugging Face Text-to-Speech Model Inference.",
        "type": "code",
        "content": "OpenAI Text-to-Speech API",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "History",
        "type": "text",
        "content": "A standard message content format: Model APIs evolved from returning messages with a simple content string to more complex output types - reasoning blocks, citations, server-side tool calls, etc. LangChain evolved its message formats to standardize these across providers.\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/philosophy",
        "head_menu_name": "LangChain",
        "side_menu_name": "Philosophy"
    },
    {
        "title": "Google Places",
        "type": "text",
        "content": "Search for places information. Requires googlemaps package and a Google Maps API key.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Episodic memory",
        "type": "text",
        "content": "Episodic memory , in both humans and AI agents, involves recalling past events or actions. The CoALA paper frames this well: facts can be written to semantic memory, whereas experiences can be written to episodic memory. For AI agents, episodic memory is often used to help an agent remember how to accomplish a task.\n\nIn practice, episodic memories are often implemented through few-shot example prompting, where agents learn from past sequences to perform tasks correctly. Sometimes it’s easier to “show” than “tell” and LLMs learn well from examples. Few-shot learning lets you “program” your LLM by updating the prompt with input-output examples to illustrate the intended behavior. While various best-practices can be used to generate few-shot examples, often the challenge lies in selecting the most relevant examples based on user input.\n\nNote that the memory store is just one way to store data as few-shot examples. If you want to have more developer involvement, or tie few-shots more closely to your evaluation harness, you can also use a LangSmith Dataset to store your data. Then dynamic few-shot example selectors can be used out-of-the box to achieve this same goal. LangSmith will index the dataset for you and enable retrieval of few shot examples that are most relevant to the user input based upon keyword similarity ( using a BM25-like algorithm for keyword based similarity).\n\nSee this how-to video for example usage of dynamic few-shot example selection in LangSmith. Also, see this blog post showcasing few-shot prompting to improve tool calling performance and this blog post using few-shot example to align an LLMs to human preferences.",
        "side_link": "https://docs.langchain.com/oss/python/concepts/memory",
        "head_menu_name": "Learn",
        "side_menu_name": "Memory"
    },
    {
        "title": "Model Context Protocol (MCP)",
        "type": "code",
        "content": "langchain-mcp-adapters",
        "side_link": "https://docs.langchain.com/oss/python/langchain/mcp",
        "head_menu_name": "LangChain",
        "side_menu_name": "Model Context Protocol (MCP)"
    },
    {
        "title": "Get state history",
        "type": "code",
        "content": "config = {\"configurable\": {\"thread_id\": \"1\"}}\nlist(graph.get_state_history(config))\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Enforce",
        "type": "text",
        "content": "Apply rate limits, guardrails, and PII detection\n\nAdd middleware by passing it to create_agent :",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Playwright URL Loader",
        "type": "code",
        "content": "from langchain_community.document_loaders.onenote import OneNoteLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Examples",
        "type": "code",
        "content": "./your_package/your_file.py",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/application-structure",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Application structure"
    },
    {
        "title": "Custom tool name",
        "type": "code",
        "content": "@tool(\"web_search\")  # Custom name\ndef search(query: str) -> str:\n    \"\"\"Search the web for information.\"\"\"\n    return f\"Results for: {query}\"\n\nprint(search.name)  # web_search\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "Reporting issues",
        "type": "text",
        "content": "Please report any issues discovered with 1.0 on GitHub using the 'v1' label .",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Datadog",
        "type": "text",
        "content": "Monitoring and analytics platform for applications.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/all_providers",
        "head_menu_name": "Integrations",
        "side_menu_name": "All providers"
    },
    {
        "title": "Stream subgraph outputs",
        "type": "code",
        "content": "from langgraph.graph import START, StateGraph\nfrom typing import TypedDict\n\n# Define subgraph\nclass SubgraphState(TypedDict):\n    foo: str  # note that this key is shared with the parent graph state\n    bar: str\n\ndef subgraph_node_1(state: SubgraphState):\n    return {\"bar\": \"bar\"}\n\ndef subgraph_node_2(state: SubgraphState):\n    return {\"foo\": state[\"foo\"] + state[\"bar\"]}\n\nsubgraph_builder = StateGraph(SubgraphState)\nsubgraph_builder.add_node(subgraph_node_1)\nsubgraph_builder.add_node(subgraph_node_2)\nsubgraph_builder.add_edge(START, \"subgraph_node_1\")\nsubgraph_builder.add_edge(\"subgraph_node_1\", \"subgraph_node_2\")\nsubgraph = subgraph_builder.compile()\n\n# Define parent graph\nclass ParentState(TypedDict):\n    foo: str\n\ndef node_1(state: ParentState):\n    return {\"foo\": \"hi! \" + state[\"foo\"]}\n\nbuilder = StateGraph(ParentState)\nbuilder.add_node(\"node_1\", node_1)\nbuilder.add_node(\"node_2\", subgraph)\nbuilder.add_edge(START, \"node_1\")\nbuilder.add_edge(\"node_1\", \"node_2\")\ngraph = builder.compile()\n\nfor chunk in graph.stream(\n    {\"foo\": \"foo\"},\n    stream_mode=\"updates\",\n    # Set subgraphs=True to stream outputs from subgraphs\n    subgraphs=True,  \n):\n    print(chunk)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Chat models",
        "type": "text",
        "content": "Microsoft offers three main options for accessing chat models through Azure:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Development environment",
        "type": "text",
        "content": "Our Python projects use uv for dependency management. Make sure you have the latest version installed.",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Memorystore for Redis",
        "type": "code",
        "content": "from langchain_google_memorystore_redis import RedisVectorStore\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Cloud Vision loader",
        "type": "text",
        "content": "Load data using Google Cloud Vision API.\n\nInstall with Vision dependencies:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Trace selectively",
        "type": "code",
        "content": "import langsmith as ls\n\n# This WILL be traced\nwith ls.tracing_context(enabled=True):\n    agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Send a test email to alice@example.com\"}]})\n\n# This will NOT be traced (if LANGSMITH_TRACING is not set)\nagent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Send another email\"}]})\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/observability",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Observability"
    },
    {
        "title": "Content block reference",
        "type": "code",
        "content": "{\n    \"type\": \"text\",\n    \"text\": \"Hello world\",\n    \"annotations\": []\n}\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Vertex AI Vector Search",
        "type": "code",
        "content": "from langchain_google_vertexai import VectorSearchVectorStoreGCS\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Trim messages",
        "type": "text",
        "content": "To trim message history in an agent, use the @before_model middleware decorator:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Memorystore for Redis",
        "type": "code",
        "content": "from langchain_google_memorystore_redis import MemorystoreDocumentLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Defining tools",
        "type": "text",
        "content": "If an empty tool list is provided, the agent will consist of a single LLM node without tool-calling capabilities.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "LLM tool emulator",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import LLMToolEmulator\n\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[get_weather, search_database, send_email],\n    middleware=[\n        # Emulate all tools by default\n        LLMToolEmulator(),\n\n        # Or emulate specific tools\n        # LLMToolEmulator(tools=[\"get_weather\", \"search_database\"]),\n\n        # Or use a custom model for emulation\n        # LLMToolEmulator(model=\"claude-sonnet-4-5-20250929\"),\n    ],\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "AWS Glue",
        "type": "text",
        "content": "The AWS Glue Data Catalog is a centralized metadata\nrepository that allows you to manage, access, and share metadata about\nyour data stored in AWS. It acts as a metadata store for your data assets,\nenabling various AWS services and your applications to query and connect\nto the data they need efficiently.\n\nSee a usage example .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Specify a backend",
        "type": "code",
        "content": "FilesystemBackend(root_dir=\".\")",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Use with any LLM",
        "type": "text",
        "content": "You can use stream_mode=\"custom\" to stream data from any LLM API — even if that API does not implement the LangChain chat model interface.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Serialize standard content",
        "type": "text",
        "content": "Learn more: Messages , Standard content blocks , and Multimodal .",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Invoke a graph from a node",
        "type": "code",
        "content": "from typing_extensions import TypedDict\nfrom langgraph.graph.state import StateGraph, START\n\nclass SubgraphState(TypedDict):\n    bar: str\n\n# Subgraph\n\ndef subgraph_node_1(state: SubgraphState):\n    return {\"bar\": \"hi! \" + state[\"bar\"]}\n\nsubgraph_builder = StateGraph(SubgraphState)\nsubgraph_builder.add_node(subgraph_node_1)\nsubgraph_builder.add_edge(START, \"subgraph_node_1\")\nsubgraph = subgraph_builder.compile()\n\n# Parent graph\n\nclass State(TypedDict):\n    foo: str\n\ndef call_subgraph(state: State):\n    # Transform the state to the subgraph state\n    subgraph_output = subgraph.invoke({\"bar\": state[\"foo\"]})  \n    # Transform response back to the parent state\n    return {\"foo\": subgraph_output[\"bar\"]}\n\nbuilder = StateGraph(State)\nbuilder.add_node(\"node_1\", call_subgraph)\nbuilder.add_edge(START, \"node_1\")\ngraph = builder.compile()\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-subgraphs",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Subgraphs"
    },
    {
        "title": "Updated return type for chat models",
        "type": "text",
        "content": "The return type signature for chat model invocation has been fixed from BaseMessage to AIMessage . Custom chat models implementing bind_tools should update their return signature:",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "InMemoryStore (development)",
        "type": "code",
        "content": "from langgraph.store.memory import InMemoryStore\n\nstore = InMemoryStore()\nagent = create_deep_agent(store=store, use_longterm_memory=True)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "2. Identify a checkpoint",
        "type": "code",
        "content": "# This is the state before last (states are listed in chronological order)\nselected_state = states[1]\nprint(selected_state.next)\nprint(selected_state.values)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-time-travel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Time travel"
    },
    {
        "title": "Google Cloud",
        "type": "code",
        "content": "langchain-google-cloud-sql-pg",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Error handling strategies",
        "type": "code",
        "content": "================================= Tool Message =================================\nName: ToolStrategy\n\nThere was an issue with the format. Try again.\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Basic usage example",
        "type": "text",
        "content": "LangGraph graphs expose the stream (sync) and astream (async) methods to yield streamed outputs as iterators.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Repository structure",
        "type": "text",
        "content": "LangChain is organized as a monorepo with multiple packages:",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Quick fix: submit a bugfix",
        "type": "text",
        "content": "Follow the PR template provided. If applicable, reference the issue you’re fixing using a closing keyword (e.g. Fixes #123 ).",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Quick edit: fix a typo",
        "type": "text",
        "content": "For simple changes like fixing typos, you can edit directly on GitHub without setting up a local development environment:\n\nPrerequisites:\n\nNavigate to any documentation page, scroll to the bottom of the page, and click the link “Edit the source of this page on GitHub”\n\nGitHub will prompt you to fork the repository to your account. Make sure to fork into your personal account\n\nCorrect the typo directly in GitHub’s web editor\n\nClick Commit changes... and give your commit a descriptive title like fix(docs): summary of change . If applicable, add an extended description",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "ToolStrategy",
        "type": "code",
        "content": "from pydantic import BaseModel\nfrom langchain.agents import create_agent\nfrom langchain.agents.structured_output import ToolStrategy\n\n\nclass ContactInfo(BaseModel):\n    name: str\n    email: str\n    phone: str\n\nagent = create_agent(\n    model=\"gpt-4o-mini\",\n    tools=[search_tool],\n    response_format=ToolStrategy(ContactInfo)\n)\n\nresult = agent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"Extract contact info from: John Doe, john@example.com, (555) 123-4567\"}]\n})\n\nresult[\"structured_response\"]\n# ContactInfo(name='John Doe', email='john@example.com', phone='(555) 123-4567')\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Async with Python < 3.11",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Hugging Face Hub Tools",
        "type": "code",
        "content": "pip install transformers huggingface_hub\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "After model",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Vertex AI",
        "type": "code",
        "content": "from langchain_google_vertexai import ChatVertexAI\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Invoke",
        "type": "code",
        "content": "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n\nconversation = [\n    SystemMessage(\"You are a helpful assistant that translates English to French.\"),\n    HumanMessage(\"Translate: I love programming.\"),\n    AIMessage(\"J'adore la programmation.\"),\n    HumanMessage(\"Translate: I love building applications.\")\n]\n\nresponse = model.invoke(conversation)\nprint(response)  # AIMessage(\"J'adore créer des applications.\")\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Profile",
        "type": "text",
        "content": "Memories can be a single, continuously updated “profile” of well-scoped and specific information about a user, organization, or other entity (including the agent itself). A profile is generally just a JSON document with various key-value pairs you’ve selected to represent your domain.\n\nWhen remembering a profile, you will want to make sure that you are updating the profile each time. As a result, you will want to pass in the previous profile and ask the model to generate a new profile (or some JSON patch to apply to the old profile). This can be become error-prone as the profile gets larger, and may benefit from splitting a profile into multiple documents or strict decoding when generating documents to ensure the memory schemas remains valid.",
        "side_link": "https://docs.langchain.com/oss/python/concepts/memory",
        "head_menu_name": "Learn",
        "side_menu_name": "Memory"
    },
    {
        "title": "Acreom",
        "type": "text",
        "content": "Knowledge management platform with AI-powered organization.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/all_providers",
        "head_menu_name": "Integrations",
        "side_menu_name": "All providers"
    },
    {
        "title": "Execution order",
        "type": "code",
        "content": "middleware3.before_model()",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Tutorial: Agentic RAG with Self-Correction",
        "type": "text",
        "content": "An example of Hybrid RAG that combines agentic reasoning with retrieval and self-correction.\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/retrieval",
        "head_menu_name": "LangChain",
        "side_menu_name": "Retrieval"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "pip install -qU langchain-cohere\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Bring-your-own documents",
        "type": "code",
        "content": "langchain-elasticsearch",
        "side_link": "https://docs.langchain.com/oss/python/integrations/retrievers",
        "head_menu_name": "Integrations",
        "side_menu_name": "Retrievers"
    },
    {
        "title": "Threads",
        "type": "code",
        "content": "{\"configurable\": {\"thread_id\": \"1\"}}\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Custom SQL Agent",
        "type": "text",
        "content": "Implement a SQL agent directly in LangGraph for maximum flexibility.",
        "side_link": "https://docs.langchain.com/oss/python/learn",
        "head_menu_name": "Learn",
        "side_menu_name": "Learn"
    },
    {
        "title": "Protocol reference",
        "type": "code",
        "content": "ls_info(path: str) -> list[FileInfo]",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Response Format",
        "type": "code",
        "content": "type[StructuredResponseT]",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Amazon DocumentDB Vector Search",
        "type": "text",
        "content": "Amazon DocumentDB (with MongoDB Compatibility) makes it easy to set up, operate, and scale MongoDB-compatible databases in the cloud.\nWith Amazon DocumentDB, you can run the same application code and use the same drivers and tools that you use with MongoDB.\nVector search for Amazon DocumentDB combines the flexibility and rich querying capability of a JSON-based document database with the power of vector search.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "2. Deploy to LangSmith",
        "type": "text",
        "content": "Log in to LangSmith . In the left sidebar, select Deployments .\n\nClick the + New Deployment button. A pane will open where you can fill in the required fields.\n\nIf you are a first time user or adding a private repository that has not been previously connected, click the Add new account button and follow the instructions to connect your GitHub account.\n\nSelect your application’s repository. Click Submit to deploy. This may take about 15 minutes to complete. You can check the status in the Deployment details view.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/deploy",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Deploy"
    },
    {
        "title": "StoreBackend (LangGraph Store)",
        "type": "code",
        "content": "from deepagents.backends import StoreBackend\n\nagent = create_deep_agent(\n    backend=(lambda rt: StoreBackend(rt))   # Note that the tools access Store through the runtime.store\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Token usage",
        "type": "code",
        "content": "from langchain.chat_models import init_chat_model\n\nmodel = init_chat_model(\"gpt-5-nano\")\n\nresponse = model.invoke(\"Hello!\")\nresponse.usage_metadata\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Philosophy",
        "type": "text",
        "content": "Aim to follow these core principles for all code contributions:",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Structured output",
        "type": "text",
        "content": "create_agent has improved structured output generation:",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Tailor configurations by risk",
        "type": "text",
        "content": "Configure different tools based on their risk level:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/human-in-the-loop",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Overview",
        "type": "text",
        "content": "A LangGraph application consists of one or more graphs, a configuration file ( langgraph.json ), a file that specifies dependencies, and an optional .env file that specifies environment variables.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/application-structure",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Application structure"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "pip install -qU langchain-azure-ai pymongo\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Multiple structured outputs error",
        "type": "text",
        "content": "When a model incorrectly calls multiple structured output tools, the agent provides error feedback in a ToolMessage and prompts the model to retry:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Summarize messages",
        "type": "code",
        "content": "from typing import Any, TypedDict\n\nfrom langchain.chat_models import init_chat_model\nfrom langchain.messages import AnyMessage\nfrom langchain_core.messages.utils import count_tokens_approximately\nfrom langgraph.graph import StateGraph, START, MessagesState\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langmem.short_term import SummarizationNode, RunningSummary  \n\nmodel = init_chat_model(\"claude-sonnet-4-5-20250929\")\nsummarization_model = model.bind(max_tokens=128)\n\nclass State(MessagesState):\n    context: dict[str, RunningSummary]  \n\nclass LLMInputState(TypedDict):  \n    summarized_messages: list[AnyMessage]\n    context: dict[str, RunningSummary]\n\nsummarization_node = SummarizationNode(  \n    token_counter=count_tokens_approximately,\n    model=summarization_model,\n    max_tokens=256,\n    max_tokens_before_summary=256,\n    max_summary_tokens=128,\n)\n\ndef call_model(state: LLMInputState):  \n    response = model.invoke(state[\"summarized_messages\"])\n    return {\"messages\": [response]}\n\ncheckpointer = InMemorySaver()\nbuilder = StateGraph(State)\nbuilder.add_node(call_model)\nbuilder.add_node(\"summarize\", summarization_node)  \nbuilder.add_edge(START, \"summarize\")\nbuilder.add_edge(\"summarize\", \"call_model\")\ngraph = builder.compile(checkpointer=checkpointer)\n\n# Invoke the graph\nconfig = {\"configurable\": {\"thread_id\": \"1\"}}\ngraph.invoke({\"messages\": \"hi, my name is bob\"}, config)\ngraph.invoke({\"messages\": \"write a short poem about cats\"}, config)\ngraph.invoke({\"messages\": \"now do the same but for dogs\"}, config)\nfinal_response = graph.invoke({\"messages\": \"what's my name?\"}, config)\n\nfinal_response[\"messages\"][-1].pretty_print()\nprint(\"\\nSummary:\", final_response[\"context\"][\"running_summary\"].summary)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Control",
        "type": "text",
        "content": "Add retries, fallbacks, and early termination logic",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Reasoning",
        "type": "code",
        "content": "for chunk in model.stream(\"Why do parrots have colorful feathers?\"):\n    reasoning_steps = [r for r in chunk.content_blocks if r[\"type\"] == \"reasoning\"]\n    print(reasoning_steps if reasoning_steps else chunk.text)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Wrap-style hooks",
        "type": "code",
        "content": "from langchain.agents.middleware import AgentMiddleware, ModelRequest, ModelResponse\nfrom typing import Callable\n\nclass RetryMiddleware(AgentMiddleware):\n    def __init__(self, max_retries: int = 3):\n        super().__init__()\n        self.max_retries = max_retries\n\n    def wrap_model_call(\n        self,\n        request: ModelRequest,\n        handler: Callable[[ModelRequest], ModelResponse],\n    ) -> ModelResponse:\n        for attempt in range(self.max_retries):\n            try:\n                return handler(request)\n            except Exception as e:\n                if attempt == self.max_retries - 1:\n                    raise\n                print(f\"Retry {attempt + 1}/{self.max_retries} after error: {e}\")\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Prebuilt middleware",
        "type": "code",
        "content": "SummarizationMiddleware",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Pre-model hook",
        "type": "text",
        "content": "Pre-model hooks are now implemented as middleware with the before_model method.\nThis new pattern is more extensible—you can define multiple middlewares to run before the model is called,\nreusing common patterns across different agents.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Structured outputs",
        "type": "code",
        "content": "from pydantic import BaseModel, Field\n\nclass Movie(BaseModel):\n    \"\"\"A movie with details.\"\"\"\n    title: str = Field(..., description=\"The title of the movie\")\n    year: int = Field(..., description=\"The year the movie was released\")\n    director: str = Field(..., description=\"The director of the movie\")\n    rating: float = Field(..., description=\"The movie's rating out of 10\")\n\nmodel_with_structure = model.with_structured_output(Movie)\nresponse = model_with_structure.invoke(\"Provide details about the movie Inception\")\nprint(response)  # Movie(title=\"Inception\", year=2010, director=\"Christopher Nolan\", rating=8.8)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Custom tool description",
        "type": "code",
        "content": "@tool(\"calculator\", description=\"Performs arithmetic calculations. Use this for any math problems.\")\ndef calc(expression: str) -> str:\n    \"\"\"Evaluate mathematical expressions.\"\"\"\n    return str(eval(expression))\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "Response Format",
        "type": "text",
        "content": "Schema specification for the model’s final response.\n\nAll of these types of model context can draw from state (short-term memory), store (long-term memory), or runtime context (static configuration).",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Install LangChain",
        "type": "text",
        "content": "LangChain provides integrations to hundreds of LLMs and thousands of other integrations. These live in independent provider packages. For example:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/install",
        "head_menu_name": "LangChain",
        "side_menu_name": "Install"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "from langchain_core.vectorstores import InMemoryVectorStore\n\nvector_store = InMemoryVectorStore(embeddings)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Azure Cosmos DB for Apache Gremlin",
        "type": "code",
        "content": "from langchain_community.graphs import GremlinGraph\nfrom langchain_community.graphs.graph_document import GraphDocument, Node, Relationship\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Wrap-style hooks",
        "type": "text",
        "content": "Intercept execution with full control over handler calls. Use for retries, caching, and transformation.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Google Jobs",
        "type": "code",
        "content": "pip install google-search-results langchain-community # Requires langchain-community\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Bing Search",
        "type": "text",
        "content": "Follow the documentation here to get a detail explanations and instructions of this tool.\n\nThe environment variable BING_SUBSCRIPTION_KEY and BING_SEARCH_URL are required from Bing Search resource.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Delete messages",
        "type": "text",
        "content": "When deleting messages, make sure that the resulting message history is valid. Check the limitations of the LLM provider you’re using. For example:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Stream subgraph outputs",
        "type": "text",
        "content": "The outputs will be streamed as tuples (namespace, data) , where namespace is a tuple with the path to the node where a subgraph is invoked, e.g. (\"parent_node:<task_id>\", \"child_node:<task_id>\") .",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Backwards compatibility",
        "type": "text",
        "content": "Breaking changes to public APIs are not allowed except for critical security fixes.\n\nSee our versioning policy for details on major version releases.\n\nMaintain compatibility:\n\nAlways preserve :\n\nAcceptable modifications :\n\nAdding new optional parameters\n\nAdding new methods to classes\n\nImproving performance without changing behavior\n\nAdding new modules or functions\n\nWould this break existing user code?\n\nCheck if your target is public\n\nIf needed, is it exported in __init__.py ?",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Static prompt rename",
        "type": "text",
        "content": "The prompt parameter has been renamed to system_prompt :",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Model",
        "type": "text",
        "content": "This functionality has been ported to the middleware interface in v1.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Mocking Chat Model",
        "type": "code",
        "content": "from langchain_core.language_models.fake_chat_models import GenericFakeChatModel\n\nmodel = GenericFakeChatModel(messages=iter([\n    AIMessage(content=\"\", tool_calls=[ToolCall(name=\"foo\", args={\"bar\": \"baz\"}, id=\"call_1\")]),\n    \"bar\"\n]))\n\nmodel.invoke(\"hello\")\n# AIMessage(content='', ..., tool_calls=[{'name': 'foo', 'args': {'bar': 'baz'}, 'id': 'call_1', 'type': 'tool_call'}])\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Caching",
        "type": "code",
        "content": "CacheBackedEmbeddings",
        "side_link": "https://docs.langchain.com/oss/python/integrations/text_embedding",
        "head_menu_name": "Integrations",
        "side_menu_name": "Embedding models"
    },
    {
        "title": "Similarity metrics & indexing",
        "type": "text",
        "content": "Embedding similarity may be computed using:\n\nEfficient search often employs indexing methods such as HNSW (Hierarchical Navigable Small World), though specifics depend on the vector store.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Approve or reject",
        "type": "code",
        "content": "from typing import Literal\nfrom langgraph.types import interrupt, Command\n\ndef approval_node(state: State) -> Command[Literal[\"proceed\", \"cancel\"]]:\n    # Pause execution; payload shows up under result[\"__interrupt__\"]\n    is_approved = interrupt({\n        \"question\": \"Do you want to proceed with this action?\",\n        \"details\": state[\"action_details\"]\n    })\n\n    # Route based on the response\n    if is_approved:\n        return Command(goto=\"proceed\")  # Runs after the resume payload is provided\n    else:\n        return Command(goto=\"cancel\")\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Pre-bound models",
        "type": "text",
        "content": "To better support structured output, create_agent no longer accepts pre-bound models with tools or configuration:",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Tool Message",
        "type": "text",
        "content": "The name of the tool that was called.\n\nAdditional data not sent to the model but can be accessed programmatically.\n\nThe artifact field stores supplementary data that won’t be sent to the model but can be accessed programmatically. This is useful for storing raw results, debugging information, or data for downstream processing without cluttering the model’s context.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Error handling strategies",
        "type": "code",
        "content": "================================= Tool Message =================================\nName: ProductRating\n\nPlease provide a valid rating between 1-5 and include a comment.\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Metadata filtering",
        "type": "text",
        "content": "Filtering by metadata (e.g., source, date) can refine search results:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Vertex AI Model Garden",
        "type": "code",
        "content": "from langchain_google_vertexai import VertexAIModelGarden\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "YouTube Transcripts Loader",
        "type": "code",
        "content": "pip install youtube-transcript-api langchain-community # Requires langchain-community\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Key Insights",
        "type": "text",
        "content": "Building this email agent has shown us the LangGraph way of thinking:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Deprecations",
        "type": "text",
        "content": "The following table lists all items deprecated in LangGraph v1:",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langgraph-v1",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "4. Create a LangGraph config file",
        "type": "text",
        "content": "Inside your app’s directory, create a configuration file langgraph.json :",
        "side_link": "https://docs.langchain.com/oss/python/langchain/studio",
        "head_menu_name": "LangChain",
        "side_menu_name": "Studio"
    },
    {
        "title": "Google Search",
        "type": "code",
        "content": "from langchain_community.tools import GoogleSearchRun, GoogleSearchResults\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Office 365 individual tools",
        "type": "code",
        "content": "O365CreateDraftMessage",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "AlloyDB for PostgreSQL",
        "type": "text",
        "content": "Google Cloud AlloyDB is a fully managed relational database service that offers high performance, seamless integration, and impressive scalability on Google Cloud. AlloyDB is 100% compatible with PostgreSQL.\n\nInstall the python package:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Prompt",
        "type": "text",
        "content": "Access short term memory (state) in middleware to create dynamic prompts based on conversation history or custom state fields.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Microsoft SharePoint",
        "type": "text",
        "content": "Microsoft SharePoint is a website-based collaboration system\nthat uses workflow applications, “list” databases, and other web parts and security features to\nempower business teams to work together developed by Microsoft.\n\nSee a usage example .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Error handling strategies",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Speech-to-Text",
        "type": "code",
        "content": "from langchain_google_community import SpeechToTextLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Ways to Contribute",
        "type": "text",
        "content": "Found a bug? Please help us fix it by following these steps:\n\nCheck if the issue already exists in our GitHub Issues for the respective repo:",
        "side_link": "https://docs.langchain.com/oss/python/contributing/overview",
        "head_menu_name": "Contribute",
        "side_menu_name": "Overview"
    },
    {
        "title": "Subagent middleware",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/middleware",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Middleware"
    },
    {
        "title": "\"sync\"",
        "type": "code",
        "content": "graph.stream(\n    {\"input\": \"test\"},\n    durability=\"sync\"\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/durable-execution",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Durable execution"
    },
    {
        "title": "Collection",
        "type": "text",
        "content": "Alternatively, memories can be a collection of documents that are continuously updated and extended over time. Each individual memory can be more narrowly scoped and easier to generate, which means that you’re less likely to lose information over time. It’s easier for an LLM to generate new objects for new information than reconcile new information with an existing profile. As a result, a document collection tends to lead to higher recall downstream .\n\nHowever, this shifts some complexity memory updating. The model must now delete or update existing items in the list, which can be tricky. In addition, some models may default to over-inserting and others may default to over-updating. See the Trustcall package for one way to manage this and consider evaluation (e.g., with a tool like LangSmith ) to help you tune the behavior.\n\nWorking with document collections also shifts complexity to memory search over the list. The Store currently supports both semantic search and filtering by content .",
        "side_link": "https://docs.langchain.com/oss/python/concepts/memory",
        "head_menu_name": "Learn",
        "side_menu_name": "Memory"
    },
    {
        "title": "Aleph Alpha",
        "type": "text",
        "content": "European AI company’s multilingual language models.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/all_providers",
        "head_menu_name": "Integrations",
        "side_menu_name": "All providers"
    },
    {
        "title": "Error handling",
        "type": "text",
        "content": "Models can make mistakes when generating structured output via tool calling. LangChain provides intelligent retry mechanisms to handle these errors automatically.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Configurable models",
        "type": "code",
        "content": "first_model.invoke(\n    \"what's your name\",\n    config={\n        \"configurable\": {\n            \"first_model\": \"claude-sonnet-4-5-20250929\",\n            \"first_temperature\": 0.5,\n            \"first_max_tokens\": 100,\n        }\n    },\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Initialize a model",
        "type": "code",
        "content": "pip install -U \"langchain[openai]\"\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Subagent not being called",
        "type": "code",
        "content": "# ✅ Good\n{\"name\": \"research-specialist\", \"description\": \"Conducts in-depth research on specific topics using web search. Use when you need detailed information that requires multiple searches.\"}\n\n# ❌ Bad\n{\"name\": \"helper\", \"description\": \"helps with stuff\"}\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Structured outputs",
        "type": "text",
        "content": "It can be useful to return the raw AIMessage object alongside the parsed representation to access response metadata such as token counts . To do this, set include_raw=True when calling with_structured_output :",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Provider strategy",
        "type": "code",
        "content": "from pydantic import BaseModel\nfrom langchain.agents import create_agent\n\n\nclass ContactInfo(BaseModel):\n    \"\"\"Contact information for a person.\"\"\"\n    name: str = Field(description=\"The name of the person\")\n    email: str = Field(description=\"The email address of the person\")\n    phone: str = Field(description=\"The phone number of the person\")\n\nagent = create_agent(\n    model=\"gpt-5\",\n    tools=tools,\n    response_format=ContactInfo  # Auto-selects ProviderStrategy\n)\n\nresult = agent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"Extract contact info from: John Doe, john@example.com, (555) 123-4567\"}]\n})\n\nresult[\"structured_response\"]\n# ContactInfo(name='John Doe', email='john@example.com', phone='(555) 123-4567')\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Speech-to-Text",
        "type": "text",
        "content": "Google Cloud Speech-to-Text transcribes audio files.\n\nInstall with Speech-to-Text dependencies:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Prompt",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom typing import TypedDict\nfrom langchain.agents.middleware import dynamic_prompt, ModelRequest\n\n\nclass CustomContext(TypedDict):\n    user_name: str\n\n\ndef get_weather(city: str) -> str:\n    \"\"\"Get the weather in a city.\"\"\"\n    return f\"The weather in {city} is always sunny!\"\n\n\n@dynamic_prompt\ndef dynamic_system_prompt(request: ModelRequest) -> str:\n    user_name = request.runtime.context[\"user_name\"]\n    system_prompt = f\"You are a helpful assistant. Address the user as {user_name}.\"\n    return system_prompt\n\n\nagent = create_agent(\n    model=\"gpt-5-nano\",\n    tools=[get_weather],\n    middleware=[dynamic_system_prompt],\n    context_schema=CustomContext,\n)\n\nresult = agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n    context=CustomContext(user_name=\"John Smith\"),\n)\nfor msg in result[\"messages\"]:\n    msg.pretty_print()\n\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Long-term memory",
        "type": "text",
        "content": "Extend agents with persistent memory across threads using LangGraph’s Store. Agents can save and retrieve information from previous conversations.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/overview",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Overview"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "from qdrant_client.models import Distance, VectorParams\nfrom langchain_qdrant import QdrantVectorStore\nfrom qdrant_client import QdrantClient\n\nclient = QdrantClient(\":memory:\")\n\nvector_size = len(embeddings.embed_query(\"sample text\"))\n\nif not client.collection_exists(\"test\"):\n    client.create_collection(\n        collection_name=\"test\",\n        vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE)\n    )\nvector_store = QdrantVectorStore(\n    client=client,\n    collection_name=\"test\",\n    embedding=embeddings,\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Vertex AI image captioning",
        "type": "code",
        "content": "langchain-google-vertexai",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Vertex AI callback handler",
        "type": "code",
        "content": "langchain-google-vertexai",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Creating workers in LangGraph",
        "type": "text",
        "content": "Orchestrator-worker workflows are common and LangGraph has built-in support for them. The Send API lets you dynamically create worker nodes and send them specific inputs. Each worker has its own state, and all worker outputs are written to a shared state key that is accessible to the orchestrator graph. This gives the orchestrator access to all worker output and allows it to synthesize them into a final output. The example below iterates over a list of sections and uses the Send API to send a section to each worker.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/workflows-agents",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Workflows + agents"
    },
    {
        "title": "Log to a project",
        "type": "text",
        "content": "You can set a custom project name for your entire application by setting the LANGSMITH_PROJECT environment variable:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/observability",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Observability"
    },
    {
        "title": "Filter by node",
        "type": "code",
        "content": "stream_mode=\"messages\"",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Trace selectively",
        "type": "code",
        "content": "import langsmith as ls\n\n# This WILL be traced\nwith ls.tracing_context(enabled=True):\n    agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Send a test email to alice@example.com\"}]})\n\n# This will NOT be traced (if LANGSMITH_TRACING is not set)\nagent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Send another email\"}]})\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/observability",
        "head_menu_name": "LangChain",
        "side_menu_name": "Observability"
    },
    {
        "title": "2. Create a LangGraph app 🌱",
        "type": "text",
        "content": "Additional templates If you use langgraph new without specifying a template, you will be presented with an interactive menu that will allow you to choose from a list of available templates.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/local-server",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Local server"
    },
    {
        "title": "Hugging Face model loader",
        "type": "code",
        "content": "from langchain_community.document_loaders import HuggingFaceModelLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Dynamic prompts",
        "type": "text",
        "content": "Dynamic prompts are a core context engineering pattern— they adapt what you tell the model based on the current conversation state. To do this, use the @dynamic_prompt decorator:",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "pip install -qU langchain-community\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Step 3: Design your state",
        "type": "text",
        "content": "State is the shared memory accessible to all nodes in your agent. Think of it as the notebook your agent uses to keep track of everything it learns and decides as it works through the process.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "LangSmith Integration",
        "type": "code",
        "content": "import pytest\nfrom langsmith import testing as t\nfrom agentevals.trajectory.llm import create_trajectory_llm_as_judge, TRAJECTORY_ACCURACY_PROMPT\n\ntrajectory_evaluator = create_trajectory_llm_as_judge(\n    model=\"openai:o3-mini\",\n    prompt=TRAJECTORY_ACCURACY_PROMPT,\n)\n\n@pytest.mark.langsmith\ndef test_trajectory_accuracy():\n    result = agent.invoke({\n        \"messages\": [HumanMessage(content=\"What's the weather in SF?\")]\n    })\n\n    reference_trajectory = [\n        HumanMessage(content=\"What's the weather in SF?\"),\n        AIMessage(content=\"\", tool_calls=[\n            {\"id\": \"call_1\", \"name\": \"get_weather\", \"args\": {\"city\": \"SF\"}},\n        ]),\n        ToolMessage(content=\"It's 75 degrees and sunny in SF.\", tool_call_id=\"call_1\"),\n        AIMessage(content=\"The weather in SF is 75 degrees and sunny.\"),\n    ]\n\n    # Log inputs, outputs, and reference outputs to LangSmith\n    t.log_inputs({})\n    t.log_outputs({\"messages\": result[\"messages\"]})\n    t.log_reference_outputs({\"messages\": reference_trajectory})\n\n    trajectory_evaluator(\n        outputs=result[\"messages\"],\n        reference_outputs=reference_trajectory\n    )\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Test writing guidelines",
        "type": "text",
        "content": "In order to write effective tests, there’s a few good practices to follow:",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Memory overview",
        "type": "text",
        "content": "Memory is a system that remembers information about previous interactions. For AI agents, memory is crucial because it lets them remember previous interactions, learn from feedback, and adapt to user preferences. As agents tackle more complex tasks with numerous user interactions, this capability becomes essential for both efficiency and user satisfaction.\n\nThis conceptual guide covers two types of memory, based on their recall scope:",
        "side_link": "https://docs.langchain.com/oss/python/concepts/memory",
        "head_menu_name": "Learn",
        "side_menu_name": "Memory"
    },
    {
        "title": "Tool retry",
        "type": "text",
        "content": "Maximum number of retry attempts after the initial call (3 total attempts with default)\n\nOptional list of tools or tool names to apply retry logic to. If None , applies to all tools.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Development environment",
        "type": "text",
        "content": "For changes to community integrations (located in a separate repo ):",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Combine multiple guardrails",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import PIIMiddleware, HumanInTheLoopMiddleware\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[search_tool, send_email_tool],\n    middleware=[\n        # Layer 1: Deterministic input filter (before agent)\n        ContentFilterMiddleware(banned_keywords=[\"hack\", \"exploit\"]),\n\n        # Layer 2: PII protection (before and after model)\n        PIIMiddleware(\"email\", strategy=\"redact\", apply_to_input=True),\n        PIIMiddleware(\"email\", strategy=\"redact\", apply_to_output=True),\n\n        # Layer 3: Human approval for sensitive tools\n        HumanInTheLoopMiddleware(interrupt_on={\"send_email\": True}),\n\n        # Layer 4: Model-based safety check (after agent)\n        SafetyGuardrailMiddleware(),\n    ],\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/guardrails",
        "head_menu_name": "LangChain",
        "side_menu_name": "Guardrails"
    },
    {
        "title": "Vertex AI Vector Search",
        "type": "code",
        "content": "from langchain_google_vertexai import VectorSearchVectorStore\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "AI Message",
        "type": "code",
        "content": "from langchain.messages import AIMessage, SystemMessage, HumanMessage\n\n# Create an AI message manually (e.g., for conversation history)\nai_msg = AIMessage(\"I'd be happy to help you with that question!\")\n\n# Add to conversation history\nmessages = [\n    SystemMessage(\"You are a helpful assistant\"),\n    HumanMessage(\"Can you help me?\"),\n    ai_msg,  # Insert as if it came from the model\n    HumanMessage(\"Great! What's 2+2?\")\n]\n\nresponse = model.invoke(messages)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Using tasks in nodes",
        "type": "text",
        "content": "If a node contains multiple operations, you may find it easier to convert each operation into a task rather than refactor the operations into individual nodes.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/durable-execution",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Durable execution"
    },
    {
        "title": "6. Test your application in Studio",
        "type": "text",
        "content": "Studio is a specialized UI that you can connect to LangGraph API server to visualize, interact with, and debug your application locally. Test your graph in Studio by visiting the URL provided in the output of the langgraph dev command:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/local-server",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Local server"
    },
    {
        "title": "Amazon Kendra",
        "type": "text",
        "content": "With Kendra , we can search across a wide range of content types, including documents, FAQs, knowledge bases,\nmanuals, and websites. It supports multiple languages and can understand complex queries, synonyms, and\ncontextual meanings to provide highly relevant search results.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Google Lens",
        "type": "text",
        "content": "Perform visual searches. Requires google-search-results package and SerpApi key.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "AWS Glue",
        "type": "code",
        "content": "from langchain_community.document_loaders.glue_catalog import GlueCatalogLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Match decision order to actions",
        "type": "text",
        "content": "The decisions list must match the order of action_requests :",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/human-in-the-loop",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "create_agent",
        "type": "code",
        "content": "langgraph.prebuilt.create_react_agent",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Protocol reference",
        "type": "code",
        "content": "EditResult(error, path, files_update, occurrences)",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Defining tools",
        "type": "code",
        "content": "from langchain.tools import tool\n\n@tool(parse_docstring=True)\ndef search_orders(\n    user_id: str,\n    status: str,\n    limit: int = 10\n) -> str:\n    \"\"\"Search for user orders by status.\n\n    Use this when the user asks about order history or wants to check\n    order status. Always filter by the provided status.\n\n    Args:\n        user_id: Unique identifier for the user\n        status: Order status: 'pending', 'shipped', or 'delivered'\n        limit: Maximum number of results to return\n    \"\"\"\n    # Implementation here\n    pass\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "What's new in v1",
        "type": "text",
        "content": "LangChain v1 is a focused, production-ready foundation for building agents. We’ve streamlined the framework around three core improvements:",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Recording & Replaying HTTP Calls",
        "type": "text",
        "content": "When you modify prompts, add new tools, or change expected trajectories, your saved cassettes will become outdated and your existing tests will fail . You should delete the corresponding cassette files and rerun the tests to record fresh interactions.\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Tool calling",
        "type": "text",
        "content": "The model intelligently determines when parallel execution is appropriate based on the independence of the requested operations.\n\nMost models supporting tool calling enable parallel tool calls by default. Some (including OpenAI and Anthropic ) allow you to disable this feature. To do this, set parallel_tool_calls=False :",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Execution order",
        "type": "code",
        "content": "middleware3.after_agent()",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "import getpass\nimport os\n\nif not os.environ.get(\"NVIDIA_API_KEY\"):\n  os.environ[\"NVIDIA_API_KEY\"] = getpass.getpass(\"Enter API key for NVIDIA: \")\n\nfrom langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n\nembeddings = NVIDIAEmbeddings(model=\"NV-Embed-QA\")\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Defining state viastate_schema",
        "type": "text",
        "content": "To learn more about memory, see Memory . For information on implementing long-term memory that persists across sessions, see Long-term memory .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Store is required",
        "type": "code",
        "content": "# ❌ This will error\nagent = create_deep_agent(use_longterm_memory=True)  # Missing store!\n\n# ✅ Correct\nagent = create_deep_agent(\n    use_longterm_memory=True,\n    store=InMemoryStore()\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "What belongs in state?",
        "type": "text",
        "content": "Ask yourself these questions about each piece of data:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "langchain-classic",
        "type": "text",
        "content": "If you use any of this functionality, install langchain-classic :",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "from langchain_google_vertexai import VertexAIEmbeddings\n\nembeddings = VertexAIEmbeddings(model=\"text-embedding-005\")\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "6. View your agent in Studio",
        "type": "code",
        "content": "https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/studio",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Studio"
    },
    {
        "title": "Azure OpenAI",
        "type": "code",
        "content": "import os\n\nos.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://<your-endpoint.openai.azure.com/\"\nos.environ[\"AZURE_OPENAI_API_KEY\"] = \"your AzureOpenAI key\"\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Node-style hooks",
        "type": "code",
        "content": "from langchain.agents.middleware import AgentMiddleware, AgentState\nfrom langgraph.runtime import Runtime\nfrom typing import Any\n\nclass LoggingMiddleware(AgentMiddleware):\n    def before_model(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n        print(f\"About to call model with {len(state['messages'])} messages\")\n        return None\n\n    def after_model(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n        print(f\"Model returned: {state['messages'][-1].content}\")\n        return None\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Use time-travel",
        "type": "text",
        "content": "For a conceptual overview of time-travel, see Time travel .",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-time-travel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Time travel"
    },
    {
        "title": "Decision types",
        "type": "text",
        "content": "You can customize which decisions are available for each tool:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/human-in-the-loop",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Amazon Neptune",
        "type": "code",
        "content": "pip install langchain-aws\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Decorator-based middleware",
        "type": "text",
        "content": "For simple middleware that only needs a single hook, decorators provide the quickest way to add functionality:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Integration Testing",
        "type": "text",
        "content": "Many agent behaviors only emerge when using a real LLM, such as which tool the agent decides to call, how it formats responses, or whether a prompt modification affects the entire execution trajectory. LangChain’s agentevals package provides evaluators specifically designed for testing agent trajectories with live models.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Stream",
        "type": "text",
        "content": "Invoke the model, but stream the output as it is generated in real-time.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Install LangChain",
        "type": "code",
        "content": "# Installing the OpenAI integration\npip install -U langchain-openai\n\n# Installing the Anthropic integration\npip install -U langchain-anthropic\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/install",
        "head_menu_name": "LangChain",
        "side_menu_name": "Install"
    },
    {
        "title": "Error handling strategies",
        "type": "text",
        "content": "If handle_errors is an exception type, the agent will only retry (using the default error message) if the exception raised is the specified type. In all other cases, the exception will be raised.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "In a workflow",
        "type": "text",
        "content": "This example builds a simple LangGraph workflow that generates a joke topic and writes a joke using an LLM. It demonstrates how to run the graph, retrieve past execution checkpoints, optionally modify the state, and resume execution from a chosen checkpoint to explore alternate outcomes.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-time-travel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Time travel"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "pip install -qU langchain-core\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Tool use in the ReAct loop",
        "type": "code",
        "content": "================================ Human Message =================================\n\nFind the most popular wireless headphones right now and check if they're in stock\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "High-level API",
        "type": "code",
        "content": "{'__start__': <langgraph.pregel.read.PregelNode at 0x7d05e3ba1810>,\n 'write_essay': <langgraph.pregel.read.PregelNode at 0x7d05e3ba14d0>,\n 'score_essay': <langgraph.pregel.read.PregelNode at 0x7d05e3ba1710>}\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/pregel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Runtime"
    },
    {
        "title": "Airbyte",
        "type": "text",
        "content": "Data integration platform for ETL and ELT pipelines.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/all_providers",
        "head_menu_name": "Integrations",
        "side_menu_name": "All providers"
    },
    {
        "title": "Tool retry",
        "type": "text",
        "content": "Multiplier for exponential backoff. Each retry waits initial_delay * (backoff_factor ** retry_number) seconds. Set to 0.0 for constant delay.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Error handling strategies",
        "type": "code",
        "content": "StructuredOutputValidationError",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Getting Started",
        "type": "text",
        "content": "Here is a quick example of how to use MCP Toolbox to connect to your database:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "User preferences",
        "type": "code",
        "content": "agent = create_deep_agent(\n    store=store,\n    use_longterm_memory=True,\n    system_prompt=\"\"\"When users tell you their preferences, save them to\n    /memories/user_preferences.txt so you remember them in future conversations.\"\"\"\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Debugging",
        "type": "text",
        "content": "Use the debug streaming mode to stream as much information as possible throughout the execution of the graph. The streamed outputs include the name of the node as well as the full state.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Server-side tool use",
        "type": "code",
        "content": "[\n    {\n        \"type\": \"server_tool_call\",\n        \"name\": \"web_search\",\n        \"args\": {\n            \"query\": \"positive news stories today\",\n            \"type\": \"search\"\n        },\n        \"id\": \"ws_abc123\"\n    },\n    {\n        \"type\": \"server_tool_result\",\n        \"tool_call_id\": \"ws_abc123\",\n        \"status\": \"success\"\n    },\n    {\n        \"type\": \"text\",\n        \"text\": \"Here are some positive news stories from today...\",\n        \"annotations\": [\n            {\n                \"end_index\": 410,\n                \"start_index\": 337,\n                \"title\": \"article title\",\n                \"type\": \"citation\",\n                \"url\": \"...\"\n            }\n        ]\n    }\n]\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Static model",
        "type": "text",
        "content": "Static models are configured once when creating the agent and remain unchanged throughout execution. This is the most common and straightforward approach.\n\nTo initialize a static model from a model identifier string :",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Step 5: Wire it together",
        "type": "code",
        "content": "from langgraph.checkpoint.memory import MemorySaver\nfrom langgraph.types import RetryPolicy\n\n# Create the graph\nworkflow = StateGraph(EmailAgentState)\n\n# Add nodes with appropriate error handling\nworkflow.add_node(\"read_email\", read_email)\nworkflow.add_node(\"classify_intent\", classify_intent)\n\n# Add retry policy for nodes that might have transient failures\nworkflow.add_node(\n    \"search_documentation\",\n    search_documentation,\n    retry_policy=RetryPolicy(max_attempts=3)\n)\nworkflow.add_node(\"bug_tracking\", bug_tracking)\nworkflow.add_node(\"draft_response\", draft_response)\nworkflow.add_node(\"human_review\", human_review)\nworkflow.add_node(\"send_reply\", send_reply)\n\n# Add only the essential edges\nworkflow.add_edge(START, \"read_email\")\nworkflow.add_edge(\"read_email\", \"classify_intent\")\nworkflow.add_edge(\"send_reply\", END)\n\n# Compile with checkpointer for persistence, in case run graph with Local_Server --> Please compile without checkpointer\nmemory = MemorySaver()\napp = workflow.compile(checkpointer=memory)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Philosophy",
        "type": "text",
        "content": "LangChain is driven by a few core beliefs:\n\nWith LangChain, we have two core focuses:\n\nDifferent providers expose different APIs, with different model parameters and different message formats.\nStandardizing these model inputs and outputs is a core focus, making it easy for developer to easily change to the most recent state-of-the-art model, avoiding lock-in.\n\nModels should be used for more than just text generation - they should also be used to orchestrate more complex flows that interact with other data. LangChain makes it easy to define tools that LLMs can use dynamically, as well as help with parsing of and access to unstructured data.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/philosophy",
        "head_menu_name": "LangChain",
        "side_menu_name": "Philosophy"
    },
    {
        "title": "Memory",
        "type": "text",
        "content": "state_schema is still supported for backwards compatibility on create_agent .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "from langchain_huggingface import HuggingFaceEmbeddings\n\nembeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "ScaNN (Local Index)",
        "type": "code",
        "content": "from langchain_community.vectorstores import ScaNN\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Graphs",
        "type": "text",
        "content": "Use the graphs key in the LangGraph configuration file to specify which graphs will be available in the deployed LangGraph application.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/application-structure",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Application structure"
    },
    {
        "title": "create_react_agent→create_agent",
        "type": "code",
        "content": "from langchain.agents import create_agent\n\nagent = create_agent(  \n    model,\n    tools,\n    system_prompt=\"You are a helpful assistant.\",\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langgraph-v1",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Filter by LLM invocation",
        "type": "code",
        "content": "from typing import TypedDict\n\nfrom langchain.chat_models import init_chat_model\nfrom langgraph.graph import START, StateGraph\n\n# The joke_model is tagged with \"joke\"\njoke_model = init_chat_model(model=\"gpt-4o-mini\", tags=[\"joke\"])\n# The poem_model is tagged with \"poem\"\npoem_model = init_chat_model(model=\"gpt-4o-mini\", tags=[\"poem\"])\n\n\nclass State(TypedDict):\n      topic: str\n      joke: str\n      poem: str\n\n\nasync def call_model(state, config):\n      topic = state[\"topic\"]\n      print(\"Writing joke...\")\n      # Note: Passing the config through explicitly is required for python < 3.11\n      # Since context var support wasn't added before then: https://docs.python.org/3/library/asyncio-task.html#creating-tasks\n      # The config is passed through explicitly to ensure the context vars are propagated correctly\n      # This is required for Python < 3.11 when using async code. Please see the async section for more details\n      joke_response = await joke_model.ainvoke(\n            [{\"role\": \"user\", \"content\": f\"Write a joke about {topic}\"}],\n            config,\n      )\n      print(\"\\n\\nWriting poem...\")\n      poem_response = await poem_model.ainvoke(\n            [{\"role\": \"user\", \"content\": f\"Write a short poem about {topic}\"}],\n            config,\n      )\n      return {\"joke\": joke_response.content, \"poem\": poem_response.content}\n\n\ngraph = (\n      StateGraph(State)\n      .add_node(call_model)\n      .add_edge(START, \"call_model\")\n      .compile()\n)\n\n# The stream_mode is set to \"messages\" to stream LLM tokens\n# The metadata contains information about the LLM invocation, including the tags\nasync for msg, metadata in graph.astream(\n      {\"topic\": \"cats\"},\n      stream_mode=\"messages\",\n):\n    if metadata[\"tags\"] == [\"joke\"]:\n        print(msg.content, end=\"|\", flush=True)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Using CompiledSubAgent",
        "type": "code",
        "content": "from deepagents import create_deep_agent, CompiledSubAgent\nfrom langchain.agents import create_agent\n\n# Create a custom agent graph\ncustom_graph = create_agent(\n    model=your_model,\n    tools=specialized_tools,\n    prompt=\"You are a specialized agent for data analysis...\"\n)\n\n# Use it as a custom subagent\ncustom_subagent = CompiledSubAgent(\n    name=\"data-analyzer\",\n    description=\"Specialized agent for complex data analysis tasks\",\n    runnable=custom_graph\n)\n\nsubagents = [custom_subagent]\n\nagent = create_deep_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    tools=[internet_search],\n    system_prompt=research_instructions,\n    subagents=subagents\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "\"async\"",
        "type": "text",
        "content": "Changes are persisted asynchronously while the next step executes. This provides good performance and durability, but there’s a small risk that checkpoints might not be written if the process crashes during execution.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/durable-execution",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Durable execution"
    },
    {
        "title": "Validating human input",
        "type": "code",
        "content": "import sqlite3\nfrom typing import TypedDict\n\nfrom langgraph.checkpoint.sqlite import SqliteSaver\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.types import Command, interrupt\n\n\nclass FormState(TypedDict):\n    age: int | None\n\n\ndef get_age_node(state: FormState):\n    prompt = \"What is your age?\"\n\n    while True:\n        answer = interrupt(prompt)  # payload surfaces in result[\"__interrupt__\"]\n\n        if isinstance(answer, int) and answer > 0:\n            return {\"age\": answer}\n\n        prompt = f\"'{answer}' is not a valid age. Please enter a positive number.\"\n\n\nbuilder = StateGraph(FormState)\nbuilder.add_node(\"collect_age\", get_age_node)\nbuilder.add_edge(START, \"collect_age\")\nbuilder.add_edge(\"collect_age\", END)\n\ncheckpointer = SqliteSaver(sqlite3.connect(\"forms.db\"))\ngraph = builder.compile(checkpointer=checkpointer)\n\nconfig = {\"configurable\": {\"thread_id\": \"form-1\"}}\nfirst = graph.invoke({\"age\": None}, config=config)\nprint(first[\"__interrupt__\"])  # -> [Interrupt(value='What is your age?', ...)]\n\n# Provide invalid data; the node re-prompts\nretry = graph.invoke(Command(resume=\"thirty\"), config=config)\nprint(retry[\"__interrupt__\"])  # -> [Interrupt(value=\"'thirty' is not a valid age...\", ...)]\n\n# Provide valid data; loop exits and state updates\nfinal = graph.invoke(Command(resume=30), config=config)\nprint(final[\"age\"])  # -> 30\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Custom middleware",
        "type": "text",
        "content": "You can also build custom middleware to fit your needs. Middleware exposes hooks at each step in an agent’s execution:\n\nBuild custom middleware by implementing any of these hooks on a subclass of the AgentMiddleware class:",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Content block reference",
        "type": "text",
        "content": "URL pointing to the file location.\n\nBase64-encoded file data.\n\nReference ID to an externally stored file (e.g., in a provider’s file system or in a bucket).\n\nFile MIME type (e.g., application/pdf )",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Memory storage",
        "type": "code",
        "content": "from langgraph.store.memory import InMemoryStore\n\n\ndef embed(texts: list[str]) -> list[list[float]]:\n    # Replace with an actual embedding function or LangChain embeddings object\n    return [[1.0, 2.0] * len(texts)]\n\n\n# InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production use.\nstore = InMemoryStore(index={\"embed\": embed, \"dims\": 2}) \nuser_id = \"my-user\"\napplication_context = \"chitchat\"\nnamespace = (user_id, application_context) \nstore.put( \n    namespace,\n    \"a-memory\",\n    {\n        \"rules\": [\n            \"User likes short, direct language\",\n            \"User only speaks English & python\",\n        ],\n        \"my-key\": \"my-value\",\n    },\n)\n# get the \"memory\" by ID\nitem = store.get(namespace, \"a-memory\") \n# search for \"memories\" within this namespace, filtering on content equivalence, sorted by vector similarity\nitems = store.search( \n    namespace, filter={\"my-key\": \"my-value\"}, query=\"language preferences\"\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/long-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "LangGraph runtime",
        "type": "text",
        "content": "Compiling a StateGraph or creating an @entrypoint produces a Pregel instance that can be invoked with input.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/pregel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Runtime"
    },
    {
        "title": "Gemma local from Kaggle",
        "type": "text",
        "content": "Local Gemma model loaded from Kaggle. Requires langchain-google-vertexai .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "AI Message",
        "type": "text",
        "content": "Providers weigh/contextualize types of messages differently, which means it is sometimes helpful to manually create a new AIMessage object and insert it into the message history as if it came from the model.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Human-in-the-loop",
        "type": "text",
        "content": "First, checkpointers facilitate human-in-the-loop workflows workflows by allowing humans to inspect, interrupt, and approve graph steps. Checkpointers are needed for these workflows as the human has to be able to view the state of a graph at any point in time, and the graph has to be to resume execution after the human has made any updates to the state. See the how-to guides for examples.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "from langchain_astradb import AstraDBVectorStore\n\nvector_store = AstraDBVectorStore(\n    embedding=embeddings,\n    api_endpoint=ASTRA_DB_API_ENDPOINT,\n    collection_name=\"astra_vector_langchain\",\n    token=ASTRA_DB_APPLICATION_TOKEN,\n    namespace=ASTRA_DB_NAMESPACE,\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Tool Message",
        "type": "text",
        "content": "For example, a retrieval tool could retrieve a passage from a document for reference by a model. Where message content contains text that the model will reference, an artifact can contain document identifiers or other metadata that an application can use (e.g., to render a page). See example below:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Azure AI Services individual tools",
        "type": "code",
        "content": "Azure Cognitive Services",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "LangSmith Integration",
        "type": "text",
        "content": "For tracking experiments over time, you can log evaluator results to LangSmith , a platform for building production-grade LLM applications that includes tracing, evaluation, and experimentation tools.\n\nFirst, set up LangSmith by setting the required environment variables:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Encryption",
        "type": "code",
        "content": "from langgraph.checkpoint.serde.encrypted import EncryptedSerializer\nfrom langgraph.checkpoint.postgres import PostgresSaver\n\nserde = EncryptedSerializer.from_pycryptodome_aes()\ncheckpointer = PostgresSaver.from_conn_string(\"postgresql://...\", serde=serde)\ncheckpointer.setup()\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Resuming Workflows",
        "type": "text",
        "content": "Once you have enabled durable execution in your workflow, you can resume execution for the following scenarios:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/durable-execution",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Durable execution"
    },
    {
        "title": "Testing and validation",
        "type": "text",
        "content": "Verify the build completes without errors\n\nCheck that all internal links work correctly",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "Updated return type for chat models",
        "type": "code",
        "content": "def bind_tools(\n        ...\n    ) -> Runnable[LanguageModelInput, AIMessage]:\n",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Checkpointer interface",
        "type": "text",
        "content": "If the checkpointer is used with asynchronous graph execution (i.e. executing the graph via .ainvoke , .astream , .abatch ), asynchronous versions of the above methods will be used ( .aput , .aput_writes , .aget_tuple , .alist ).",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "6. View your agent in Studio",
        "type": "code",
        "content": "http://127.0.0.1:2024",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/studio",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Studio"
    },
    {
        "title": "Debugging with interrupts",
        "type": "text",
        "content": "To debug and test a graph, you can use static interrupts as breakpoints to step through the graph execution one node at a time. Static interrupts are triggered at defined points either before or after a node executes. You can set these by specifying interrupt_before and interrupt_after when compiling the graph.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Azure Container Apps dynamic sessions",
        "type": "code",
        "content": "pip install langchain-azure-dynamic-sessions\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Image captions",
        "type": "text",
        "content": "It uses the Hugging Face models to generate image captions.\n\nWe need to install several python packages.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Messaging Services",
        "type": "code",
        "content": "TelegramChatFileLoader",
        "side_link": "https://docs.langchain.com/oss/python/integrations/document_loaders",
        "head_menu_name": "Integrations",
        "side_menu_name": "Document loaders"
    },
    {
        "title": "Enable tracing",
        "type": "text",
        "content": "All LangChain agents automatically support LangSmith tracing. To enable it, set the following environment variables:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/observability",
        "head_menu_name": "LangChain",
        "side_menu_name": "Observability"
    },
    {
        "title": "System Prompt",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import dynamic_prompt, ModelRequest\n\n@dynamic_prompt\ndef state_aware_prompt(request: ModelRequest) -> str:\n    # request.messages is a shortcut for request.state[\"messages\"]\n    message_count = len(request.messages)\n\n    base = \"You are a helpful assistant.\"\n\n    if message_count > 10:\n        base += \"\\nThis is a long conversation - be extra concise.\"\n\n    return base\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[...],\n    middleware=[state_aware_prompt]\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "values",
        "type": "text",
        "content": "Let’s assume you have defined the state of your graph with the following schema (see full example above):",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "File structure",
        "type": "text",
        "content": "The directory structure of a LangGraph application can vary depending on the programming language and the package manager used.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/application-structure",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Application structure"
    },
    {
        "title": "Default message format for OpenAI Responses API",
        "type": "code",
        "content": "# Enforce previous behavior with output_version flag\nmodel = ChatOpenAI(model=\"gpt-4o-mini\", output_version=\"v0\")\n",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Using in LangGraph",
        "type": "text",
        "content": "We can access the in_memory_store and the user_id in any node by passing store: BaseStore and config: RunnableConfig as node arguments. Here’s how we might use semantic search in a node to find relevant memories:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "HuggingFaceEndpoint",
        "type": "code",
        "content": "from langchain_huggingface import HuggingFaceEndpoint\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Model fallback",
        "type": "text",
        "content": "Additional fallback models to try in order if previous models fail",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Popular providers",
        "type": "code",
        "content": "langchain-huggingface",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/overview",
        "head_menu_name": "Integrations",
        "side_menu_name": "Overview"
    },
    {
        "title": "Context editing",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import ContextEditingMiddleware, ClearToolUsesEdit\n\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[...],\n    middleware=[\n        ContextEditingMiddleware(\n            edits=[\n                ClearToolUsesEdit(trigger=1000),  # Clear old tool uses\n            ],\n        ),\n    ],\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "langchain-classic",
        "type": "code",
        "content": "from langchain import ...\nfrom langchain_classic import ...\n\nfrom langchain.chains import ...\nfrom langchain_classic.chains import ...\n\nfrom langchain.retrievers import ...\nfrom langchain_classic.retrievers import ...\n\nfrom langchain import hub  \nfrom langchain_classic import hub  \n",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "YouTube Audio Loader",
        "type": "code",
        "content": "from langchain_community.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader\n# Often used with whisper parsers:\n# from langchain_community.document_loaders.parsers import OpenAIWhisperParser, OpenAIWhisperParserLocal\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Deep Agents Middleware",
        "type": "text",
        "content": "Middleware is composable—you can add as many or as few middleware to an agent as needed. You can use any middleware independently.\n\nThe following sections explain what each middleware provides.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/middleware",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Middleware"
    },
    {
        "title": "InMemoryStore (development)",
        "type": "text",
        "content": "Good for testing and development, but data is lost on restart:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Prerequisites",
        "type": "text",
        "content": "Before you begin, make sure you have an API key from a model provider (e.g., Anthropic, OpenAI).",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/quickstart",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Content block reference",
        "type": "text",
        "content": "The text content\n\nMIME type of the text (e.g., text/plain , text/markdown )",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Microsoft Excel",
        "type": "code",
        "content": "UnstructuredExcelLoader",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Human-in-the-loop",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import HumanInTheLoopMiddleware\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.types import Command\n\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[search_tool, send_email_tool, delete_database_tool],\n    middleware=[\n        HumanInTheLoopMiddleware(\n            interrupt_on={\n                # Require approval for sensitive operations\n                \"send_email\": True,\n                \"delete_database\": True,\n                # Auto-approve safe operations\n                \"search\": False,\n            }\n        ),\n    ],\n    # Persist the state across interrupts\n    checkpointer=InMemorySaver(),\n)\n\n# Human-in-the-loop requires a thread ID for persistence\nconfig = {\"configurable\": {\"thread_id\": \"some_id\"}}\n\n# Agent will pause and wait for approval before executing sensitive tools\nresult = agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"Send an email to the team\"}]},\n    config=config\n)\n\nresult = agent.invoke(\n    Command(resume={\"decisions\": [{\"type\": \"approve\"}]}),\n    config=config  # Same thread ID to resume the paused conversation\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/guardrails",
        "head_menu_name": "LangChain",
        "side_menu_name": "Guardrails"
    },
    {
        "title": "Amazon Neptune with Cypher",
        "type": "code",
        "content": "from langchain_aws.graphs import NeptuneGraph\nfrom langchain_aws.graphs import NeptuneAnalyticsGraph\nfrom langchain_aws.chains import create_neptune_opencypher_qa_chain\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Example",
        "type": "text",
        "content": "Instead of the main agent making 10 web searches and filling its context with results, it delegates to the general-purpose subagent: task(name=\"general-purpose\", task=\"Research quantum computing trends\") . The subagent performs all the searches internally and returns only a summary.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Microsoft OneNote",
        "type": "code",
        "content": "from langchain_community.document_loaders.onenote import OneNoteLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Retrieval Pipeline",
        "type": "text",
        "content": "A typical retrieval workflow looks like this:\n\nEach component is modular: you can swap loaders, splitters, embeddings, or vector stores without rewriting the app’s logic.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/retrieval",
        "head_menu_name": "LangChain",
        "side_menu_name": "Retrieval"
    },
    {
        "title": "Content block reference",
        "type": "text",
        "content": "Purpose: Streaming tool call fragments\n\nAlways \"tool_call_chunk\"",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Guardrails",
        "type": "text",
        "content": "Guardrails help you build safe, compliant AI applications by validating and filtering content at key points in your agent’s execution. They can detect sensitive information, enforce content policies, validate outputs, and prevent unsafe behaviors before they cause problems.\n\nCommon use cases include:\n\nYou can implement guardrails using middleware to intercept execution at strategic points - before the agent starts, after it completes, or around model and tool calls.\n\nGuardrails can be implemented using two complementary approaches:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/guardrails",
        "head_menu_name": "LangChain",
        "side_menu_name": "Guardrails"
    },
    {
        "title": "Summarize messages",
        "type": "text",
        "content": "Summarize earlier messages in the history and replace them with a summary",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "1. Install the LangGraph CLI",
        "type": "code",
        "content": "# Python >= 3.11 is required.\npip install --upgrade \"langgraph-cli[inmem]\"\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/studio",
        "head_menu_name": "LangChain",
        "side_menu_name": "Studio"
    },
    {
        "title": "Message metadata",
        "type": "text",
        "content": "The name field behavior varies by provider - some use it for user identification, others ignore it. To check, refer to the model provider’s reference .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Featured providers",
        "type": "code",
        "content": "langchain-huggingface",
        "side_link": "https://docs.langchain.com/oss/python/integrations/chat",
        "head_menu_name": "Integrations",
        "side_menu_name": "Chat models"
    },
    {
        "title": "Testing requirements",
        "type": "text",
        "content": "Directories are relative to the package you’re working in.\n\nEvery code change must include comprehensive tests.\n\nLocation : tests/unit_tests/",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Tool use in the ReAct loop",
        "type": "text",
        "content": "Agents follow the ReAct (“Reasoning + Acting”) pattern, alternating between brief reasoning steps with targeted tool calls and feeding the resulting observations into subsequent decisions until they can deliver a final answer.\n\nPrompt: Identify the current most popular wireless headphones and verify availability.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Keep state raw, format prompts on-demand",
        "type": "text",
        "content": "Notice that the state contains only raw data - no prompt templates, no formatted strings, no instructions. The classification output is stored as a single dictionary, straight from the LLM.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Backends",
        "type": "text",
        "content": "Deep agents expose a filesystem surface to the agent via tools like ls , read_file , write_file , edit_file , glob , and grep . These tools operate through a pluggable backend.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Selecting tools",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\nfrom typing import Callable\n\n@wrap_model_call\ndef state_based_tools(\n    request: ModelRequest,\n    handler: Callable[[ModelRequest], ModelResponse]\n) -> ModelResponse:\n    \"\"\"Filter tools based on conversation State.\"\"\"\n    # Read from State: check if user has authenticated\n    state = request.state  \n    is_authenticated = state.get(\"authenticated\", False)  \n    message_count = len(state[\"messages\"])\n\n    # Only enable sensitive tools after authentication\n    if not is_authenticated:\n        tools = [t for t in request.tools if t.name.startswith(\"public_\")]\n        request = request.override(tools=tools)  \n    elif message_count < 5:\n        # Limit tools early in conversation\n        tools = [t for t in request.tools if t.name != \"advanced_search\"]\n        request = request.override(tools=tools)  \n\n    return handler(request)\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[public_search, private_search, advanced_search],\n    middleware=[state_based_tools]\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Decision types",
        "type": "code",
        "content": "interrupt_on = {\n    # Sensitive operations: allow all options\n    \"delete_file\": {\"allowed_decisions\": [\"approve\", \"edit\", \"reject\"]},\n\n    # Moderate risk: approval or rejection only\n    \"write_file\": {\"allowed_decisions\": [\"approve\", \"reject\"]},\n\n    # Must approve (no rejection allowed)\n    \"critical_operation\": {\"allowed_decisions\": [\"approve\"]},\n}\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/human-in-the-loop",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Step 1: Map out your workflow as discrete steps",
        "type": "text",
        "content": "Start by identifying the distinct steps in your process. Each step will become a node (a function that does one specific thing). Then sketch how these steps connect to each other.\n\nThe arrows show possible paths, but the actual decision of which path to take happens inside each node.\n\nNow that you’ve identified the components in your workflow, let’s understand what each node needs to do:\n\nNotice that some nodes make decisions about where to go next (Classify Intent, Draft Reply, Human Review), while others always proceed to the same next step (Read Email always goes to Classify Intent, Doc Search always goes to Draft Reply).",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Document structure-based",
        "type": "text",
        "content": "Some documents have an inherent structure, such as HTML, Markdown, or JSON files. In these cases, it’s beneficial to split the document based on its structure, as it often naturally groups semantically related text. Key benefits of structure-based splitting:\n\nExamples of structure-based splitting:\n\nAvailable text splitters :",
        "side_link": "https://docs.langchain.com/oss/python/integrations/splitters",
        "head_menu_name": "Integrations",
        "side_menu_name": "Text splitters"
    },
    {
        "title": "View subgraph state",
        "type": "code",
        "content": "from langgraph.graph import START, StateGraph\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom langgraph.types import interrupt, Command\nfrom typing_extensions import TypedDict\n\nclass State(TypedDict):\n    foo: str\n\n# Subgraph\n\ndef subgraph_node_1(state: State):\n    value = interrupt(\"Provide value:\")\n    return {\"foo\": state[\"foo\"] + value}\n\nsubgraph_builder = StateGraph(State)\nsubgraph_builder.add_node(subgraph_node_1)\nsubgraph_builder.add_edge(START, \"subgraph_node_1\")\n\nsubgraph = subgraph_builder.compile()\n\n# Parent graph\n\nbuilder = StateGraph(State)\nbuilder.add_node(\"node_1\", subgraph)\nbuilder.add_edge(START, \"node_1\")\n\ncheckpointer = MemorySaver()\ngraph = builder.compile(checkpointer=checkpointer)\n\nconfig = {\"configurable\": {\"thread_id\": \"1\"}}\n\ngraph.invoke({\"foo\": \"\"}, config)\nparent_state = graph.get_state(config)\n\n# This will be available only when the subgraph is interrupted.\n# Once you resume the graph, you won't be able to access the subgraph state.\nsubgraph_state = graph.get_state(config, subgraphs=True).tasks[0].state\n\n# resume the subgraph\ngraph.invoke(Command(resume=\"bar\"), config)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-subgraphs",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Subgraphs"
    },
    {
        "title": "Gemma local from Hugging Face",
        "type": "code",
        "content": "from langchain_google_vertexai.gemma import GemmaChatLocalHF\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Add metadata to traces",
        "type": "text",
        "content": "tracing_context also accepts tags and metadata for fine-grained control:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/observability",
        "head_menu_name": "LangChain",
        "side_menu_name": "Observability"
    },
    {
        "title": "Pre-bound models",
        "type": "text",
        "content": "Dynamic model functions can return pre-bound models if structured output is not used.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Summarize messages",
        "type": "code",
        "content": "SummarizationMiddleware",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Keep state raw, format prompts on-demand",
        "type": "code",
        "content": "from typing import TypedDict, Literal\n\n# Define the structure for email classification\nclass EmailClassification(TypedDict):\n    intent: Literal[\"question\", \"bug\", \"billing\", \"feature\", \"complex\"]\n    urgency: Literal[\"low\", \"medium\", \"high\", \"critical\"]\n    topic: str\n    summary: str\n\nclass EmailAgentState(TypedDict):\n    # Raw email data\n    email_content: str\n    sender_email: str\n    email_id: str\n\n    # Classification result\n    classification: EmailClassification | None\n\n    # Raw search/API results\n    search_results: list[str] | None  # List of raw document chunks\n    customer_history: dict | None  # Raw customer data from CRM\n\n    # Generated content\n    draft_response: str | None\n    messages: list[str] | None\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Semantic Search",
        "type": "text",
        "content": "You can control which parts of your memories get embedded by configuring the fields parameter or by specifying the index parameter when storing memories:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Use MCP tools",
        "type": "text",
        "content": "langchain-mcp-adapters enables agents to use tools defined across one or more MCP server.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/mcp",
        "head_menu_name": "LangChain",
        "side_menu_name": "Model Context Protocol (MCP)"
    },
    {
        "title": "Setup",
        "type": "code",
        "content": "pip install -U langgraph\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-subgraphs",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Subgraphs"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "pip install -qU \"langchain[langchain-perplexity]\"\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Configuring interrupts",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import HumanInTheLoopMiddleware \nfrom langgraph.checkpoint.memory import InMemorySaver \n\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[write_file_tool, execute_sql_tool, read_data_tool],\n    middleware=[\n        HumanInTheLoopMiddleware( \n            interrupt_on={\n                \"write_file\": True,  # All decisions (approve, edit, reject) allowed\n                \"execute_sql\": {\"allowed_decisions\": [\"approve\", \"reject\"]},  # No editing allowed\n                # Safe operation, no approval needed\n                \"read_data\": False,\n            },\n            # Prefix for interrupt messages - combined with tool name and args to form the full message\n            # e.g., \"Tool execution pending approval: execute_sql with query='DELETE FROM...'\"\n            # Individual tools can override this by specifying a \"description\" in their interrupt config\n            description_prefix=\"Tool execution pending approval\",\n        ),\n    ],\n    # Human-in-the-loop requires checkpointing to handle interrupts.\n    # In production, use a persistent checkpointer like AsyncPostgresSaver.\n    checkpointer=InMemorySaver(),  \n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/human-in-the-loop",
        "head_menu_name": "LangChain",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "create_agent",
        "type": "text",
        "content": "Under the hood, create_agent is built on the basic agent loop — calling a model, letting it choose tools to execute, and then finishing when it calls no more tools:",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Partial execution",
        "type": "text",
        "content": "Here’s an example that executes only the second and third nodes in a linear graph:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/test",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Test"
    },
    {
        "title": "Use with chat models",
        "type": "text",
        "content": "Chat models accept a sequence of message objects as input and return an AIMessage as output. Interactions are often stateless, so that a simple conversational loop involves invoking a model with a growing list of messages.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "VertexStringEvaluator",
        "type": "code",
        "content": "# Note: Original doc listed VertexPairWiseStringEvaluator twice. Assuming this class exists.\nfrom langchain_google_vertexai.evaluators.evaluation import VertexStringEvaluator # Verify class name if needed\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Read short-term memory in a tool",
        "type": "text",
        "content": "Access short term memory (state) in a tool using the ToolRuntime parameter.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Server-side tool use",
        "type": "code",
        "content": "from langchain.chat_models import init_chat_model\n\nmodel = init_chat_model(\"gpt-4.1-mini\")\n\ntool = {\"type\": \"web_search\"}\nmodel_with_tools = model.bind_tools([tool])\n\nresponse = model_with_tools.invoke(\"What was a positive news story from today?\")\nresponse.content_blocks\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Dictionary format",
        "type": "text",
        "content": "You can also specify messages directly in OpenAI chat completions format.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Bedrock",
        "type": "code",
        "content": "from langchain_aws import BedrockEmbeddings\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Add a graph as a node",
        "type": "text",
        "content": "When the parent graph and subgraph can communicate over a shared state key (channel) in the schema , you can add a graph as a node in another graph. For example, in multi-agent systems, the agents often communicate over a shared messages key.\n\nIf your subgraph shares state keys with the parent graph, you can follow these steps to add it to your graph:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-subgraphs",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Subgraphs"
    },
    {
        "title": "Tool retry",
        "type": "text",
        "content": "Either a tuple of exception types to retry on, or a callable that takes an exception and returns True if it should be retried.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Tools",
        "type": "text",
        "content": "Many AI applications interact with users via natural language. However, some use cases require models to interface directly with external systems—such as APIs, databases, or file systems—using structured input.\n\nTools are components that agents call to perform actions. They extend model capabilities by letting them interact with the world through well-defined inputs and outputs. Tools encapsulate a callable function and its input schema. These can be passed to compatible chat models , allowing the model to decide whether to invoke a tool and with what arguments. In these scenarios, tool calling enables models to generate requests that conform to a specified input schema.\n\nServer-side tool use\n\nSome chat models (e.g., OpenAI , Anthropic , and Gemini ) feature built-in tools that are executed server-side, such as web search and code interpreters. Refer to the provider overview to learn how to access these tools with your specific chat model.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "Messages",
        "type": "text",
        "content": "Messages make up the prompt that is sent to the LLM.\nIt’s critical to manage the content of messages to ensure that the LLM has the right information to respond well.\n\nInject uploaded file context from State when relevant to current query:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Repository structure",
        "type": "text",
        "content": "Located in libs/partners/ , these are independently versioned packages for specific integrations. For example:",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "ToolRuntime",
        "type": "text",
        "content": "Updating state:\n\nUse Command to update the agent’s state or control the graph’s execution flow:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "Customizing agent memory",
        "type": "text",
        "content": "You can extend AgentState to add additional fields. Custom state schemas are passed to create_agent using the state_schema parameter.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "LangGraph overview",
        "type": "text",
        "content": "LangGraph v1.0 is now available!\n\nFor a complete list of changes and instructions on how to upgrade your code, see the release notes and migration guide .\n\nIf you encounter any issues or have feedback, please open an issue so we can improve. To view v0.x documentation, go to the archived content .\n\nTrusted by companies shaping the future of agents— including Klarna, Replit, Elastic, and more— LangGraph is a low-level orchestration framework and runtime for building, managing, and deploying long-running, stateful agents.\n\nLangGraph is very low-level, and focused entirely on agent orchestration . Before using LangGraph, we recommend you familiarize yourself with some of the components used to build agents, starting with models and tools .\n\nWe will commonly use LangChain components throughout the documentation to integrate models and tools, but you don’t need to use LangChain to use LangGraph. If you are just getting started with agents or want a higher-level abstraction, we recommend you use LangChain’s agents that provide pre-built architectures for common LLM and tool-calling loops.\n\nLangGraph is focused on the underlying capabilities important for agent orchestration: durable execution, streaming, human-in-the-loop, and more.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/overview",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Overview"
    },
    {
        "title": "Import path",
        "type": "code",
        "content": "from langgraph.prebuilt import create_react_agent \nfrom langchain.agents import create_agent \n",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "SubAgent (Dictionary-based)",
        "type": "text",
        "content": "For most use cases, define subagents as dictionaries:\n\nRequired fields:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Getting help",
        "type": "text",
        "content": "Our goal is to have the simplest developer setup possible. Should you experience any difficulty getting setup, please ask in the community slack or open a forum post .\n\nYou now have everything you need to contribute high-quality documentation to LangChain! 🎤🦜\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "Use in subgraphs",
        "type": "text",
        "content": "If you want the subgraph to have its own memory, you can compile it with the appropriate checkpointer option. This is useful in multi-agent systems, if you want agents to keep track of their internal message histories.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Local development",
        "type": "code",
        "content": "# Create a new Agent Chat UI project\nnpx create-agent-chat-app --project-name my-chat-ui\ncd my-chat-ui\n\n# Install dependencies and start\npnpm install\npnpm dev\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/ui",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agent Chat UI"
    },
    {
        "title": "Spanner",
        "type": "code",
        "content": "from langchain_google_spanner import SpannerLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Development environment",
        "type": "code",
        "content": "cd libs/core\nuv sync --all-groups\nmake test  # Ensure tests pass before starting development\n",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "1. Install the LangGraph CLI",
        "type": "code",
        "content": "# Python >= 3.11 is required.\npip install --upgrade \"langgraph-cli[inmem]\"\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/studio",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Studio"
    },
    {
        "title": "Agent Chat UI",
        "type": "text",
        "content": "Agent Chat UI is a Next.js application that provides a conversational interface for interacting with any LangChain agent. It supports real-time chat, tool visualization, and advanced features like time-travel debugging and state forking.\n\nAgent Chat UI is open source and can be adapted to your application needs.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/ui",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agent Chat UI"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "pip install -qU langchain-milvus\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Self-improving instructions",
        "type": "text",
        "content": "An agent can update its own instructions based on feedback:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "State type restrictions",
        "type": "text",
        "content": "create_agent only supports TypedDict for state schemas. Pydantic models and dataclasses are no longer supported.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Long-term memory",
        "type": "code",
        "content": "use_longterm_memory=True",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "6. View your agent in Studio",
        "type": "text",
        "content": "Safari blocks localhost connections to Studio. To work around this, run the above command with --tunnel to access Studio via a secure tunnel.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/studio",
        "head_menu_name": "LangChain",
        "side_menu_name": "Studio"
    },
    {
        "title": "Standard content blocks",
        "type": "code",
        "content": "langchain-google-genai",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Writes",
        "type": "code",
        "content": "from langchain.tools import tool, ToolRuntime\nfrom langchain.agents import create_agent\nfrom langgraph.types import Command\n\n@tool\ndef authenticate_user(\n    password: str,\n    runtime: ToolRuntime\n) -> Command:\n    \"\"\"Authenticate user and update State.\"\"\"\n    # Perform authentication (simplified)\n    if password == \"correct\":\n        # Write to State: mark as authenticated using Command\n        return Command(\n            update={\"authenticated\": True},\n        )\n    else:\n        return Command(update={\"authenticated\": False})\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[authenticate_user]\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Standard content blocks",
        "type": "text",
        "content": "Content block support is currently only available for the following integrations:",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Abso",
        "type": "text",
        "content": "Custom AI integration platform for enterprise workflows.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/all_providers",
        "head_menu_name": "Integrations",
        "side_menu_name": "All providers"
    },
    {
        "title": "Embedding Models",
        "type": "text",
        "content": "Microsoft offers two main options for accessing embedding models through Azure:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Metadata filtering",
        "type": "code",
        "content": "vector_store.similarity_search(\n  \"query\",\n  k=3,\n  filter={\"source\": \"tweets\"}\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Research projects",
        "type": "code",
        "content": "research_agent = create_deep_agent(\n    store=store,\n    use_longterm_memory=True,\n    system_prompt=\"\"\"You are a research assistant.\n\n    Save your research progress to /memories/research/:\n    - /memories/research/sources.txt - List of sources found\n    - /memories/research/notes.txt - Key findings and notes\n    - /memories/research/report.md - Final report draft\n\n    This allows research to continue across multiple sessions.\"\"\"\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Build a real-world agent",
        "type": "text",
        "content": "Tools should be well-documented: their name, description, and argument names become part of the model’s prompt.\nLangChain’s @tool decorator adds metadata and enables runtime injection via the ToolRuntime parameter.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/quickstart",
        "head_menu_name": "LangChain",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "6. Test your application in Studio",
        "type": "text",
        "content": "For a LangGraph Server running on a custom host/port, update the baseURL parameter.\n\nUse the --tunnel flag with your command to create a secure tunnel, as Safari has limitations when connecting to localhost servers:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/local-server",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Local server"
    },
    {
        "title": "Tool calling",
        "type": "text",
        "content": "When streaming responses, tool calls are progressively built through ToolCallChunk . This allows you to see tool calls as they’re being generated rather than waiting for the complete response.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Standard content blocks",
        "type": "text",
        "content": "Broader support for content blocks will be rolled out gradually across more providers.\n\nThe new content_blocks property introduces a standard representation for message content that works across providers:",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Human-in-the-loop",
        "type": "text",
        "content": "Prefix for action request descriptions\n\nInterruptOnConfig options:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Google Cloud",
        "type": "text",
        "content": "Access Gemini models, Vertex AI Model Garden and other Google Cloud services via Vertex AI and specific cloud integrations.\n\nVertex AI models require the langchain-google-vertexai package. Other services might require additional packages like langchain-google-community , langchain-google-cloud-sql-pg , etc.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Serialize standard content",
        "type": "text",
        "content": "Standard content blocks are not serialized into the content attribute by default. If you need to access standard content blocks in the content attribute (e.g., when sending messages to a client), you can opt-in to serializing them into content .",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Add persistence",
        "type": "text",
        "content": "You only need to provide the checkpointer when compiling the parent graph . LangGraph will automatically propagate the checkpointer to the child subgraphs.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-subgraphs",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Subgraphs"
    },
    {
        "title": "Build a real-world agent",
        "type": "code",
        "content": "from langchain.chat_models import init_chat_model\n\nmodel = init_chat_model(\n    \"claude-sonnet-4-5-20250929\",\n    temperature=0.5,\n    timeout=10,\n    max_tokens=1000\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/quickstart",
        "head_menu_name": "LangChain",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Review and edit state",
        "type": "code",
        "content": "graph.invoke(\n    Command(resume=\"The edited and improved text\"),  # Value becomes the return from interrupt()\n    config=config\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "YouTube Search Tool",
        "type": "text",
        "content": "Search YouTube videos without the official API. Requires youtube_search package.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Before model",
        "type": "code",
        "content": "from langchain.messages import RemoveMessage\nfrom langgraph.graph.message import REMOVE_ALL_MESSAGES\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langchain.agents import create_agent, AgentState\nfrom langchain.agents.middleware import before_model\nfrom langgraph.runtime import Runtime\nfrom typing import Any\n\n\n@before_model\ndef trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n    messages = state[\"messages\"]\n\n    if len(messages) <= 3:\n        return None  # No changes needed\n\n    first_msg = messages[0]\n    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]\n    new_messages = [first_msg] + recent_messages\n\n    return {\n        \"messages\": [\n            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n            *new_messages\n        ]\n    }\n\nagent = create_agent(\n    model,\n    tools=tools,\n    middleware=[trim_messages]\n)\n\nconfig: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n\nagent.invoke({\"messages\": \"hi, my name is bob\"}, config)\nagent.invoke({\"messages\": \"write a short poem about cats\"}, config)\nagent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\nfinal_response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n\nfinal_response[\"messages\"][-1].pretty_print()\n\"\"\"\n================================== Ai Message ==================================\n\nYour name is Bob. You told me that earlier.\nIf you'd like me to call you a nickname or use a different name, just say the word.\n\"\"\"\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "RAG Agent",
        "type": "text",
        "content": "Create a Retrieval Augmented Generation (RAG) agent.",
        "side_link": "https://docs.langchain.com/oss/python/learn",
        "head_menu_name": "Learn",
        "side_menu_name": "Learn"
    },
    {
        "title": "Quick fix: submit a bugfix",
        "type": "code",
        "content": "git checkout -b your-username/short-bugfix-name\n",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "General guidelines",
        "type": "text",
        "content": "Multiple pages covering the same material are difficult to maintain and cause confusion. There should be only one canonical page for each concept or feature. Link to other guides instead of re-explaining.\n\nDocumentation sections don’t exist in a vacuum. Link to other sections frequently to allow users to learn about unfamiliar topics. This includes linking to API references and conceptual sections.\n\nTake a less-is-more approach. If another section with a good explanation exists, link to it rather than re-explain, unless your content presents a new angle.",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "Cloud SQL for PostgreSQL",
        "type": "code",
        "content": "pip install langchain-google-cloud-sql-pg\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "langchain-classic",
        "type": "code",
        "content": "# Chains\nfrom langchain_classic.chains import LLMChain\n\n# Retrievers\nfrom langchain_classic.retrievers import ...\n\n# Indexing\nfrom langchain_classic.indexes import ...\n\n# Hub\nfrom langchain_classic import hub\n",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Always use a checkpointer",
        "type": "code",
        "content": "from langgraph.checkpoint.memory import MemorySaver\n\ncheckpointer = MemorySaver()\nagent = create_deep_agent(\n    tools=[...],\n    interrupt_on={...},\n    checkpointer=checkpointer  # Required for HITL\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/human-in-the-loop",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Hugging Face dataset",
        "type": "code",
        "content": "from langchain_community.document_loaders.hugging_face_dataset import HuggingFaceDatasetLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Transient context",
        "type": "text",
        "content": "What the LLM sees for a single call. You can modify messages, tools, or prompts without changing what’s saved in state.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Google Generative AI (Gemini API & AI Studio)",
        "type": "code",
        "content": "export GOOGLE_API_KEY=\"YOUR_API_KEY\"\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Cloud SQL for PostgreSQL",
        "type": "text",
        "content": "Vector store using Cloud SQL for PostgreSQL .\n\nInstall the python package:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Delete messages",
        "type": "code",
        "content": "[('human', \"hi! I'm bob\")]\n[('human', \"hi! I'm bob\"), ('ai', 'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.')]\n[('human', \"hi! I'm bob\"), ('ai', 'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.'), ('human', \"what's my name?\")]\n[('human', \"hi! I'm bob\"), ('ai', 'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.'), ('human', \"what's my name?\"), ('ai', 'Your name is Bob. How can I help you today, Bob?')]\n[('human', \"what's my name?\"), ('ai', 'Your name is Bob. How can I help you today, Bob?')]\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Interface",
        "type": "code",
        "content": "mget(key: Sequence[str]) -> List[Optional[bytes]]",
        "side_link": "https://docs.langchain.com/oss/python/integrations/stores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Key-value stores"
    },
    {
        "title": "References",
        "type": "text",
        "content": "Reference documentation contains detailed, low-level information describing exactly what functionality exists and how to use it.",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "Summarization",
        "type": "text",
        "content": "Automatically summarize conversation history when approaching token limits.\n\nPerfect for:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Multimodal",
        "type": "code",
        "content": "# From URL\nmessage = {\n    \"role\": \"user\",\n    \"content\": [\n        {\"type\": \"text\", \"text\": \"Describe the content of this image.\"},\n        {\"type\": \"image\", \"url\": \"https://example.com/path/to/image.jpg\"},\n    ]\n}\n\n# From base64 data\nmessage = {\n    \"role\": \"user\",\n    \"content\": [\n        {\"type\": \"text\", \"text\": \"Describe the content of this image.\"},\n        {\n            \"type\": \"image\",\n            \"base64\": \"AAAAIGZ0eXBtcDQyAAAAAGlzb21tcDQyAAACAGlzb2...\",\n            \"mime_type\": \"image/jpeg\",\n        },\n    ]\n}\n\n# From provider-managed File ID\nmessage = {\n    \"role\": \"user\",\n    \"content\": [\n        {\"type\": \"text\", \"text\": \"Describe the content of this image.\"},\n        {\"type\": \"image\", \"file_id\": \"file-abc123\"},\n    ]\n}\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Microsoft",
        "type": "text",
        "content": "All LangChain integrations with Microsoft Azure and other Microsoft products.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Bring-your-own documents",
        "type": "code",
        "content": "AzureAISearchRetriever",
        "side_link": "https://docs.langchain.com/oss/python/integrations/retrievers",
        "head_menu_name": "Integrations",
        "side_menu_name": "Retrievers"
    },
    {
        "title": "Disable streaming for specific chat models",
        "type": "text",
        "content": "If your application mixes models that support streaming with those that do not, you may need to explicitly disable streaming for\nmodels that do not support it.\n\nSet disable_streaming=True when initializing the model.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Bedrock",
        "type": "code",
        "content": "from langchain_aws import BedrockLLM\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Build a real-world agent",
        "type": "code",
        "content": "from dataclasses import dataclass\nfrom langchain.tools import tool, ToolRuntime\n\n@tool\ndef get_weather_for_location(city: str) -> str:\n    \"\"\"Get weather for a given city.\"\"\"\n    return f\"It's always sunny in {city}!\"\n\n@dataclass\nclass Context:\n    \"\"\"Custom runtime context schema.\"\"\"\n    user_id: str\n\n@tool\ndef get_user_location(runtime: ToolRuntime[Context]) -> str:\n    \"\"\"Retrieve user information based on user ID.\"\"\"\n    user_id = runtime.context.user_id\n    return \"Florida\" if user_id == \"1\" else \"SF\"\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/quickstart",
        "head_menu_name": "LangChain",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "6. View your agent in Studio",
        "type": "text",
        "content": "Studio makes each step of your agent easily observable. Replay any input and inspect the exact prompt, tool arguments, return values, and token/latency metrics. If a tool throws an exception, Studio records it with surrounding state so you can spend less time debugging.\n\nKeep your dev server running, edit prompts or tool signatures, and watch Studio hot-reload. Re-run the conversation thread from any step to verify behavior changes. See Manage threads for more details.\n\nAs your agent grows, the same view scales from a single-tool demo to multi-node graphs, keeping decisions legible and reproducible.\n\nFor an in-depth look at Studio, check out the overview page .\n\nFor more information about local and deployed agents, see Set up local LangGraph Server and Deploy .\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/studio",
        "head_menu_name": "LangChain",
        "side_menu_name": "Studio"
    },
    {
        "title": "ProviderStrategy",
        "type": "text",
        "content": "ProviderStrategy uses the model provider’s native structured output generation. This is more reliable but only works with providers that support native structured output (e.g., OpenAI):",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Azure OpenAI",
        "type": "text",
        "content": "Azure OpenAI is an Azure service with powerful language models from OpenAI including the GPT-3 , Codex and Embeddings model series for content generation, summarization, semantic search, and natural language to code translation.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Testing requirements",
        "type": "code",
        "content": "tests/integration_tests/",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Using CompiledSubAgent",
        "type": "text",
        "content": "For more complex use cases, you can provide your own pre-built LangGraph graph as a subagent:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Zotero",
        "type": "text",
        "content": "Reference management and research tool.\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/all_providers",
        "head_menu_name": "Integrations",
        "side_menu_name": "All providers"
    },
    {
        "title": "Human-in-the-loop",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import HumanInTheLoopMiddleware\nfrom langgraph.checkpoint.memory import InMemorySaver\n\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[read_email_tool, send_email_tool],\n    checkpointer=InMemorySaver(),\n    middleware=[\n        HumanInTheLoopMiddleware(\n            interrupt_on={\n                # Require approval, editing, or rejection for sending emails\n                \"send_email_tool\": {\n                    \"allowed_decisions\": [\"approve\", \"edit\", \"reject\"],\n                },\n                # Auto-approve reading emails\n                \"read_email_tool\": False,\n            }\n        ),\n    ],\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Using in LangGraph",
        "type": "code",
        "content": "# Invoke the graph\nconfig = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"1\"}}\n\n# Let's say hi again\nfor update in graph.stream(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"hi, tell me about my memories\"}]}, config, stream_mode=\"updates\"\n):\n    print(update)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Observability",
        "type": "text",
        "content": "Traces capture every step your agent takes, from the initial user input to the final response, including all tool calls, model interactions, and decision points. This enables you to debug your agents, evaluate performance, and monitor usage.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/observability",
        "head_menu_name": "LangChain",
        "side_menu_name": "Observability"
    },
    {
        "title": "3. Environment variables",
        "type": "code",
        "content": "LANGSMITH_API_KEY=lsv2...\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/studio",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Studio"
    },
    {
        "title": "Resuming interrupts",
        "type": "text",
        "content": "After an interrupt pauses execution, you resume the graph by invoking it again with a Command that contains the resume value. The resume value is passed back to the interrupt call, allowing the node to continue execution with the external input.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "View the history of the thread",
        "type": "code",
        "content": "config = {\n    \"configurable\": {\n        \"thread_id\": \"1\"\n    }\n}\nlist(graph.get_state_history(config))  \n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "When to use it",
        "type": "text",
        "content": "The general-purpose subagent is ideal for context isolation without specialized behavior. The main agent can delegate a complex multi-step task to this subagent and get a concise result back without bloat from intermediate tool calls.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Message content",
        "type": "text",
        "content": "Separately, LangChain provides dedicated content types for text, reasoning, citations, multi-modal data, server-side tool calls, and other message content. See content blocks below.\n\nLangChain chat models accept message content in the content attribute, and can contain:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "3. Environment variables",
        "type": "text",
        "content": "Be sure not to commit your .env to version control systems such as Git!",
        "side_link": "https://docs.langchain.com/oss/python/langchain/studio",
        "head_menu_name": "LangChain",
        "side_menu_name": "Studio"
    },
    {
        "title": "Route to different backends",
        "type": "code",
        "content": "from deepagents import create_deep_agent\nfrom deepagents.backends import FilesystemBackend\nfrom deepagents.backends.composite import build_composite_state_backend\n\ncomposite_backend = lambda rt: CompositeBackend(\n    routes={\n        \"/memories/\": FilesystemBackend(root_dir=\"/deepagents/myagent\"),\n    },\n)\n\nagent = create_deep_agent(backend=composite_backend)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Google Jobs",
        "type": "text",
        "content": "Query job listings. Requires google-search-results package and SerpApi key.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Delete messages",
        "type": "code",
        "content": "from langchain.messages import RemoveMessage  \n\ndef delete_messages(state):\n    messages = state[\"messages\"]\n    if len(messages) > 2:\n        # remove the earliest two messages\n        return {\"messages\": [RemoveMessage(id=m.id) for m in messages[:2]]}  \n\ndef call_model(state: MessagesState):\n    response = model.invoke(state[\"messages\"])\n    return {\"messages\": response}\n\nbuilder = StateGraph(MessagesState)\nbuilder.add_sequence([call_model, delete_messages])\nbuilder.add_edge(START, \"call_model\")\n\ncheckpointer = InMemorySaver()\napp = builder.compile(checkpointer=checkpointer)\n\nfor event in app.stream(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"hi! I'm bob\"}]},\n    config,\n    stream_mode=\"values\"\n):\n    print([(message.type, message.content) for message in event[\"messages\"]])\n\nfor event in app.stream(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what's my name?\"}]},\n    config,\n    stream_mode=\"values\"\n):\n    print([(message.type, message.content) for message in event[\"messages\"]])\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "State type restrictions",
        "type": "code",
        "content": "langchain.agents.AgentState",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Interface",
        "type": "code",
        "content": "mset(key_value_pairs: Sequence[Tuple[str, bytes]]) -> None",
        "side_link": "https://docs.langchain.com/oss/python/integrations/stores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Key-value stores"
    },
    {
        "title": "Manual formatting and linting",
        "type": "text",
        "content": "Code formatting and linting are enforced via CI/CD. Run these commands before committing to ensure your code passes checks.\n\nRun formatting and linting:",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "6. View your agent in Studio",
        "type": "text",
        "content": "Your agent will be accessible via API ( http://127.0.0.1:2024 ) and the Studio UI https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024 :",
        "side_link": "https://docs.langchain.com/oss/python/langchain/studio",
        "head_menu_name": "LangChain",
        "side_menu_name": "Studio"
    },
    {
        "title": "Provider strategy",
        "type": "text",
        "content": "LangChain automatically uses ProviderStrategy when you pass a schema type directly to create_agent.response_format and the model supports native structured output:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Similarity metrics",
        "type": "code",
        "content": "import numpy as np\n\ndef cosine_similarity(vec1, vec2):\n    dot = np.dot(vec1, vec2)\n    return dot / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n\nsimilarity = cosine_similarity(query_embedding, document_embedding)\nprint(\"Cosine Similarity:\", similarity)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/text_embedding",
        "head_menu_name": "Integrations",
        "side_menu_name": "Embedding models"
    },
    {
        "title": "Orchestrator-worker",
        "type": "code",
        "content": "from typing import Annotated, List\nimport operator\n\n\n# Schema for structured output to use in planning\nclass Section(BaseModel):\n    name: str = Field(\n        description=\"Name for this section of the report.\",\n    )\n    description: str = Field(\n        description=\"Brief overview of the main topics and concepts to be covered in this section.\",\n    )\n\n\nclass Sections(BaseModel):\n    sections: List[Section] = Field(\n        description=\"Sections of the report.\",\n    )\n\n\n# Augment the LLM with schema for structured output\nplanner = llm.with_structured_output(Sections)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/workflows-agents",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Workflows + agents"
    },
    {
        "title": "Replay",
        "type": "code",
        "content": "config = {\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"0c62ca34-ac19-445d-bbb0-5b4984975b2a\"}}\ngraph.invoke(None, config=config)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Setup",
        "type": "code",
        "content": "from deepagents import create_deep_agent\nfrom langgraph.store.memory import InMemoryStore\n\nstore = InMemoryStore()  # Or any other Store object\nagent = create_deep_agent(\n    store=store,\n    use_longterm_memory=True\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "HuggingFacePipeline",
        "type": "text",
        "content": "We can use the HuggingFacePipeline class to run open source models locally.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Agent harness capabilities",
        "type": "text",
        "content": "This page lists out the components that make up the agent harness.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/harness",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Agent harness"
    },
    {
        "title": "Connect to your agent",
        "type": "code",
        "content": "http://localhost:2024",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/ui",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Agent Chat UI"
    },
    {
        "title": "Customizing agent memory",
        "type": "text",
        "content": "By default, agents use AgentState to manage short term memory, specifically the conversation history via a messages key.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Defining state viastate_schema",
        "type": "code",
        "content": "from langchain.tools import tool, ToolRuntime\nfrom langchain.agents import create_agent, AgentState  \n\n\n# Define custom state extending AgentState\nclass CustomState(AgentState):\n    user_name: str\n\n@tool\ndef greet(\n    runtime: ToolRuntime[CustomState]\n) -> str:\n    \"\"\"Use this to greet the user by name.\"\"\"\n    user_name = runtime.state.get(\"user_name\", \"Unknown\")  \n    return f\"Hello {user_name}!\"\n\nagent = create_agent(  \n    model=\"claude-sonnet-4-5-20250929\",\n    tools=[greet],\n    state_schema=CustomState  \n)\n",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Model Context Protocol (MCP)",
        "type": "text",
        "content": "Model Context Protocol (MCP) is an open protocol that standardizes how applications provide tools and context to LLMs. LangChain agents can use tools defined on MCP servers using the langchain-mcp-adapters library.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/mcp",
        "head_menu_name": "LangChain",
        "side_menu_name": "Model Context Protocol (MCP)"
    },
    {
        "title": "Azure AI Search",
        "type": "text",
        "content": "Search is foundational to any app that surfaces text to users, where common scenarios include catalog or document search, online retail apps, or data exploration over proprietary content. When you create a search service, you’ll work with the following capabilities:\n\nSee set up instructions .\n\nSee a usage example .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "HuggingFaceBgeEmbeddings",
        "type": "text",
        "content": "BGE models on the HuggingFace are one of the best open-source embedding models .\nBGE model is created by the Beijing Academy of Artificial Intelligence (BAAI) . BAAI is a private non-profit organization engaged in AI research and development.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Configurable models",
        "type": "code",
        "content": "[\n    {\n        'name': 'GetPopulation',\n        'args': {'location': 'Los Angeles, CA'},\n        'id': 'toolu_01JMufPf4F4t2zLj7miFeqXp',\n        'type': 'tool_call'\n    },\n    {\n        'name': 'GetPopulation',\n        'args': {'location': 'New York City, NY'},\n        'id': 'toolu_01RQBHcE8kEEbYTuuS8WqY1u',\n        'type': 'tool_call'\n    }\n]\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Async Support",
        "type": "code",
        "content": "from agentevals.trajectory.llm import create_async_trajectory_llm_as_judge, TRAJECTORY_ACCURACY_PROMPT\nfrom agentevals.trajectory.match import create_async_trajectory_match_evaluator\n\nasync_judge = create_async_trajectory_llm_as_judge(\n    model=\"openai:o3-mini\",\n    prompt=TRAJECTORY_ACCURACY_PROMPT,\n)\n\nasync_evaluator = create_async_trajectory_match_evaluator(\n    trajectory_match_mode=\"strict\",\n)\n\nasync def test_async_evaluation():\n    result = await agent.ainvoke({\n        \"messages\": [HumanMessage(content=\"What's the weather?\")]\n    })\n\n    evaluation = await async_judge(outputs=result[\"messages\"])\n    assert evaluation[\"score\"] is True\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Google",
        "type": "code",
        "content": "langchain-google-cloud-sql-pg",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "ZenGuard AI",
        "type": "text",
        "content": "If you’d like to contribute an integration, see Contributing integrations .\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/tools",
        "head_menu_name": "Integrations",
        "side_menu_name": "Tools and toolkits"
    },
    {
        "title": "Chat models",
        "type": "text",
        "content": "Chat models are language models that use a sequence of messages as inputs and return messages as outputs (as opposed to traditional, plaintext LLMs) .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/chat",
        "head_menu_name": "Integrations",
        "side_menu_name": "Chat models"
    },
    {
        "title": "Enable tracing",
        "type": "text",
        "content": "To enable tracing for your application, set the following environment variables:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/observability",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Observability"
    },
    {
        "title": "Structured output",
        "type": "text",
        "content": "Error handling : Control error handling via the handle_errors parameter to ToolStrategy :",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Gemma local from Hugging Face",
        "type": "text",
        "content": "Local Gemma model loaded from HuggingFace. Requires langchain-google-vertexai .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Agent progress",
        "type": "text",
        "content": "For example, if you have an agent that calls a tool once, you should see the following updates:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/streaming",
        "head_menu_name": "LangChain",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Connect to your agent",
        "type": "text",
        "content": "Once configured, Agent Chat UI will automatically fetch and display any interrupted threads from your agent.\n\nAgent Chat UI has out-of-the-box support for rendering tool calls and tool result messages. To customize what messages are shown, see Hiding Messages in the Chat .\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/ui",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Agent Chat UI"
    },
    {
        "title": "Azure AI",
        "type": "code",
        "content": "AzureAIChatCompletionsModel",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Google Lens",
        "type": "code",
        "content": "google-search-results",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Summarize messages",
        "type": "text",
        "content": "The problem with trimming or removing messages, as shown above, is that you may lose information from culling of the message queue.\nBecause of this, some applications benefit from a more sophisticated approach of summarizing the message history using a chat model.\n\nTo summarize message history in an agent, use the built-in SummarizationMiddleware :",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Amazon OpenSearch Service",
        "type": "code",
        "content": "Amazon OpenSearch Service",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Interface",
        "type": "text",
        "content": "Each document loader may define its own parameters, but they share a common API:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/document_loaders",
        "head_menu_name": "Integrations",
        "side_menu_name": "Document loaders"
    },
    {
        "title": "File system access",
        "type": "text",
        "content": "The harness provides six tools for file system operations, making files first-class citizens in the agent’s environment:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/harness",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Agent harness"
    },
    {
        "title": "Context still getting bloated",
        "type": "code",
        "content": "system_prompt=\"\"\"When you gather large amounts of data:\n1. Save raw data to /data/raw_results.txt\n2. Process and analyze the data\n3. Return only the analysis summary\n\nThis keeps context clean.\"\"\"\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Token usage",
        "type": "text",
        "content": "An AIMessage can hold token counts and other usage metadata in its usage_metadata field:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "3. Define model node",
        "type": "text",
        "content": "The model node is used to call the LLM and decide whether to call a tool or not.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/quickstart",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Debugging",
        "type": "code",
        "content": "for chunk in graph.stream(\n    {\"topic\": \"ice cream\"},\n    stream_mode=\"debug\",  \n):\n    print(chunk)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Tool calling",
        "type": "text",
        "content": "By default, the model has the freedom to choose which bound tool to use based on the user’s input. However, you might want to force choosing a tool, ensuring the model uses either a particular tool or any tool from a given list:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Enable tracing",
        "type": "text",
        "content": "You can get your API key from your LangSmith settings .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/observability",
        "head_menu_name": "LangChain",
        "side_menu_name": "Observability"
    },
    {
        "title": "Vertex AI image editor",
        "type": "text",
        "content": "Given an image and a prompt, edit the image. Currently only supports mask-free editing. Requires langchain-google-vertexai .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "ToolRuntime",
        "type": "code",
        "content": "from langchain.tools import tool, ToolRuntime\n\n# Access the current conversation state\n@tool\ndef summarize_conversation(\n    runtime: ToolRuntime\n) -> str:\n    \"\"\"Summarize the conversation so far.\"\"\"\n    messages = runtime.state[\"messages\"]\n\n    human_msgs = sum(1 for m in messages if m.__class__.__name__ == \"HumanMessage\")\n    ai_msgs = sum(1 for m in messages if m.__class__.__name__ == \"AIMessage\")\n    tool_msgs = sum(1 for m in messages if m.__class__.__name__ == \"ToolMessage\")\n\n    return f\"Conversation has {human_msgs} user messages, {ai_msgs} AI responses, and {tool_msgs} tool results\"\n\n# Access custom state fields\n@tool\ndef get_user_preference(\n    pref_name: str,\n    runtime: ToolRuntime  # ToolRuntime parameter is not visible to the model\n) -> str:\n    \"\"\"Get a user preference value.\"\"\"\n    preferences = runtime.state.get(\"user_preferences\", {})\n    return preferences.get(pref_name, \"Not set\")\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "Customizing agent memory",
        "type": "code",
        "content": "from langchain.agents import create_agent, AgentState\nfrom langgraph.checkpoint.memory import InMemorySaver\n\n\nclass CustomAgentState(AgentState):  \n    user_id: str\n    preferences: dict\n\nagent = create_agent(\n    \"gpt-5\",\n    [get_user_info],\n    state_schema=CustomAgentState,  \n    checkpointer=InMemorySaver(),\n)\n\n# Custom state can be passed in invoke\nresult = agent.invoke(\n    {\n        \"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}],\n        \"user_id\": \"user_123\",  \n        \"preferences\": {\"theme\": \"dark\"}  \n    },\n    {\"configurable\": {\"thread_id\": \"1\"}})\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Trajectory Match Evaluator",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.tools import tool\nfrom langchain.messages import HumanMessage, AIMessage, ToolMessage\nfrom agentevals.trajectory.match import create_trajectory_match_evaluator\n\n\n@tool\ndef get_weather(city: str):\n    \"\"\"Get weather information for a city.\"\"\"\n    return f\"It's 75 degrees and sunny in {city}.\"\n\nagent = create_agent(\"gpt-4o\", tools=[get_weather])\n\nevaluator = create_trajectory_match_evaluator(  \n    trajectory_match_mode=\"strict\",  \n)  \n\ndef test_weather_tool_called_strict():\n    result = agent.invoke({\n        \"messages\": [HumanMessage(content=\"What's the weather in San Francisco?\")]\n    })\n\n    reference_trajectory = [\n        HumanMessage(content=\"What's the weather in San Francisco?\"),\n        AIMessage(content=\"\", tool_calls=[\n            {\"id\": \"call_1\", \"name\": \"get_weather\", \"args\": {\"city\": \"San Francisco\"}}\n        ]),\n        ToolMessage(content=\"It's 75 degrees and sunny in San Francisco.\", tool_call_id=\"call_1\"),\n        AIMessage(content=\"The weather in San Francisco is 75 degrees and sunny.\"),\n    ]\n\n    evaluation = evaluator(\n        outputs=result[\"messages\"],\n        reference_outputs=reference_trajectory\n    )\n    # {\n    #     'key': 'trajectory_strict_match',\n    #     'score': True,\n    #     'comment': None,\n    # }\n    assert evaluation[\"score\"] is True\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Add policy hooks",
        "type": "code",
        "content": "from deepagents.backends.protocol import BackendProtocol, WriteResult, EditResult\nfrom deepagents.backends.utils import FileInfo, GrepMatch\n\nclass PolicyWrapper(BackendProtocol):\n    def __init__(self, inner: BackendProtocol, deny_prefixes: list[str] | None = None):\n        self.inner = inner\n        self.deny_prefixes = [p if p.endswith(\"/\") else p + \"/\" for p in (deny_prefixes or [])]\n\n    def _deny(self, path: str) -> bool:\n        return any(path.startswith(p) for p in self.deny_prefixes)\n\n    def ls_info(self, path: str) -> list[FileInfo]:\n        return self.inner.ls_info(path)\n    def read(self, file_path: str, offset: int = 0, limit: int = 2000) -> str:\n        return self.inner.read(file_path, offset=offset, limit=limit)\n    def grep_raw(self, pattern: str, path: str | None = None, glob: str | None = None) -> list[GrepMatch] | str:\n        return self.inner.grep_raw(pattern, path, glob)\n    def glob_info(self, pattern: str, path: str = \"/\") -> list[FileInfo]:\n        return self.inner.glob_info(pattern, path)\n    def write(self, file_path: str, content: str) -> WriteResult:\n        if self._deny(file_path):\n            return WriteResult(error=f\"Writes are not allowed under {file_path}\")\n        return self.inner.write(file_path, content)\n    def edit(self, file_path: str, old_string: str, new_string: str, replace_all: bool = False) -> EditResult:\n        if self._deny(file_path):\n            return EditResult(error=f\"Edits are not allowed under {file_path}\")\n        return self.inner.edit(file_path, old_string, new_string, replace_all)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Quick fix: submit a bugfix",
        "type": "text",
        "content": "For simple bugfixes, you can get started immediately:\n\nFork the LangChain or LangGraph repo to your personal GitHub account",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "4. Define tool node",
        "type": "code",
        "content": "from langchain.messages import ToolMessage\n\n\ndef tool_node(state: dict):\n    \"\"\"Performs the tool call\"\"\"\n\n    result = []\n    for tool_call in state[\"messages\"][-1].tool_calls:\n        tool = tools_by_name[tool_call[\"name\"]]\n        observation = tool.invoke(tool_call[\"args\"])\n        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n    return {\"messages\": result}\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/quickstart",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Amazon Neptune",
        "type": "text",
        "content": "Amazon Neptune is a high-performance graph analytics and serverless database for superior scalability and availability.\n\nFor the Cypher and SPARQL integrations below, we need to install the langchain-aws library.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Where to customize",
        "type": "text",
        "content": "There are several points where you can control how context is passed between the main agent and its subagents:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/multi-agent",
        "head_menu_name": "LangChain",
        "side_menu_name": "Multi-agent"
    },
    {
        "title": "Why use subagents?",
        "type": "text",
        "content": "Subagents solve the context bloat problem . When agents use tools with large outputs (web search, file reads, database queries), the context window fills up quickly with intermediate results. Subagents isolate this detailed work—the main agent receives only the final result, not the dozens of tool calls that produced it.\n\nWhen to use subagents:\n\nWhen NOT to use subagents:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Google",
        "type": "text",
        "content": "See Google’s guide on migrating from the Gemini API to Vertex AI for more details on the differences.\n\nIntegration packages for Gemini models and the Vertex AI platform are maintained in the langchain-google repository. You can find a host of LangChain integrations with other Google APIs and services in the googleapis Github organization and the langchain-google-community package.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Isolate storage by assistant ID",
        "type": "text",
        "content": "Each assistant gets its own namespace in the Store, preventing cross-contamination.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "LLM tool selector",
        "type": "text",
        "content": "Instructions for the selection model. Uses built-in prompt if not specified.\n\nMaximum number of tools to select. Defaults to no limit.\n\nList of tool names to always include in the selection",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Vertex AI Model Garden",
        "type": "text",
        "content": "Access Gemini, and hundreds of OSS models via Vertex AI Model Garden service. Requires langchain-google-vertexai .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "ToolRuntime",
        "type": "text",
        "content": "Accessing state:\n\nTools can access the current graph state using ToolRuntime :",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "Gemma on Vertex AI Model Garden",
        "type": "code",
        "content": "from langchain_google_vertexai.gemma import GemmaVertexAIModelGarden\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "LangGraph v1 migration guide",
        "type": "text",
        "content": "This guide outlines changes in LangGraph v1 and how to migrate from previous versions. For a high-level overview of changes, see the what’s new page.\n\nTo upgrade:",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langgraph-v1",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "pip install -qU langchain-google-vertexai\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Google Drive",
        "type": "text",
        "content": "Google Drive file storage. Currently supports Google Docs.\n\nInstall with Drive dependencies:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Parameters",
        "type": "text",
        "content": "A chat model takes parameters that can be used to configure its behavior. The full set of supported parameters varies by model and provider, but standard ones include:\n\nThe name or identifier of the specific model you want to use with a provider.\n\nThe key required for authenticating with the model’s provider. This is usually issued when you sign up for access to the model. Often accessed by setting an environment variable .\n\nControls the randomness of the model’s output. A higher number makes responses more creative; lower ones make them more deterministic.\n\nThe maximum time (in seconds) to wait for a response from the model before canceling the request.\n\nLimits the total number of tokens in the response, effectively controlling how long the output can be.\n\nThe maximum number of attempts the system will make to resend a request if it fails due to issues like network timeouts or rate limits.\n\nUsing init_chat_model , pass these parameters as inline **kwargs :",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Social Platforms",
        "type": "text",
        "content": "The below document loaders allow you to load documents from different social media platforms.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/document_loaders",
        "head_menu_name": "Integrations",
        "side_menu_name": "Document loaders"
    },
    {
        "title": "Multimodal",
        "type": "text",
        "content": "Certain models can process and return non-textual data such as images, audio, and video. You can pass non-textual data to a model by providing content blocks .\n\nAll LangChain chat models with underlying multimodal capabilities support:\n\nSee the multimodal section of the messages guide for details.\n\nSome models can return multimodal data as part of their response. If invoked to do so, the resulting AIMessage will have content blocks with multimodal types.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Multiple structured outputs error",
        "type": "code",
        "content": "================================ Human Message =================================\n\nExtract info: John Doe (john@email.com) is organizing Tech Conference on March 15th\nNone\n================================== Ai Message ==================================\nTool Calls:\n  ContactInfo (call_1)\n Call ID: call_1\n  Args:\n    name: John Doe\n    email: john@email.com\n  EventDetails (call_2)\n Call ID: call_2\n  Args:\n    event_name: Tech Conference\n    date: March 15th\n================================= Tool Message =================================\nName: ContactInfo\n\nError: Model incorrectly returned multiple structured responses (ContactInfo, EventDetails) when only one is expected.\n Please fix your mistakes.\n================================= Tool Message =================================\nName: EventDetails\n\nError: Model incorrectly returned multiple structured responses (ContactInfo, EventDetails) when only one is expected.\n Please fix your mistakes.\n================================== Ai Message ==================================\nTool Calls:\n  ContactInfo (call_3)\n Call ID: call_3\n  Args:\n    name: John Doe\n    email: john@email.com\n================================= Tool Message =================================\nName: ContactInfo\n\nReturning structured response: {'name': 'John Doe', 'email': 'john@email.com'}\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Advanced considerations",
        "type": "text",
        "content": "Or why separate Doc Search from Draft Reply?\n\nThe answer involves trade-offs between resilience and observability.\n\nThe resilience consideration: LangGraph’s durable execution creates checkpoints at node boundaries. When a workflow resumes after an interruption or failure, it starts from the beginning of the node where execution stopped. Smaller nodes mean more frequent checkpoints, which means less work to repeat if something goes wrong. If you combine multiple operations into one large node, a failure near the end means re-executing everything from the start of that node.\n\nWhy we chose this breakdown for the email agent:\n\nIsolation of external services: Doc Search and Bug Track are separate nodes because they call external APIs. If the search service is slow or fails, we want to isolate that from the LLM calls. We can add retry policies to these specific nodes without affecting others.\n\nIntermediate visibility: Having Classify Intent as its own node lets us inspect what the LLM decided before taking action. This is valuable for debugging and monitoring—you can see exactly when and why the agent routes to human review.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Tools",
        "type": "code",
        "content": "import os\nfrom typing import Literal\nfrom tavily import TavilyClient\nfrom deepagents import create_deep_agent\n\ntavily_client = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n\ndef internet_search(\n    query: str,\n    max_results: int = 5,\n    topic: Literal[\"general\", \"news\", \"finance\"] = \"general\",\n    include_raw_content: bool = False,\n):\n    \"\"\"Run a web search\"\"\"\n    return tavily_client.search(\n        query,\n        max_results=max_results,\n        include_raw_content=include_raw_content,\n        topic=topic,\n    )\n\nagent = create_deep_agent(\n    tools=[internet_search]\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/customization",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Customization"
    },
    {
        "title": "Schema validation error",
        "type": "code",
        "content": "from pydantic import BaseModel, Field\nfrom langchain.agents import create_agent\nfrom langchain.agents.structured_output import ToolStrategy\n\n\nclass ProductRating(BaseModel):\n    rating: int | None = Field(description=\"Rating from 1-5\", ge=1, le=5)\n    comment: str = Field(description=\"Review comment\")\n\nagent = create_agent(\n    model=\"gpt-5\",\n    tools=[],\n    response_format=ToolStrategy(ProductRating),  # Default: handle_errors=True\n    system_prompt=\"You are a helpful assistant that parses product reviews. Do not make any field or value up.\"\n)\n\nagent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"Parse this: Amazing product, 10/10!\"}]\n})\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Tool use in the ReAct loop",
        "type": "code",
        "content": "check_inventory(\"WH-1000XM5\")",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Filter by node",
        "type": "code",
        "content": "from typing import TypedDict\nfrom langgraph.graph import START, StateGraph\nfrom langchain_openai import ChatOpenAI\n\nmodel = ChatOpenAI(model=\"gpt-4o-mini\")\n\n\nclass State(TypedDict):\n      topic: str\n      joke: str\n      poem: str\n\n\ndef write_joke(state: State):\n      topic = state[\"topic\"]\n      joke_response = model.invoke(\n            [{\"role\": \"user\", \"content\": f\"Write a joke about {topic}\"}]\n      )\n      return {\"joke\": joke_response.content}\n\n\ndef write_poem(state: State):\n      topic = state[\"topic\"]\n      poem_response = model.invoke(\n            [{\"role\": \"user\", \"content\": f\"Write a short poem about {topic}\"}]\n      )\n      return {\"poem\": poem_response.content}\n\n\ngraph = (\n      StateGraph(State)\n      .add_node(write_joke)\n      .add_node(write_poem)\n      # write both the joke and the poem concurrently\n      .add_edge(START, \"write_joke\")\n      .add_edge(START, \"write_poem\")\n      .compile()\n)\n\n# The \"messages\" stream mode returns a tuple of (message_chunk, metadata)\n# where message_chunk is the token streamed by the LLM and metadata is a dictionary\n# with information about the graph node where the LLM was called and other information\nfor msg, metadata in graph.stream(\n    {\"topic\": \"cats\"},\n    stream_mode=\"messages\",  \n):\n    # Filter the streamed tokens by the langgraph_node field in the metadata\n    # to only include the tokens from the write_poem node\n    if msg.content and metadata[\"langgraph_node\"] == \"write_poem\":\n        print(msg.content, end=\"|\", flush=True)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Custom tool message content",
        "type": "text",
        "content": "The tool_message_content parameter allows you to customize the message that appears in the conversation history when structured output is generated:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Message content",
        "type": "text",
        "content": "You can think of a message’s content as the payload of data that gets sent to the model. Messages have a content attribute that is loosely-typed, supporting strings and lists of untyped objects (e.g., dictionaries). This allows support for provider-native structures directly in LangChain chat models, such as multimodal content and other data.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Structured output",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.structured_output import ToolStrategy\nfrom pydantic import BaseModel\n\n\nclass Weather(BaseModel):\n    temperature: float\n    condition: str\n\ndef weather_tool(city: str) -> str:\n    \"\"\"Get the weather for a city.\"\"\"\n    return f\"it's sunny and 70 degrees in {city}\"\n\nagent = create_agent(\n    \"gpt-4o-mini\",\n    tools=[weather_tool],\n    response_format=ToolStrategy(Weather)\n)\n\nresult = agent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"What's the weather in SF?\"}]\n})\n\nprint(repr(result[\"structured_response\"]))\n# results in `Weather(temperature=70.0, condition='sunny')`\n",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Summarize messages",
        "type": "code",
        "content": "summarize_conversation",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Channels",
        "type": "code",
        "content": "BinaryOperatorAggregate",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/pregel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Runtime"
    },
    {
        "title": "Tool calling",
        "type": "text",
        "content": "When binding user-defined tools, the model’s response includes a request to execute a tool. When using a model separately from an agent , it is up to you to perform the requested action and return the result back to the model for use in subsequent reasoning. Note that when using an agent , the agent loop will handle the tool execution loop for you.\n\nBelow, we show some common ways you can use tool calling.\n\nWhen a model returns tool calls, you need to execute the tools and pass the results back to the model. This creates a conversation loop where the model can use tool results to generate its final response. LangChain includes agent abstractions that handle this orchestration for you.\n\nHere’s a simple example of how to do this:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Tool calling",
        "type": "code",
        "content": "from langchain.tools import tool\n\n@tool\ndef get_weather(location: str) -> str:\n    \"\"\"Get the weather at a location.\"\"\"\n    return f\"It's sunny in {location}.\"\n\n\nmodel_with_tools = model.bind_tools([get_weather])  \n\nresponse = model_with_tools.invoke(\"What's the weather like in Boston?\")\nfor tool_call in response.tool_calls:\n    # View tool calls made by the model\n    print(f\"Tool: {tool_call['name']}\")\n    print(f\"Args: {tool_call['args']}\")\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Add a graph as a node",
        "type": "code",
        "content": "from typing_extensions import TypedDict\nfrom langgraph.graph.state import StateGraph, START\n\nclass State(TypedDict):\n    foo: str\n\n# Subgraph\n\ndef subgraph_node_1(state: State):\n    return {\"foo\": \"hi! \" + state[\"foo\"]}\n\nsubgraph_builder = StateGraph(State)\nsubgraph_builder.add_node(subgraph_node_1)\nsubgraph_builder.add_edge(START, \"subgraph_node_1\")\nsubgraph = subgraph_builder.compile()\n\n# Parent graph\n\nbuilder = StateGraph(State)\nbuilder.add_node(\"node_1\", subgraph)  \nbuilder.add_edge(START, \"node_1\")\ngraph = builder.compile()\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-subgraphs",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Subgraphs"
    },
    {
        "title": "1. Create a repository on GitHub",
        "type": "text",
        "content": "Your application’s code must reside in a GitHub repository to be deployed on LangSmith. Both public and private repositories are supported. For this quickstart, first make sure your app is LangGraph-compatible by following the local server setup guide . Then, push your code to the repository.\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/deploy",
        "head_menu_name": "LangChain",
        "side_menu_name": "Deploy"
    },
    {
        "title": "Static model",
        "type": "text",
        "content": "Model identifier strings support automatic inference (e.g., \"gpt-5\" will be inferred as \"openai:gpt-5\" ). Refer to the reference to see a full list of model identifier string mappings.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Testing first",
        "type": "text",
        "content": "Every change must include comprehensive tests to verify correctness and prevent regressions",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "How it works",
        "type": "text",
        "content": "Callback events allow LangGraph stream() and astream_events() to surface the chat model’s output in real-time.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Durability modes",
        "type": "code",
        "content": "checkpoint_during=False",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/durable-execution",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Durable execution"
    },
    {
        "title": "Trim messages",
        "type": "code",
        "content": "================================== Ai Message ==================================\n\nYour name is Bob, as you mentioned when you first introduced yourself.\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Trajectory Match Evaluator",
        "type": "code",
        "content": "create_trajectory_match_evaluator",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Use with any LLM",
        "type": "text",
        "content": "Let’s invoke the graph with an AIMessage that includes a tool call:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Defining tools",
        "type": "code",
        "content": "from langchain.tools import tool\nfrom langchain.agents import create_agent\n\n\n@tool\ndef search(query: str) -> str:\n    \"\"\"Search for information.\"\"\"\n    return f\"Results for: {query}\"\n\n@tool\ndef get_weather(location: str) -> str:\n    \"\"\"Get weather information for a location.\"\"\"\n    return f\"Weather in {location}: Sunny, 72°F\"\n\nagent = create_agent(model, tools=[search, get_weather])\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "LLMs",
        "type": "code",
        "content": "from langchain_google_genai import GoogleGenerativeAI\n\nllm = GoogleGenerativeAI(model=\"gemini-2.5-flash\")\nresult = llm.invoke(\"Sing a ballad of LangChain.\")\nprint(result)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Use in subgraphs",
        "type": "code",
        "content": "subgraph_builder = StateGraph(...)\nsubgraph = subgraph_builder.compile(checkpointer=True)  \n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Advanced considerations",
        "type": "text",
        "content": "Application-level concerns: The caching discussion in Step 2 (whether to cache search results) is an application-level decision, not a LangGraph framework feature. You implement caching within your node functions based on your specific requirements—LangGraph doesn’t prescribe this.\n\nPerformance considerations: More nodes doesn’t mean slower execution. LangGraph writes checkpoints in the background by default ( async durability mode ), so your graph continues running without waiting for checkpoints to complete. This means you get frequent checkpoints with minimal performance impact. You can adjust this behavior if needed—use \"exit\" mode to checkpoint only at completion, or \"sync\" mode to block execution until each checkpoint is written.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Use with any LLM",
        "type": "code",
        "content": "inputs = {\n    \"messages\": [\n        {\n            \"content\": None,\n            \"role\": \"assistant\",\n            \"tool_calls\": [\n                {\n                    \"id\": \"1\",\n                    \"function\": {\n                        \"arguments\": '{\"place\":\"bedroom\"}',\n                        \"name\": \"get_items\",\n                    },\n                    \"type\": \"function\",\n                }\n            ],\n        }\n    ]\n}\n\nasync for chunk in graph.astream(\n    inputs,\n    stream_mode=\"custom\",\n):\n    print(chunk[\"content\"], end=\"|\", flush=True)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Protocol reference",
        "type": "code",
        "content": "\"Invalid regex pattern: ...\"",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "After model",
        "type": "text",
        "content": "Access short term memory (state) in @after_model middleware to process messages after model calls.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Tool use in the ReAct loop",
        "type": "code",
        "content": "search_products(\"wireless headphones\")",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Development environment",
        "type": "code",
        "content": "cd libs/langchain\nuv sync --all-groups\nmake test  # Ensure tests pass before starting development\n",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Multimodal",
        "type": "code",
        "content": "\"extras\": {\"key\": value}",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Content block reference",
        "type": "text",
        "content": "URL pointing to the image location.\n\nBase64-encoded image data.\n\nReference ID to an externally stored image (e.g., in a provider’s file system or in a bucket).\n\nImage MIME type (e.g., image/jpeg , image/png )",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Using in LangGraph",
        "type": "code",
        "content": "{\n    ...\n    \"store\": {\n        \"index\": {\n            \"embed\": \"openai:text-embeddings-3-small\",\n            \"dims\": 1536,\n            \"fields\": [\"$\"]\n        }\n    }\n}\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Before model",
        "type": "text",
        "content": "Access short term memory (state) in @before_model middleware to process messages before model calls.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Defining state viastate_schema",
        "type": "text",
        "content": "Use the state_schema parameter as a shortcut to define custom state that is only used in tools.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Provider strategy",
        "type": "code",
        "content": "response_format=ToolStrategy(ProductReview)",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Reporting issues",
        "type": "text",
        "content": "Please report any issues discovered with 1.0 on GitHub using the 'v1' label .",
        "side_link": "https://docs.langchain.com/oss/python/releases/langgraph-v1",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Configuring interrupts",
        "type": "text",
        "content": "You must configure a checkpointer to persist the graph state across interrupts.\nIn production, use a persistent checkpointer like AsyncPostgresSaver . For testing or prototyping, use InMemorySaver .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/human-in-the-loop",
        "head_menu_name": "LangChain",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "AWS Lambda",
        "type": "text",
        "content": "Amazon AWS Lambda is a serverless computing service provided by Amazon Web Services ( AWS ). It helps developers to build and run applications and services without\nprovisioning or managing servers. This serverless architecture enables you to focus on writing and\ndeploying code, while AWS automatically takes care of scaling, patching, and managing the\ninfrastructure required to run your applications.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "To-do list tracking",
        "type": "text",
        "content": "The harness provides a write_todos tool that agents can use to maintain a structured task list.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/harness",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Agent harness"
    },
    {
        "title": "Tool calling strategy",
        "type": "text",
        "content": "Custom content for the tool message returned when structured output is generated.\nIf not provided, defaults to a message showing the structured response data.\n\nError handling strategy for structured output validation failures. Defaults to True .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Static model",
        "type": "code",
        "content": "from langchain.agents import create_agent\n\nagent = create_agent(\n    \"gpt-5\",\n    tools=tools\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "4. Create a LangGraph config file",
        "type": "text",
        "content": "create_agent automatically returns a compiled LangGraph graph that we can pass to the graphs key in our configuration file.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/studio",
        "head_menu_name": "LangChain",
        "side_menu_name": "Studio"
    },
    {
        "title": "Initialize a model",
        "type": "text",
        "content": "The easiest way to get started with a standalone model in LangChain is to use init_chat_model to initialize one from a chat model provider of your choice (examples below):",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "SerpApi",
        "type": "text",
        "content": "SerpApi provides API access to Google search results. Requires langchain-community .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Text splitters",
        "type": "text",
        "content": "Break large docs into smaller chunks that will be retrievable individually and fit within a model’s context window.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/retrieval",
        "head_menu_name": "LangChain",
        "side_menu_name": "Retrieval"
    },
    {
        "title": "Overview",
        "type": "text",
        "content": "LangChain provides a key-value store interface for storing and retrieving data by key. The key-value store interface in LangChain is primarily used for caching embeddings .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/stores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Key-value stores"
    },
    {
        "title": "Popular providers",
        "type": "code",
        "content": "langchain-google-genai",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/overview",
        "head_menu_name": "Integrations",
        "side_menu_name": "Overview"
    },
    {
        "title": "Bedrock Chat",
        "type": "text",
        "content": "Amazon Bedrock is a fully managed service that offers a choice of\nhigh-performing foundation models (FMs) from leading AI companies like AI21 Labs , Anthropic , Cohere , Meta , Stability AI , and Amazon via a single API, along with a broad set of capabilities you need to\nbuild generative AI applications with security, privacy, and responsible AI. Using Amazon Bedrock ,\nyou can easily experiment with and evaluate top FMs for your use case, privately customize them with\nyour data using techniques such as fine-tuning and Retrieval Augmented Generation ( RAG ), and build\nagents that execute tasks using your enterprise systems and data sources. Since Amazon Bedrock is\nserverless, you don’t have to manage any infrastructure, and you can securely integrate and deploy\ngenerative AI capabilities into your applications using the AWS services you are already familiar with.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Interrupt decision types",
        "type": "text",
        "content": "The middleware defines three built-in ways a human can respond to an interrupt:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/human-in-the-loop",
        "head_menu_name": "LangChain",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Async with Python < 3.11",
        "type": "text",
        "content": "In Python versions < 3.11, asyncio tasks do not support the context parameter.\nThis limits LangGraph ability to automatically propagate context, and affects LangGraph’s streaming mechanisms in two key ways:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "YouTube Search Tool",
        "type": "code",
        "content": "# Note: YouTubeSearchTool might be in langchain or langchain_community\nfrom langchain.tools import YouTubeSearchTool # Or langchain_community.tools\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Testing requirements",
        "type": "code",
        "content": "make test\n# Or directly:\nuv run --group test pytest tests/unit_tests\n",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Setup",
        "type": "code",
        "content": "import getpass\nimport os\n\n\ndef _set_env(var: str):\n    if not os.environ.get(var):\n        os.environ[var] = getpass.getpass(f\"{var}: \")\n\n\n_set_env(\"ANTHROPIC_API_KEY\")\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-time-travel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Time travel"
    },
    {
        "title": "Error handling strategies",
        "type": "code",
        "content": "response_format = ToolStrategy(\n    schema=ProductRating,\n    handle_errors=False  # All errors raised\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Structured output",
        "type": "text",
        "content": "In some situations, you may want the agent to return an output in a specific format. LangChain provides strategies for structured output via the response_format parameter.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Node changes",
        "type": "text",
        "content": "Structured output used to be generated in a separate node from the main agent. This is no longer the case.\nWe generate structured output in the main loop, reducing cost and latency.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Multimodal",
        "type": "text",
        "content": "Multimodality refers to the ability to work with data that comes in different\nforms, such as text, audio, images, and video. LangChain includes standard types\nfor these data that can be used across providers.\n\nChat models can accept multimodal data as input and generate\nit as output. Below we show short examples of input messages featuring multimodal data.\n\nExtra keys can be included top-level in the content block or nested in \"extras\": {\"key\": value} .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Quick start",
        "type": "code",
        "content": "from langchain.agents import create_agent\n\n\ndef send_email(to: str, subject: str, body: str):\n    \"\"\"Send an email to a recipient.\"\"\"\n    # ... email sending logic\n    return f\"Email sent to {to}\"\n\ndef search_web(query: str):\n    \"\"\"Search the web for information.\"\"\"\n    # ... web search logic\n    return f\"Search results for: {query}\"\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[send_email, search_web],\n    system_prompt=\"You are a helpful assistant that can send emails and search the web.\"\n)\n\n# Run the agent - all steps will be traced automatically\nresponse = agent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"Search for the latest AI news and email a summary to john@example.com\"}]\n})\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/observability",
        "head_menu_name": "LangChain",
        "side_menu_name": "Observability"
    },
    {
        "title": "Tool error handling",
        "type": "code",
        "content": "[\n    ...\n    ToolMessage(\n        content=\"Tool error: Please check your input and try again. (division by zero)\",\n        tool_call_id=\"...\"\n    ),\n    ...\n]\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "4. Create a LangGraph config file",
        "type": "code",
        "content": "{\n  \"dependencies\": [\".\"],\n  \"graphs\": {\n    \"agent\": \"./src/agent.py:agent\"\n  },\n  \"env\": \".env\"\n}\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/studio",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Studio"
    },
    {
        "title": "Execution order",
        "type": "code",
        "content": "middleware2.wrap_model_call()",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Control the input to the subagent",
        "type": "text",
        "content": "There are two main levers to control the input that the main agent passes to a subagent:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/multi-agent",
        "head_menu_name": "LangChain",
        "side_menu_name": "Multi-agent"
    },
    {
        "title": "Validating human input",
        "type": "text",
        "content": "Sometimes you need to validate input from humans and ask again if it’s invalid. You can do this using multiple interrupt calls in a loop.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Memory storage",
        "type": "text",
        "content": "For more information about the memory store, see the Persistence guide.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/long-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Google Translate",
        "type": "text",
        "content": "Google Translate is a multilingual neural machine\ntranslation service developed by Google to translate text, documents and websites\nfrom one language into another.\n\nThe GoogleTranslateTransformer allows you to translate text and HTML with the Google Cloud Translation API .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Chat Completions API",
        "type": "text",
        "content": "Refer to the OpenRouter documentation for more details.\n\nTo capture reasoning tokens ,",
        "side_link": "https://docs.langchain.com/oss/python/integrations/chat",
        "head_menu_name": "Integrations",
        "side_menu_name": "Chat models"
    },
    {
        "title": "Vector stores",
        "type": "text",
        "content": "Specialized databases for storing and searching embeddings.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/retrieval",
        "head_menu_name": "LangChain",
        "side_menu_name": "Retrieval"
    },
    {
        "title": "Get state history",
        "type": "text",
        "content": "In our example, the output of get_state_history will look like this:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Initialization",
        "type": "text",
        "content": "To initialize a vector store, provide it with an embedding model:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Channels",
        "type": "code",
        "content": "total = BinaryOperatorAggregate(int, operator.add)",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/pregel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Runtime"
    },
    {
        "title": "Gmail",
        "type": "text",
        "content": "Load chat history from Gmail threads.\n\nInstall with Gmail dependencies:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "LangGraph",
        "type": "text",
        "content": "Have an idea for a new feature or enhancement?\n\nSearch the issues for the respective repository for existing feature requests:",
        "side_link": "https://docs.langchain.com/oss/python/contributing/overview",
        "head_menu_name": "Contribute",
        "side_menu_name": "Overview"
    },
    {
        "title": "Structured output",
        "type": "code",
        "content": "'structured_response'",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Human-in-the-loop",
        "type": "text",
        "content": "The Human-in-the-Loop (HITL) middleware lets you add human oversight to agent tool calls.\nWhen a model proposes an action that might require review — for example, writing to a file or executing SQL — the middleware can pause execution and wait for a decision.\n\nIt does this by checking each tool call against a configurable policy. If intervention is needed, the middleware issues an interrupt that halts execution. The graph state is saved using LangGraph’s persistence layer , so execution can pause safely and resume later.\n\nA human decision then determines what happens next: the action can be approved as-is ( approve ), modified before running ( edit ), or rejected with feedback ( reject ).",
        "side_link": "https://docs.langchain.com/oss/python/langchain/human-in-the-loop",
        "head_menu_name": "LangChain",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Tool use in the ReAct loop",
        "type": "code",
        "content": "================================= Tool Message =================================\n\nFound 5 products matching \"wireless headphones\". Top 5 results: WH-1000XM5, ...\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Step 4: Create a deep agent",
        "type": "code",
        "content": "# System prompt to steer the agent to be an expert researcher\nresearch_instructions = \"\"\"You are an expert researcher. Your job is to conduct thorough research and then write a polished report.\n\nYou have access to an internet search tool as your primary means of gathering information.\n\n## `internet_search`\n\nUse this to run an internet search for a given query. You can specify the max number of results to return, the topic, and whether raw content should be included.\n\"\"\"\n\nagent = create_deep_agent(\n    tools=[internet_search],\n    system_prompt=research_instructions\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/quickstart",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Dangling tool call repair",
        "type": "text",
        "content": "The harness fixes message history when tool calls are interrupted or cancelled before receiving results.\n\nThe problem:\n\nThe solution:\n\nWhy it’s useful:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/harness",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Agent harness"
    },
    {
        "title": "Summarize messages",
        "type": "code",
        "content": "================================== Ai Message ==================================\n\nFrom our conversation, I can see that you introduced yourself as Bob. That's the name you shared with me when we began talking.\n\nSummary: In this conversation, I was introduced to Bob, who then asked me to write a poem about cats. I composed a poem titled \"The Mystery of Cats\" that captured cats' graceful movements, independent nature, and their special relationship with humans. Bob then requested a similar poem about dogs, so I wrote \"The Joy of Dogs,\" which highlighted dogs' loyalty, enthusiasm, and loving companionship. Both poems were written in a similar style but emphasized the distinct characteristics that make each pet special.\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "langchain-google-genai",
        "side_link": "https://docs.langchain.com/oss/python/integrations/text_embedding",
        "head_menu_name": "Integrations",
        "side_menu_name": "Embedding models"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "pip install -qU \"langchain[azure]\"\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Tool calling",
        "type": "text",
        "content": "You can accumulate chunks to build complete tool calls:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Agent Chat UI",
        "type": "text",
        "content": "LangChain provides a powerful prebuilt user interface that work seamlessly with agents created using create_agent . This UI is designed to provide rich, interactive experiences for your agents with minimal setup, whether you’re running locally or in a deployed context (such as LangSmith ).",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/ui",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Agent Chat UI"
    },
    {
        "title": "Async with Python < 3.11",
        "type": "code",
        "content": "from typing import TypedDict\nfrom langgraph.graph import START, StateGraph\nfrom langchain.chat_models import init_chat_model\n\nmodel = init_chat_model(model=\"gpt-4o-mini\")\n\nclass State(TypedDict):\n    topic: str\n    joke: str\n\n# Accept config as an argument in the async node function\nasync def call_model(state, config):\n    topic = state[\"topic\"]\n    print(\"Generating joke...\")\n    # Pass config to model.ainvoke() to ensure proper context propagation\n    joke_response = await model.ainvoke(  \n        [{\"role\": \"user\", \"content\": f\"Write a joke about {topic}\"}],\n        config,\n    )\n    return {\"joke\": joke_response.content}\n\ngraph = (\n    StateGraph(State)\n    .add_node(call_model)\n    .add_edge(START, \"call_model\")\n    .compile()\n)\n\n# Set stream_mode=\"messages\" to stream LLM tokens\nasync for chunk, metadata in graph.astream(\n    {\"topic\": \"ice cream\"},\n    stream_mode=\"messages\",  \n):\n    if chunk.content:\n        print(chunk.content, end=\"|\", flush=True)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Summarize messages",
        "type": "code",
        "content": "def summarize_conversation(state: State):\n\n    # First, we get any existing summary\n    summary = state.get(\"summary\", \"\")\n\n    # Create our summarization prompt\n    if summary:\n\n        # A summary already exists\n        summary_message = (\n            f\"This is a summary of the conversation to date: {summary}\\n\\n\"\n            \"Extend the summary by taking into account the new messages above:\"\n        )\n\n    else:\n        summary_message = \"Create a summary of the conversation above:\"\n\n    # Add prompt to our history\n    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n    response = model.invoke(messages)\n\n    # Delete all but the 2 most recent messages\n    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n    return {\"summary\": response.content, \"messages\": delete_messages}\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Bring-your-own documents",
        "type": "text",
        "content": "The below retrievers allow you to index and search a custom corpus of documents.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/retrievers",
        "head_menu_name": "Integrations",
        "side_menu_name": "Retrievers"
    },
    {
        "title": "Partial execution",
        "type": "text",
        "content": "For agents made up of larger graphs, you may wish to test partial execution paths within your agent rather than the entire flow end-to-end. In some cases, it may make semantic sense to restructure these sections as subgraphs , which you can invoke in isolation as normal.\n\nHowever, if you do not wish to make changes to your agent graph’s overall structure, you can use LangGraph’s persistence mechanisms to simulate a state where your agent is paused right before the beginning of the desired section, and will pause again at the end of the desired section. The steps are as follows:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/test",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Test"
    },
    {
        "title": "Threads",
        "type": "text",
        "content": "A thread is a unique ID or thread identifier assigned to each checkpoint saved by a checkpointer. It contains the accumulated state of a sequence of runs . When a run is executed, the state of the underlying graph of the assistant will be persisted to the thread.\n\nWhen invoking a graph with a checkpointer, you must specify a thread_id as part of the configurable portion of the config.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Trace selectively",
        "type": "text",
        "content": "You may opt to trace specific invocations or parts of your application using LangSmith’s tracing_context context manager:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/observability",
        "head_menu_name": "LangChain",
        "side_menu_name": "Observability"
    },
    {
        "title": "Invoke",
        "type": "text",
        "content": "The model takes messages as input and outputs messages after generating a complete response.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Productivity tools",
        "type": "code",
        "content": "NotionDirectoryLoader",
        "side_link": "https://docs.langchain.com/oss/python/integrations/document_loaders",
        "head_menu_name": "Integrations",
        "side_menu_name": "Document loaders"
    },
    {
        "title": "Recording & Replaying HTTP Calls",
        "type": "text",
        "content": "Now, simply decorate your tests with the vcr marker:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Finance",
        "type": "text",
        "content": "The following table shows tools that can be used to execute financial transactions such as payments, purchases, and more:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/tools",
        "head_menu_name": "Integrations",
        "side_menu_name": "Tools and toolkits"
    },
    {
        "title": "Content block reference",
        "type": "text",
        "content": "Name of the tool to call\n\nArguments to pass to the tool\n\nUnique identifier for this tool call\n\nExample:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Custom tool message content",
        "type": "code",
        "content": "================================= Tool Message =================================\nName: MeetingAction\n\nReturning structured response: {'task': 'update the project timeline', 'assignee': 'Sarah', 'priority': 'high'}\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Features",
        "type": "text",
        "content": "Studio automatically renders tool calls and results in an intuitive interface.\n\nNavigate through conversation history and fork from any point\n\nView and modify agent state at any point during execution\n\nBuilt-in support for reviewing and responding to agent requests\n\nYou can use generative UI in the Agent Chat UI. For more information, see Implement generative user interfaces with LangGraph .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/ui",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agent Chat UI"
    },
    {
        "title": "Google Cloud",
        "type": "code",
        "content": "langchain-google-vertexai",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Node-style hooks",
        "type": "text",
        "content": "Run sequentially at specific execution points. Use for logging, validation, and state updates.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "6. Build and compile the agent",
        "type": "code",
        "content": "# Build workflow\nagent_builder = StateGraph(MessagesState)\n\n# Add nodes\nagent_builder.add_node(\"llm_call\", llm_call)\nagent_builder.add_node(\"tool_node\", tool_node)\n\n# Add edges to connect nodes\nagent_builder.add_edge(START, \"llm_call\")\nagent_builder.add_conditional_edges(\n    \"llm_call\",\n    should_continue,\n    [\"tool_node\", END]\n)\nagent_builder.add_edge(\"tool_node\", \"llm_call\")\n\n# Compile the agent\nagent = agent_builder.compile()\n\n# Show the agent\nfrom IPython.display import Image, display\ndisplay(Image(agent.get_graph(xray=True).draw_mermaid_png()))\n\n# Invoke\nfrom langchain.messages import HumanMessage\nmessages = [HumanMessage(content=\"Add 3 and 4.\")]\nmessages = agent.invoke({\"messages\": messages})\nfor m in messages[\"messages\"]:\n    m.pretty_print()\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/quickstart",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Text property",
        "type": "text",
        "content": "Use of the .text() method on message objects should drop the parentheses, as it is now a property:",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Enable tracing",
        "type": "code",
        "content": "export LANGSMITH_TRACING=true\nexport LANGSMITH_API_KEY=<your-api-key>\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/observability",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Observability"
    },
    {
        "title": "Log to a project",
        "type": "text",
        "content": "You can set the project name programmatically for specific operations:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/observability",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Observability"
    },
    {
        "title": "Text structure-based",
        "type": "code",
        "content": "RecursiveCharacterTextSplitter",
        "side_link": "https://docs.langchain.com/oss/python/integrations/splitters",
        "head_menu_name": "Integrations",
        "side_menu_name": "Text splitters"
    },
    {
        "title": "Tool calling",
        "type": "code",
        "content": "parallel_tool_calls=False",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Tool Message",
        "type": "code",
        "content": "from langchain.messages import ToolMessage\n\n# Sent to model\nmessage_content = \"It was the best of times, it was the worst of times.\"\n\n# Artifact available downstream\nartifact = {\"document_id\": \"doc_123\", \"page\": 0}\n\ntool_message = ToolMessage(\n    content=message_content,\n    tool_call_id=\"call_123\",\n    name=\"search_books\",\n    artifact=artifact,\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Log to a project",
        "type": "code",
        "content": "import langsmith as ls\n\nwith ls.tracing_context(project_name=\"email-agent-test\", enabled=True):\n    response = agent.invoke({\n        \"messages\": [{\"role\": \"user\", \"content\": \"Send a welcome email\"}]\n    })\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/observability",
        "head_menu_name": "LangChain",
        "side_menu_name": "Observability"
    },
    {
        "title": "Stream multiple modes",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langgraph.config import get_stream_writer\n\n\ndef get_weather(city: str) -> str:\n    \"\"\"Get weather for a given city.\"\"\"\n    writer = get_stream_writer()\n    writer(f\"Looking up data for city: {city}\")\n    writer(f\"Acquired data for city: {city}\")\n    return f\"It's always sunny in {city}!\"\n\nagent = create_agent(\n    model=\"gpt-5-nano\",\n    tools=[get_weather],\n)\n\nfor stream_mode, chunk in agent.stream(  \n    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n    stream_mode=[\"updates\", \"custom\"]\n):\n    print(f\"stream_mode: {stream_mode}\")\n    print(f\"content: {chunk}\")\n    print(\"\\n\")\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/streaming",
        "head_menu_name": "LangChain",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Prerequisites",
        "type": "code",
        "content": "$ pip install -U pytest\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/test",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Test"
    },
    {
        "title": "4. Create a.envfile",
        "type": "text",
        "content": "You will find a .env.example in the root of your new LangGraph app. Create a .env file in the root of your new LangGraph app and copy the contents of the .env.example file into it, filling in the necessary API keys:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/local-server",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Local server"
    },
    {
        "title": "Tool use in the ReAct loop",
        "type": "code",
        "content": "================================== Ai Message ==================================\nTool Calls:\n  search_products (call_abc123)\n Call ID: call_abc123\n  Args:\n    query: wireless headphones\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Microsoft SharePoint",
        "type": "code",
        "content": "from langchain_community.document_loaders.sharepoint import SharePointLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Messages",
        "type": "text",
        "content": "LangChain provides a standard message type that works across all model providers, ensuring consistent behavior regardless of the model being called.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "2. Define state",
        "type": "text",
        "content": "The graph’s state is used to store the messages and the number of LLM calls.\n\nState in LangGraph persists throughout the agent’s execution.\n\nThe Annotated type with operator.add ensures that new messages are appended to the existing list rather than replacing it.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/quickstart",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Side effects called beforeinterruptmust be idempotent",
        "type": "text",
        "content": "Because interrupts work by re-running the nodes they were called from, side effects called before interrupt should (ideally) be idempotent. For context, idempotency means that the same operation can be applied multiple times without changing the result beyond the initial execution.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Vertex AI",
        "type": "code",
        "content": "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Firestore (Native Mode)",
        "type": "code",
        "content": "from langchain_google_firestore import FirestoreVectorStore\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Transport types",
        "type": "text",
        "content": "MCP supports different transport mechanisms for client-server communication:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/mcp",
        "head_menu_name": "LangChain",
        "side_menu_name": "Model Context Protocol (MCP)"
    },
    {
        "title": "Agent harness capabilities",
        "type": "text",
        "content": "We think of deepagents as an “agent harness”. It is the same core tool calling loop as other agent frameworks, but with built-in tools and capabilities.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/harness",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Agent harness"
    },
    {
        "title": "Azure AI Services individual tools",
        "type": "code",
        "content": "AzureCogsText2SpeechTool",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Selecting formats",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\nfrom pydantic import BaseModel, Field\nfrom typing import Callable\n\nclass SimpleResponse(BaseModel):\n    \"\"\"Simple response for early conversation.\"\"\"\n    answer: str = Field(description=\"A brief answer\")\n\nclass DetailedResponse(BaseModel):\n    \"\"\"Detailed response for established conversation.\"\"\"\n    answer: str = Field(description=\"A detailed answer\")\n    reasoning: str = Field(description=\"Explanation of reasoning\")\n    confidence: float = Field(description=\"Confidence score 0-1\")\n\n@wrap_model_call\ndef state_based_output(\n    request: ModelRequest,\n    handler: Callable[[ModelRequest], ModelResponse]\n) -> ModelResponse:\n    \"\"\"Select output format based on State.\"\"\"\n    # request.messages is a shortcut for request.state[\"messages\"]\n    message_count = len(request.messages)  \n\n    if message_count < 3:\n        # Early conversation - use simple format\n        request = request.override(response_format=SimpleResponse)  \n    else:\n        # Established conversation - use detailed format\n        request = request.override(response_format=DetailedResponse)  \n\n    return handler(request)\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[...],\n    middleware=[state_based_output]\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Azure AI Services individual tools",
        "type": "code",
        "content": "AzureCogsSpeech2TextTool",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Azure AI Search",
        "type": "code",
        "content": "from langchain_community.vectorstores.azuresearch import AzureSearch\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Use Cases",
        "type": "text",
        "content": "Below are tutorials for common use cases, organized by framework.",
        "side_link": "https://docs.langchain.com/oss/python/learn",
        "head_menu_name": "Learn",
        "side_menu_name": "Learn"
    },
    {
        "title": "Google Scholar",
        "type": "code",
        "content": "pip install google-search-results langchain-community # Requires langchain-community\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Rate limiting",
        "type": "text",
        "content": "LangChain in comes with (an optional) built-in InMemoryRateLimiter . This limiter is thread safe and can be shared by multiple threads in the same process.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Semantic Search",
        "type": "code",
        "content": "# Find memories about food preferences\n# (This can be done after putting memories into the store)\nmemories = store.search(\n    namespace_for_memory,\n    query=\"What does the user like to eat?\",\n    limit=3  # Return top 3 matches\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Speech-to-Text",
        "type": "code",
        "content": "pip install langchain-google-community[speech]\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Azure Database for PostgreSQL",
        "type": "text",
        "content": "Azure Database for PostgreSQL - Flexible Server is a relational database service based on the open-source Postgres database engine. It’s a fully managed database-as-a-service that can handle mission-critical workloads with predictable performance, security, high availability, and dynamic scalability.\n\nSee set up instructions for Azure Database for PostgreSQL.\n\nYou need to enable pgvector extension in your database to use Postgres as a vector store. Once you have the extension enabled, you can use the PGVector in LangChain to connect to Azure Database for PostgreSQL.\n\nSee a usage example . Simply use the connection string from your Azure Portal.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Semantic Search",
        "type": "code",
        "content": "from langchain.embeddings import init_embeddings\n\nstore = InMemoryStore(\n    index={\n        \"embed\": init_embeddings(\"openai:text-embedding-3-small\"),  # Embedding provider\n        \"dims\": 1536,                              # Embedding dimensions\n        \"fields\": [\"food_preference\", \"$\"]              # Fields to embed\n    }\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Use a virtual filesystem",
        "type": "code",
        "content": "files(path text primary key, content text, created_at timestamptz, modified_at timestamptz)",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "2-step RAG",
        "type": "text",
        "content": "In 2-Step RAG , the retrieval step is always executed before the generation step. This architecture is straightforward and predictable, making it suitable for many applications where the retrieval of relevant documents is a clear prerequisite for generating an answer.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/retrieval",
        "head_menu_name": "LangChain",
        "side_menu_name": "Retrieval"
    },
    {
        "title": "Use semantic search",
        "type": "code",
        "content": "from langchain.embeddings import init_embeddings\nfrom langgraph.store.memory import InMemoryStore\n\n# Create store with semantic search enabled\nembeddings = init_embeddings(\"openai:text-embedding-3-small\")\nstore = InMemoryStore(\n    index={\n        \"embed\": embeddings,\n        \"dims\": 1536,\n    }\n)\n\nstore.put((\"user_123\", \"memories\"), \"1\", {\"text\": \"I love pizza\"})\nstore.put((\"user_123\", \"memories\"), \"2\", {\"text\": \"I am a plumber\"})\n\nitems = store.search(\n    (\"user_123\", \"memories\"), query=\"I'm hungry\", limit=1\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Add metadata to traces",
        "type": "text",
        "content": "tracing_context also accepts tags and metadata for fine-grained control:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/observability",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Observability"
    },
    {
        "title": "AI Message",
        "type": "text",
        "content": "An AIMessage represents the output of a model invocation. They can include multimodal data, tool calls, and provider-specific metadata that you can later access.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Structured outputs",
        "type": "text",
        "content": "Models can be requested to provide their response in a format matching a given schema. This is useful for ensuring the output can be easily parsed and used in subsequent processing. LangChain supports multiple schema types and methods for enforcing structured outputs.\n\nPydantic models provide the richest feature set with field validation, descriptions, and nested structures.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Document loaders",
        "type": "text",
        "content": "Ingest data from external sources (Google Drive, Slack, Notion, etc.), returning standardized",
        "side_link": "https://docs.langchain.com/oss/python/langchain/retrieval",
        "head_menu_name": "LangChain",
        "side_menu_name": "Retrieval"
    },
    {
        "title": "SubAgent (Dictionary-based)",
        "type": "code",
        "content": "\"provider:model-name\"",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "LangGraph",
        "type": "text",
        "content": "If no requests exist, start a new discussion under the relevant category so that project maintainers and the community can provide feedback.\n\nBe sure to describe the use case and why it would be valuable to others. If possible, provide examples or mockups where applicable. Outline test cases that should pass.\n\nDocumentation improvements are always welcome! We strive to keep our docs clear and comprehensive, and your perspective can make a big difference.",
        "side_link": "https://docs.langchain.com/oss/python/contributing/overview",
        "head_menu_name": "Contribute",
        "side_menu_name": "Overview"
    },
    {
        "title": "Install",
        "type": "code",
        "content": "pip install -U langchain\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/overview",
        "head_menu_name": "LangChain",
        "side_menu_name": "Overview"
    },
    {
        "title": "Basic tool definition",
        "type": "code",
        "content": "from langchain.tools import tool\n\n@tool\ndef search_database(query: str, limit: int = 10) -> str:\n    \"\"\"Search the customer database for records matching the query.\n\n    Args:\n        query: Search terms to look for\n        limit: Maximum number of results to return\n    \"\"\"\n    return f\"Found {limit} results for '{query}'\"\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "Pre-model hook",
        "type": "text",
        "content": "Common use cases include:\n\nv1 now has summarization middleware as a built in option:",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Custom state",
        "type": "text",
        "content": "state_schema is still supported for backwards compatibility on create_agent .",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Tool retry",
        "type": "code",
        "content": "initial_delay * (backoff_factor ** retry_number)",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Case studies",
        "type": "text",
        "content": "This list of companies using LangGraph and their success stories is compiled from public sources. If your company uses LangGraph, we’d love for you to share your story and add it to the list. You’re also welcome to contribute updates based on publicly available information from other companies, such as blog posts or press releases.\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/case-studies",
        "head_menu_name": "Learn",
        "side_menu_name": "Case studies"
    },
    {
        "title": "Google Drive",
        "type": "text",
        "content": "Retrieve documents from Google Drive.\n\nInstall required packages:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Model",
        "type": "text",
        "content": "By default, deepagents uses \"claude-sonnet-4-5-20250929\" . You can customize this by passing any LangChain model object .",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/customization",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Customization"
    },
    {
        "title": "Tool calling strategy",
        "type": "code",
        "content": "tuple[type[Exception], ...]",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Token usage",
        "type": "code",
        "content": "{\n    'gpt-4o-mini-2024-07-18': {\n        'input_tokens': 8,\n        'output_tokens': 10,\n        'total_tokens': 18,\n        'input_token_details': {'audio': 0, 'cache_read': 0},\n        'output_token_details': {'audio': 0, 'reasoning': 0}\n    },\n    'claude-haiku-4-5-20251001': {\n        'input_tokens': 8,\n        'output_tokens': 21,\n        'total_tokens': 29,\n        'input_token_details': {'cache_read': 0, 'cache_creation': 0}\n    }\n}\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "LLM Steps",
        "type": "text",
        "content": "When a step needs to understand, analyze, generate text, or make reasoning decisions:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Google Drive",
        "type": "code",
        "content": "from langchain_googledrive.retrievers import GoogleDriveRetriever\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Webpages",
        "type": "text",
        "content": "The below document loaders allow you to load webpages.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/document_loaders",
        "head_menu_name": "Integrations",
        "side_menu_name": "Document loaders"
    },
    {
        "title": "Handoffs",
        "type": "text",
        "content": "In handoffs , agents can directly pass control to each other. The “active” agent changes, and the user interacts with whichever agent currently has control.\n\nFlow:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/multi-agent",
        "head_menu_name": "LangChain",
        "side_menu_name": "Multi-agent"
    },
    {
        "title": "Featured providers",
        "type": "code",
        "content": "ChatGoogleGenerativeAI",
        "side_link": "https://docs.langchain.com/oss/python/integrations/chat",
        "head_menu_name": "Integrations",
        "side_menu_name": "Chat models"
    },
    {
        "title": "Google Scholar",
        "type": "code",
        "content": "google-search-results",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Usage",
        "type": "text",
        "content": "LangChain’s agent manages short-term memory as a part of your agent’s state.\n\nBy storing these in the graph’s state, the agent can access the full context for a given conversation while maintaining separation between different threads.\n\nState is persisted to a database (or memory) using a checkpointer so the thread can be resumed at any time.\n\nShort-term memory updates when the agent is invoked or a step (like a tool call) is completed, and the state is read at the start of each step.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Repository structure",
        "type": "code",
        "content": "langchain-text-splitters",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Microsoft Presidio",
        "type": "text",
        "content": "Presidio (Origin from Latin praesidium ‘protection, garrison’)\nhelps to ensure sensitive data is properly managed and governed. It provides fast identification and\nanonymization modules for private entities in text and images such as credit card numbers, names,\nlocations, social security numbers, bitcoin wallets, US phone numbers, financial data and more.\n\nFirst, you need to install several python packages and download a SpaCy model.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Execution order",
        "type": "code",
        "content": "middleware2.after_agent()",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Agent jumps",
        "type": "text",
        "content": "To exit early from middleware, return a dictionary with jump_to :",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Error handling strategies",
        "type": "code",
        "content": "ToolStrategy(\n    schema=ProductRating,\n    handle_errors=ValueError  # Only retry on ValueError, raise others\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Use in production",
        "type": "text",
        "content": "You need to call store.setup() the first time you’re using Postgres store",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Tools",
        "type": "text",
        "content": "In addition to any tools that you provide, deep agents also get access to a number of default tools:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/customization",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Customization"
    },
    {
        "title": "Model call limit",
        "type": "text",
        "content": "Limit the number of model calls to prevent infinite loops or excessive costs.\n\nPerfect for:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "LLM tokens",
        "type": "text",
        "content": "If your LLM is not available as a LangChain integration, you can stream its outputs using custom mode instead. See use with any LLM for details.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Durability modes",
        "type": "text",
        "content": "for persistence policy management, with the following mapping:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/durable-execution",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Durable execution"
    },
    {
        "title": "Productivity tools",
        "type": "text",
        "content": "The below document loaders allow you to load data from commonly used productivity tools.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/document_loaders",
        "head_menu_name": "Integrations",
        "side_menu_name": "Document loaders"
    },
    {
        "title": "Custom state",
        "type": "text",
        "content": "Custom state extends the default agent state with additional fields. You can define custom state in two ways:",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Error handling strategies",
        "type": "code",
        "content": "MultipleStructuredOutputsError",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Model",
        "type": "text",
        "content": "The model is the reasoning engine of your agent. It can be specified in multiple ways, supporting both static and dynamic model selection.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Protocol reference",
        "type": "code",
        "content": "read(file_path: str, offset: int = 0, limit: int = 2000) -> str",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Document AI Warehouse",
        "type": "code",
        "content": "pip install langchain-google-community # Add specific docai dependencies if needed\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "from langchain_chroma import Chroma\n\nvector_store = Chroma(\n    collection_name=\"example_collection\",\n    embedding_function=embeddings,\n    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Google Translate",
        "type": "code",
        "content": "GoogleTranslateTransformer",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "2. Prepare your agent",
        "type": "text",
        "content": "We’ll use the following simple agent as an example:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/studio",
        "head_menu_name": "LangChain",
        "side_menu_name": "Studio"
    },
    {
        "title": "Batch",
        "type": "code",
        "content": "for response in model.batch_as_completed([\n    \"Why do parrots have colorful feathers?\",\n    \"How do airplanes fly?\",\n    \"What is quantum computing?\"\n]):\n    print(response)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Quickstart",
        "type": "text",
        "content": "This quickstart takes you from a simple setup to a fully functional AI agent in just a few minutes.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/quickstart",
        "head_menu_name": "LangChain",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Encryption",
        "type": "text",
        "content": "Checkpointers can optionally encrypt all persisted state. To enable this, pass an instance of EncryptedSerializer to the serde argument of any BaseCheckpointSaver implementation. The easiest way to create an encrypted serializer is via from_pycryptodome_aes , which reads the AES key from the LANGGRAPH_AES_KEY environment variable (or accepts a key argument):",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Invoke a graph from a node",
        "type": "text",
        "content": "A simple way to implement a subgraph is to invoke a graph from inside the node of another graph. In this case subgraphs can have completely different schemas from the parent graph (no shared keys). For example, you might want to keep a private message history for each of the agents in a multi-agent system.\n\nIf that’s the case for your application, you need to define a node function that invokes the subgraph . This function needs to transform the input (parent) state to the subgraph state before invoking the subgraph, and transform the results back to the parent state before returning the state update from the node.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-subgraphs",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Subgraphs"
    },
    {
        "title": "Text splitters",
        "type": "text",
        "content": "Text splitters break large docs into smaller chunks that will be retrievable individually and fit within model context window limit.\n\nThere are several strategies for splitting documents, each with its own advantages.\n\nFor most use cases, start with the RecursiveCharacterTextSplitter . It provides a solid balance between keeping context intact and managing chunk size. This default strategy works well out of the box, and you should only consider adjusting it if you need to fine-tune performance for your specific application.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/splitters",
        "head_menu_name": "Integrations",
        "side_menu_name": "Text splitters"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "import getpass\nimport os\n\nif not os.environ.get(\"VOYAGE_API_KEY\"):\n  os.environ[\"VOYAGE_API_KEY\"] = getpass.getpass(\"Enter API key for Voyage AI: \")\n\nfrom langchain-voyageai import VoyageAIEmbeddings\n\nembeddings = VoyageAIEmbeddings(model=\"voyage-3\")\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Tools",
        "type": "code",
        "content": "from langchain.agents import create_agent\n\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    tools=[check_weather, search_web]\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Quickstart",
        "type": "code",
        "content": "agent = create_deep_agent(backend=lambda rt: StoreBackend(rt))",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "pip install -qU langchain-nvidia-ai-endpoints\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Similarity search",
        "type": "text",
        "content": "Issue a semantic query using similarity_search , which returns the closest embedded documents:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Custom middleware",
        "type": "text",
        "content": "Build custom middleware by implementing hooks that run at specific points in the agent execution flow.\n\nYou can create middleware in two ways:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Trajectory match",
        "type": "text",
        "content": "Hard-code a reference trajectory for a given input and validate the run via a step-by-step comparison.\n\nIdeal for testing well-defined workflows where you know the expected behavior. Use when you have specific expectations about which tools should be called and in what order. This approach is deterministic, fast, and cost-effective since it doesn’t require additional LLM calls.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Always use a checkpointer",
        "type": "text",
        "content": "Human-in-the-loop requires a checkpointer to persist agent state between the interrupt and resume:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/human-in-the-loop",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Checkpointer interface",
        "type": "text",
        "content": "Each checkpointer conforms to BaseCheckpointSaver interface and implements the following methods:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Chat Completions API",
        "type": "text",
        "content": "To use OpenRouter, you will need to sign up for an account and obtain an API key .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/chat",
        "head_menu_name": "Integrations",
        "side_menu_name": "Chat models"
    },
    {
        "title": "Add long-term memory",
        "type": "text",
        "content": "Use long-term memory to store user-specific or application-specific data across conversations.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Azure AI",
        "type": "code",
        "content": "from langchain_azure_ai.embeddings import AzureAIEmbeddingsModel\n\nembed_model = AzureAIEmbeddingsModel(\n    model_name=\"text-embedding-ada-002\"\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "SageMaker Endpoint",
        "type": "code",
        "content": "from langchain_aws import SagemakerEndpoint\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Disable streaming",
        "type": "text",
        "content": "In some applications you might need to disable streaming of individual tokens for a given model.\n\nThis is useful in multi-agent systems to control which agents stream their output.\n\nSee the Models guide to learn how to disable streaming.\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/streaming",
        "head_menu_name": "LangChain",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Namespace",
        "type": "text",
        "content": "Most of these are re-exported from langchain-core for convenience, which gives you a focused API surface for building agents.",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Related resources",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "LLM tokens",
        "type": "text",
        "content": "Use the messages streaming mode to stream Large Language Model (LLM) outputs token by token from any part of your graph, including nodes, tools, subgraphs, or tasks.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Google Generative AI (Gemini API & AI Studio)",
        "type": "text",
        "content": "Access Google Gemini models directly using the Gemini API, best suited for rapid development and experimentation. Gemini models are available in Google AI Studio .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Similarity metrics",
        "type": "text",
        "content": "Several metrics are commonly used to compare embeddings:\n\nHere’s an example of computing cosine similarity between two vectors:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/text_embedding",
        "head_menu_name": "Integrations",
        "side_menu_name": "Embedding models"
    },
    {
        "title": "Wrong subagent being selected",
        "type": "text",
        "content": "Problem : Main agent calls inappropriate subagent for the task.\n\nSolution : Differentiate subagents clearly in descriptions:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Chat models",
        "type": "code",
        "content": "data:image/png;base64,...",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "ActiveLoop DeepLake",
        "type": "text",
        "content": "Vector database for AI applications with deep learning focus.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/all_providers",
        "head_menu_name": "Integrations",
        "side_menu_name": "All providers"
    },
    {
        "title": "Tool calling",
        "type": "text",
        "content": "Many models support calling multiple tools in parallel when appropriate. This allows the model to gather information from different sources simultaneously.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Subagents",
        "type": "text",
        "content": "Deep agents can create subagents to delegate work. You can specify custom subagents in the subagents parameter. Subagents are useful for context quarantine (keeping the main agent’s context clean) and for providing specialized instructions.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "System Prompt",
        "type": "text",
        "content": "The system prompt sets the LLM’s behavior and capabilities. Different users, contexts, or conversation stages need different instructions. Successful agents draw on memories, preferences, and configuration to provide the right instructions for the current state of the conversation.\n\nAccess message count or conversation context from state:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Use with any LLM",
        "type": "text",
        "content": "This lets you integrate raw LLM clients or external services that provide their own streaming interfaces, making LangGraph highly flexible for custom setups.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "4. Create a LangGraph config file",
        "type": "code",
        "content": "my-app/\n├── src\n│   └── agent.py\n├── .env\n└── langgraph.json\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/studio",
        "head_menu_name": "LangChain",
        "side_menu_name": "Studio"
    },
    {
        "title": "Use time-travel",
        "type": "text",
        "content": "When working with non-deterministic systems that make model-based decisions (e.g., agents powered by LLMs), it can be useful to examine their decision-making process in detail:\n\nLangGraph provides time travel functionality to support these use cases. Specifically, you can resume execution from a prior checkpoint — either replaying the same state or modifying it to explore alternatives. In all cases, resuming past execution produces a new fork in the history.\n\nTo use time-travel in LangGraph:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-time-travel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Time travel"
    },
    {
        "title": "Interface",
        "type": "code",
        "content": "embed_documents(texts: List[str]) → List[List[float]]",
        "side_link": "https://docs.langchain.com/oss/python/integrations/text_embedding",
        "head_menu_name": "Integrations",
        "side_menu_name": "Embedding models"
    },
    {
        "title": "Google Finance",
        "type": "code",
        "content": "pip install google-search-results langchain-community # Requires langchain-community\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Tool error handling",
        "type": "text",
        "content": "To customize how tool errors are handled, use the @wrap_tool_call decorator to create middleware:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Runtime context",
        "type": "text",
        "content": "When you invoke an agent, it’s often the case that you want to pass two types of data:\n\nIn v1, static context is supported by setting the context parameter to invoke and stream .",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Contributing to documentation",
        "type": "text",
        "content": "Accessible documentation is a vital part of LangChain. We welcome both documentation for new features/ integrations , as well as community improvements to existing docs.\n\nWe generally do not merge new tutorials from outside contributors without an acute need. If you feel that a certain topic is missing from docs or is not sufficiently covered, please open a new issue .\n\nAll documentation falls under one of four categories:",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "Studio",
        "type": "text",
        "content": "This guide will walk you through how to use Studio to visualize, interact, and debug your agent locally.\n\nStudio is our free-to-use, powerful agent IDE that integrates with LangSmith to enable tracing, evaluation, and prompt engineering. See exactly how your agent thinks, trace every decision, and ship smarter, more reliable agents.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/studio",
        "head_menu_name": "LangChain",
        "side_menu_name": "Studio"
    },
    {
        "title": "Popular providers",
        "type": "code",
        "content": "langchain-google-vertexai",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/overview",
        "head_menu_name": "Integrations",
        "side_menu_name": "Overview"
    },
    {
        "title": "Next steps",
        "type": "text",
        "content": "Now that you have a LangGraph app running locally, take your journey further by exploring deployment and advanced features:\n\nDeployment quickstart : Deploy your LangGraph app using LangSmith.\n\nLangSmith : Learn about foundational LangSmith concepts.\n\nPython SDK Reference : Explore the Python SDK API Reference.\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/local-server",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Local server"
    },
    {
        "title": "Mintlify components",
        "type": "text",
        "content": "Use appropriate Mintlify components to enhance readability:",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "Migrate tocreate_agent",
        "type": "text",
        "content": "Prior to v1.0, we recommended using langgraph.prebuilt.create_react_agent to build agents. Now, we recommend you use langchain.agents.create_agent to build agents.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Access",
        "type": "code",
        "content": "from dataclasses import dataclass\n\nfrom langchain.agents import create_agent\n\n\n@dataclass\nclass Context:\n    user_name: str\n\nagent = create_agent(\n    model=\"gpt-5-nano\",\n    tools=[...],\n    context_schema=Context  \n)\n\nagent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my name?\"}]},\n    context=Context(user_name=\"John Smith\")  \n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/runtime",
        "head_menu_name": "LangChain",
        "side_menu_name": "Runtime"
    },
    {
        "title": "Conversation history summarization",
        "type": "text",
        "content": "The harness automatically compresses old conversation history when token usage becomes excessive.\n\nConfiguration:\n\nWhy it’s useful:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/harness",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Agent harness"
    },
    {
        "title": "Token usage",
        "type": "code",
        "content": "{'input_tokens': 8,\n 'output_tokens': 304,\n 'total_tokens': 312,\n 'input_token_details': {'audio': 0, 'cache_read': 0},\n 'output_token_details': {'audio': 0, 'reasoning': 256}}\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Basic tool definition",
        "type": "text",
        "content": "Type hints are required as they define the tool’s input schema. The docstring should be informative and concise to help the model understand the tool’s purpose.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "LangSmith Integration",
        "type": "code",
        "content": "pytest test_trajectory.py --langsmith-output\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Local models",
        "type": "text",
        "content": "LangChain supports running models locally on your own hardware. This is useful for scenarios where either data privacy is critical, you want to invoke a custom model, or when you want to avoid the costs incurred when using a cloud-based model.\n\nOllama is one of the easiest ways to run models locally. See the full list of local integrations on the integrations page .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Vertex AI Search",
        "type": "code",
        "content": "langchain-google-community",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Human-in-the-loop patterns",
        "type": "text",
        "content": "Learn how to add tool approval before execution, batch approval, and other patterns",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Stream Writer",
        "type": "text",
        "content": "Stream custom updates from tools as they execute using runtime.stream_writer . This is useful for providing real-time feedback to users about what a tool is doing.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "Invocation config",
        "type": "text",
        "content": "When invoking a model, you can pass additional configuration through the config parameter using a RunnableConfig dictionary. This provides run-time control over execution behavior, callbacks, and metadata tracking.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "from langchain_core.embeddings import DeterministicFakeEmbedding\n\nembeddings = DeterministicFakeEmbedding(size=4096)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Human Message",
        "type": "text",
        "content": "A HumanMessage represents user input and interactions. They can contain text, images, audio, files, and any other amount of multimodal content .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Tool calling",
        "type": "code",
        "content": "model_with_tools = model.bind_tools([get_weather])\n\nresponse = model_with_tools.invoke(\n    \"What's the weather in Boston and Tokyo?\"\n)\n\n\n# The model may generate multiple tool calls\nprint(response.tool_calls)\n# [\n#   {'name': 'get_weather', 'args': {'location': 'Boston'}, 'id': 'call_1'},\n#   {'name': 'get_weather', 'args': {'location': 'Tokyo'}, 'id': 'call_2'},\n# ]\n\n\n# Execute all tools (can be done in parallel with async)\nresults = []\nfor tool_call in response.tool_calls:\n    if tool_call['name'] == 'get_weather':\n        result = get_weather.invoke(tool_call)\n    ...\n    results.append(result)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Vertex AI Vector Search",
        "type": "code",
        "content": "from langchain_google_vertexai import VectorSearchVectorStoreDatastore\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Add metadata to traces",
        "type": "text",
        "content": "This custom metadata and tags will be attached to the trace in LangSmith.\n\nTo learn more about how to use traces to debug, evaluate, and monitor your agents, see the LangSmith documentation .",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/observability",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Observability"
    },
    {
        "title": "Initialize a model",
        "type": "text",
        "content": "See init_chat_model for more detail, including information on how to pass model parameters .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Using in LangGraph",
        "type": "code",
        "content": "from langgraph.checkpoint.memory import InMemorySaver\n\n# We need this because we want to enable threads (conversations)\ncheckpointer = InMemorySaver()\n\n# ... Define the graph ...\n\n# Compile the graph with the checkpointer and store\ngraph = graph.compile(checkpointer=checkpointer, store=in_memory_store)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Execution order",
        "type": "code",
        "content": "middleware1.before_agent()",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Vertex AI image editor",
        "type": "code",
        "content": "langchain-google-vertexai",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Code quality standards",
        "type": "text",
        "content": "Quality requirements:\n\nRequired : Complete type annotations for all functions",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "langchain-classic",
        "type": "code",
        "content": "CacheBackedEmbeddings",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Environment variables",
        "type": "text",
        "content": "If you’re working with a deployed LangGraph application locally, you can configure environment variables in the env key of the LangGraph configuration file .",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/application-structure",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Application structure"
    },
    {
        "title": "Self-improving instructions",
        "type": "code",
        "content": "agent = create_deep_agent(\n    store=store,\n    use_longterm_memory=True,\n    system_prompt=\"\"\"You have a file at /memories/instructions.txt with additional\n    instructions and preferences.\n\n    Read this file at the start of conversations to understand user preferences.\n\n    When users provide feedback like \"please always do X\" or \"I prefer Y\",\n    update /memories/instructions.txt using the edit_file tool.\"\"\"\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Quick start",
        "type": "text",
        "content": "By default, the trace will be logged to the project with the name default . To configure a custom project name, see Log to a project .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/observability",
        "head_menu_name": "LangChain",
        "side_menu_name": "Observability"
    },
    {
        "title": "Ollama",
        "type": "text",
        "content": "All LangChain integrations with Ollama .\n\nOllama allows you to run open-source models (like gpt-oss ) locally.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/ollama",
        "head_menu_name": "Integrations",
        "side_menu_name": "Ollama"
    },
    {
        "title": "YouTube Transcripts Loader",
        "type": "code",
        "content": "from langchain_community.document_loaders import YoutubeLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "SageMaker Endpoint",
        "type": "code",
        "content": "from langchain_community.embeddings import SagemakerEndpointEmbeddings\nfrom langchain_community.llms.sagemaker_endpoint import ContentHandlerBase\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Middleware",
        "type": "text",
        "content": "Middleware is the defining feature of create_agent . It offers a highly customizable entry-point, raising the ceiling for what you can build.",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Subagent middleware",
        "type": "text",
        "content": "Handing off tasks to subagents isolates context, keeping the main (supervisor) agent’s context window clean while still going deep on a task.\n\nThe subagents middleware allows you to supply subagents through a task tool.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/middleware",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Google Finance",
        "type": "code",
        "content": "google-search-results",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Get state",
        "type": "code",
        "content": "graph.get_state(config)",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "AzureOpenAI",
        "type": "text",
        "content": "Wrapper for (legacy) OpenAI text completion models hosted on Azure.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/openai",
        "head_menu_name": "Integrations",
        "side_menu_name": "OpenAI"
    },
    {
        "title": "Advanced considerations",
        "type": "text",
        "content": "Different failure modes: LLM calls, database lookups, and email sending have different retry strategies. Separate nodes let you configure these independently.\n\nReusability and testing: Smaller nodes are easier to test in isolation and reuse in other workflows.\n\nA different valid approach: You could combine Read Email and Classify Intent into a single node. You’d lose the ability to inspect the raw email before classification and would repeat both operations on any failure in that node. For most applications, the observability and debugging benefits of separate nodes are worth the trade-off.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Contributing",
        "type": "text",
        "content": "Welcome! Thank you for your interest in contributing.\n\nLangChain has helped form the largest developer community in generative AI, and we’re always open to new contributors. Whether you’re fixing bugs, adding features, improving documentation, or sharing feedback, your involvement helps make LangChain and LangGraph better for everyone.",
        "side_link": "https://docs.langchain.com/oss/python/contributing/overview",
        "head_menu_name": "Contribute",
        "side_menu_name": "Overview"
    },
    {
        "title": "Protocol reference",
        "type": "code",
        "content": "\"Error: File '/x' not found\"",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Subagent interrupts",
        "type": "text",
        "content": "Each subagent can have its own interrupt_on configuration that overrides the main agent’s settings:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/human-in-the-loop",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "create_agent",
        "type": "text",
        "content": "create_agent is the standard way to build agents in LangChain 1.0. It provides a simpler interface than langgraph.prebuilt.create_react_agent while offering greater customization potential by using middleware .",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Standard content blocks",
        "type": "code",
        "content": "from langchain.messages import AIMessage\n\nmessage = AIMessage(\n    content=[\n        {\"type\": \"thinking\", \"thinking\": \"...\", \"signature\": \"WaUjzkyp...\"},\n        {\"type\": \"text\", \"text\": \"...\"},\n    ],\n    response_metadata={\"model_provider\": \"anthropic\"}\n)\nmessage.content_blocks\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Studio",
        "type": "text",
        "content": "This guide will walk you through how to use Studio to visualize, interact, and debug your agent locally.\n\nStudio is our free-to-use, powerful agent IDE that integrates with LangSmith to enable tracing, evaluation, and prompt engineering. See exactly how your agent thinks, trace every decision, and ship smarter, more reliable agents.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/studio",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Studio"
    },
    {
        "title": "In the hot path",
        "type": "text",
        "content": "Creating memories during runtime offers both advantages and challenges. On the positive side, this approach allows for real-time updates, making new memories immediately available for use in subsequent interactions. It also enables transparency, as users can be notified when memories are created and stored.\n\nHowever, this method also presents challenges. It may increase complexity if the agent requires a new tool to decide what to commit to memory. In addition, the process of reasoning about what to save to memory can impact agent latency. Finally, the agent must multitask between memory creation and its other responsibilities, potentially affecting the quantity and quality of memories created.\n\nAs an example, ChatGPT uses a save_memories tool to upsert memories as content strings, deciding whether and how to use this tool with each user message. See our memory-agent template as an reference implementation.",
        "side_link": "https://docs.langchain.com/oss/python/concepts/memory",
        "head_menu_name": "Learn",
        "side_menu_name": "Memory"
    },
    {
        "title": "5. Install dependencies",
        "type": "text",
        "content": "In the root of your new LangGraph app, install the dependencies:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/studio",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Studio"
    },
    {
        "title": "Using in LangGraph",
        "type": "text",
        "content": "When we use the LangSmith, either locally (e.g., in Studio ) or hosted with LangSmith , the base store is available to use by default and does not need to be specified during graph compilation. To enable semantic search, however, you do need to configure the indexing settings in your langgraph.json file. For example:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Semantic Search",
        "type": "text",
        "content": "Now when searching, you can use natural language queries to find relevant memories:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Streaming and chunks",
        "type": "code",
        "content": "chunks = []\nfull_message = None\nfor chunk in model.stream(\"Hi\"):\n    chunks.append(chunk)\n    print(chunk.text)\n    full_message = chunk if full_message is None else full_message + chunk\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "values",
        "type": "code",
        "content": "graph.update_state(config, {\"foo\": 2, \"bar\": [\"b\"]})\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "PII detection",
        "type": "text",
        "content": "Type of PII to detect. Can be a built-in type ( email , credit_card , ip , mac_address , url ) or a custom type name.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Model",
        "type": "text",
        "content": "The actual model (including configuration) to be called.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "5. Define end logic",
        "type": "code",
        "content": "from typing import Literal\nfrom langgraph.graph import StateGraph, START, END\n\n\ndef should_continue(state: MessagesState) -> Literal[\"tool_node\", END]:\n    \"\"\"Decide if we should continue the loop or stop based upon whether the LLM made a tool call\"\"\"\n\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n\n    # If the LLM makes a tool call, then perform an action\n    if last_message.tool_calls:\n        return \"tool_node\"\n\n    # Otherwise, we stop (reply to the user)\n    return END\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/quickstart",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "AWS (Amazon)",
        "type": "text",
        "content": "All LangChain integrations with the Amazon AWS platform.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Wrap-style hooks",
        "type": "text",
        "content": "You decide if the handler is called zero times (short-circuit), once (normal flow), or multiple times (retry logic).\n\nExample: Model retry middleware",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Subagent not being called",
        "type": "text",
        "content": "Problem : Main agent tries to do work itself instead of delegating.\n\nSolutions :\n\nMake descriptions more specific:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Popular providers",
        "type": "code",
        "content": "langchain-unstructured",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/overview",
        "head_menu_name": "Integrations",
        "side_menu_name": "Overview"
    },
    {
        "title": "Tools",
        "type": "text",
        "content": "The argument will no longer accept ToolNode instances.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Try out your agent",
        "type": "text",
        "content": "The graph pauses when it hits interrupt() , saves everything to the checkpointer, and waits. It can resume days later, picking up exactly where it left off. The thread_id ensures all state for this conversation is preserved together.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "exampleparameter removed fromAIMessage",
        "type": "text",
        "content": "The example parameter has been removed from AIMessage objects. We recommend migrating to use additional_kwargs for passing extra metadata as needed.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Dynamic system prompt",
        "type": "text",
        "content": "For more advanced use cases where you need to modify the system prompt based on runtime context or agent state, you can use middleware .\n\nThe @dynamic_prompt decorator creates middleware that generates system prompts dynamically based on the model request:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Schema validation error",
        "type": "code",
        "content": "================================ Human Message =================================\n\nParse this: Amazing product, 10/10!\n================================== Ai Message ==================================\nTool Calls:\n  ProductRating (call_1)\n Call ID: call_1\n  Args:\n    rating: 10\n    comment: Amazing product\n================================= Tool Message =================================\nName: ProductRating\n\nError: Failed to parse structured output for tool 'ProductRating': 1 validation error for ProductRating.rating\n  Input should be less than or equal to 5 [type=less_than_equal, input_value=10, input_type=int].\n Please fix your mistakes.\n================================== Ai Message ==================================\nTool Calls:\n  ProductRating (call_2)\n Call ID: call_2\n  Args:\n    rating: 5\n    comment: Amazing product\n================================= Tool Message =================================\nName: ProductRating\n\nReturning structured response: {'rating': 5, 'comment': 'Amazing product'}\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Do not return complex values ininterruptcalls",
        "type": "code",
        "content": "def node_a(state: State):\n    # ✅ Good: passing simple types that are serializable\n    name = interrupt(\"What's your name?\")\n    count = interrupt(42)\n    approved = interrupt(True)\n\n    return {\"name\": name, \"count\": count, \"approved\": approved}\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Popular providers",
        "type": "code",
        "content": "langchain-google-community",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/overview",
        "head_menu_name": "Integrations",
        "side_menu_name": "Overview"
    },
    {
        "title": "Hugging Face Hub Tools",
        "type": "text",
        "content": "Hugging Face Tools support text I/O and are loaded using the load_huggingface_tool function.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Pause usinginterrupt",
        "type": "text",
        "content": "The interrupt function pauses graph execution and returns a value to the caller. When you call interrupt within a node, LangGraph saves the current graph state and waits for you to resume execution with input.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Quick start",
        "type": "text",
        "content": "The fastest way to get started is using the hosted version:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/ui",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Agent Chat UI"
    },
    {
        "title": "Rules of interrupts",
        "type": "text",
        "content": "When you call interrupt within a node, LangGraph suspends execution by raising an exception that signals the runtime to pause. This exception propagates up through the call stack and is caught by the runtime, which notifies the graph to save the current state and wait for external input.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Tool calling strategy",
        "type": "code",
        "content": "from pydantic import BaseModel, Field\nfrom typing import Literal\nfrom langchain.agents import create_agent\nfrom langchain.agents.structured_output import ToolStrategy\n\n\nclass ProductReview(BaseModel):\n    \"\"\"Analysis of a product review.\"\"\"\n    rating: int | None = Field(description=\"The rating of the product\", ge=1, le=5)\n    sentiment: Literal[\"positive\", \"negative\"] = Field(description=\"The sentiment of the review\")\n    key_points: list[str] = Field(description=\"The key points of the review. Lowercase, 1-3 words each.\")\n\nagent = create_agent(\n    model=\"gpt-5\",\n    tools=tools,\n    response_format=ToolStrategy(ProductReview)\n)\n\nresult = agent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"Analyze this review: 'Great product: 5 out of 5 stars. Fast shipping, but expensive'\"}]\n})\nresult[\"structured_response\"]\n# ProductReview(rating=5, sentiment='positive', key_points=['fast shipping', 'expensive'])\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "OpenAIModerationChain",
        "type": "text",
        "content": "Detect text that could be hateful, violent, etc.\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/openai",
        "head_menu_name": "Integrations",
        "side_menu_name": "OpenAI"
    },
    {
        "title": "New features",
        "type": "text",
        "content": "We aim to keep the bar high for new features. We generally don’t accept new core abstractions, changes to infra, changes to dependencies, or new agents/chains from outside contributors without an existing issue that demonstrates an acute need for them.\n\nIn general, feature contribution requirements include:\n\nOpen an issue describing:\n\nWe will reject features that are likely to lead to security vulnerabilities or reports.",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Installation",
        "type": "code",
        "content": "toolbox --tools-file \"tools.yaml\"\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Google Search",
        "type": "code",
        "content": "from langchain_community.agent_toolkits.load_tools import load_tools\ntools = load_tools([\"google-search\"])\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Agents must use correct paths",
        "type": "text",
        "content": "The agent must learn to use the /memories/ prefix for persistence. The system prompt teaches this, but the agent must follow the instructions.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Stream multiple modes",
        "type": "text",
        "content": "The streamed outputs will be tuples of (mode, chunk) where mode is the name of the stream mode and chunk is the data streamed by that mode.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Use anonymizers to prevent logging of sensitive data in traces",
        "type": "code",
        "content": "from langchain_core.tracers.langchain import LangChainTracer\nfrom langgraph.graph import StateGraph, MessagesState\nfrom langsmith import Client\nfrom langsmith.anonymizer import create_anonymizer\n\nanonymizer = create_anonymizer([\n    # Matches SSNs\n    { \"pattern\": r\"\\b\\d{3}-?\\d{2}-?\\d{4}\\b\", \"replace\": \"<ssn>\" }\n])\n\ntracer_client = Client(anonymizer=anonymizer)\ntracer = LangChainTracer(client=tracer_client)\n# Define the graph\ngraph = (\n    StateGraph(MessagesState)\n    ...\n    .compile()\n    .with_config({'callbacks': [tracer]})\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/observability",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Observability"
    },
    {
        "title": "LLM-as-Judge Evaluator",
        "type": "text",
        "content": "If you have a reference trajectory, you can add an extra variable to your prompt and pass in the reference trajectory. Below, we use the prebuilt TRAJECTORY_ACCURACY_PROMPT_WITH_REFERENCE prompt and configure the reference_outputs variable:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Agents",
        "type": "text",
        "content": "Agents combine language models with tools to create systems that can reason about tasks, decide which tools to use, and iteratively work towards solutions.\n\ncreate_agent provides a production-ready agent implementation.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "After agent guardrails",
        "type": "code",
        "content": "from langchain.agents.middleware import AgentMiddleware, AgentState, hook_config\nfrom langgraph.runtime import Runtime\nfrom langchain_core.messages import AIMessage\nfrom langchain.chat_models import init_chat_model\nfrom typing import Any\n\nclass SafetyGuardrailMiddleware(AgentMiddleware):\n    \"\"\"Model-based guardrail: Use an LLM to evaluate response safety.\"\"\"\n\n    def __init__(self):\n        super().__init__()\n        self.safety_model = init_chat_model(\"gpt-4o-mini\")\n\n    @hook_config(can_jump_to=[\"end\"])\n    def after_agent(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n        # Get the final AI response\n        if not state[\"messages\"]:\n            return None\n\n        last_message = state[\"messages\"][-1]\n        if not isinstance(last_message, AIMessage):\n            return None\n\n        # Use a model to evaluate safety\n        safety_prompt = f\"\"\"Evaluate if this response is safe and appropriate.\n        Respond with only 'SAFE' or 'UNSAFE'.\n\n        Response: {last_message.content}\"\"\"\n\n        result = self.safety_model.invoke([{\"role\": \"user\", \"content\": safety_prompt}])\n\n        if \"UNSAFE\" in result.content:\n            return {\n                \"messages\": [{\n                    \"role\": \"assistant\",\n                    \"content\": \"I cannot provide that response. Please rephrase your request.\"\n                }],\n                \"jump_to\": \"end\"\n            }\n\n        return None\n\n# Use the safety guardrail\nfrom langchain.agents import create_agent\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[search_tool, calculator_tool],\n    middleware=[SafetyGuardrailMiddleware()],\n)\n\nresult = agent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"How do I make explosives?\"}]\n})\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/guardrails",
        "head_menu_name": "LangChain",
        "side_menu_name": "Guardrails"
    },
    {
        "title": "Amazon Kendra",
        "type": "code",
        "content": "pip install langchain-aws\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "All retrievers",
        "type": "text",
        "content": "Note: The descriptions in the table below are truncated for readability.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/retrievers",
        "head_menu_name": "Integrations",
        "side_menu_name": "Retrievers"
    },
    {
        "title": "Base URL or proxy",
        "type": "text",
        "content": "When using direct chat model class instantiation, the parameter name may vary by provider. Check the respective reference for details.\n\nFor deployments requiring HTTP proxies, some model integrations support proxy configuration:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Configurable models",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Embedding Models",
        "type": "code",
        "content": "GoogleGenerativeAIEmbeddings",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "LLM tool selector",
        "type": "text",
        "content": "Model for tool selection. Can be a model string or BaseChatModel instance. Defaults to the agent’s main model.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "System prompt",
        "type": "text",
        "content": "When no system_prompt is provided, the agent will infer its task from the messages directly.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Amazon API Gateway",
        "type": "text",
        "content": "API Gateway handles all the tasks involved in accepting and processing up to hundreds of thousands of\nconcurrent API calls, including traffic management, CORS support, authorization and access control,\nthrottling, monitoring, and API version management. API Gateway has no minimum fees or startup costs.\nYou pay for the API calls you receive and the amount of data transferred out and, with the API Gateway tiered pricing model, you can reduce your cost as your API usage scales.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Azure AI Services individual tools",
        "type": "text",
        "content": "The azure_ai_services toolkit includes the following tools:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Length-based",
        "type": "code",
        "content": "from langchain_text_splitters import CharacterTextSplitter\n\ntext_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n    encoding_name=\"cl100k_base\", chunk_size=100, chunk_overlap=0\n)\ntexts = text_splitter.split_text(document)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/splitters",
        "head_menu_name": "Integrations",
        "side_menu_name": "Text splitters"
    },
    {
        "title": "Caching",
        "type": "text",
        "content": "Embeddings can be stored or temporarily cached to avoid needing to recompute them.\n\nCaching embeddings can be done using a CacheBackedEmbeddings . This wrapper stores embeddings in a key-value store, where the text is hashed and the hash is used as the key in the cache.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/text_embedding",
        "head_menu_name": "Integrations",
        "side_menu_name": "Embedding models"
    },
    {
        "title": "Break into discrete steps",
        "type": "text",
        "content": "Each node does one thing well. This decomposition enables streaming progress updates, durable execution that can pause and resume, and clear debugging since you can inspect state between steps.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "4. Resume execution from the checkpoint",
        "type": "code",
        "content": "{'topic': 'chickens',\n 'joke': 'Why did the chicken join a band?\\n\\nBecause it had excellent drumsticks!'}\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-time-travel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Time travel"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "import getpass\nimport os\n\nif not os.environ.get(\"AZURE_OPENAI_API_KEY\"):\n  os.environ[\"AZURE_OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for Azure: \")\n\nfrom langchain_openai import AzureOpenAIEmbeddings\n\nembeddings = AzureOpenAIEmbeddings(\n    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Quick fix: submit a bugfix",
        "type": "code",
        "content": "# Inside your repo, install dependencies\nuv sync --all-groups\n",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Cloud Storage",
        "type": "code",
        "content": "pip install langchain-google-community[gcs]\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Execution order",
        "type": "code",
        "content": "middleware3.wrap_model_call()",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Validating human input",
        "type": "text",
        "content": "Each time you resume the graph with invalid input, it will ask again with a clearer message. Once valid input is provided, the node completes and the graph continues.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Decision types",
        "type": "text",
        "content": "The allowed_decisions list controls what actions a human can take when reviewing a tool call:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/human-in-the-loop",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Microsoft OneNote",
        "type": "code",
        "content": "pip install bs4 msal\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "AzureCosmosDBMongoVCoreVectorStore",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Conceptual guides",
        "type": "text",
        "content": "Conceptual guide cover core concepts abstractly, providing deep understanding.",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "Install LangChain",
        "type": "text",
        "content": "See the Integrations tab for a full list of available integrations.\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/install",
        "head_menu_name": "LangChain",
        "side_menu_name": "Install"
    },
    {
        "title": "Human-in-the-loop",
        "type": "text",
        "content": "LangChain provides built-in middleware for requiring human approval before executing sensitive operations. This is one of the most effective guardrails for high-stakes decisions.\n\nHuman-in-the-loop middleware is helpful for cases such as financial transactions and transfers, deleting or modifying production data, sending communications to external parties, and any operation with significant business impact.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/guardrails",
        "head_menu_name": "LangChain",
        "side_menu_name": "Guardrails"
    },
    {
        "title": "Configurable models",
        "type": "code",
        "content": "model_with_tools.invoke(\n    \"what's bigger in 2024 LA or NYC\",\n    config={\"configurable\": {\"model\": \"claude-sonnet-4-5-20250929\"}},\n).tool_calls\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Using in LangGraph",
        "type": "code",
        "content": "memories[-1].dict()\n{'value': {'food_preference': 'I like pizza'},\n 'key': '07e0caf4-1631-47b7-b15f-65515d4c1843',\n 'namespace': ['1', 'memories'],\n 'created_at': '2024-10-02T17:22:31.590602+00:00',\n 'updated_at': '2024-10-02T17:22:31.590605+00:00'}\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "LangChain",
        "type": "text",
        "content": "LangChain agent implementations make it easy to get started for most use cases.",
        "side_link": "https://docs.langchain.com/oss/python/learn",
        "head_menu_name": "Learn",
        "side_menu_name": "Learn"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "pip install -qU langchain-ollama\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Planning and task decomposition",
        "type": "text",
        "content": "Deep agents include a built-in write_todos tool that enables agents to break down complex tasks into discrete steps, track progress, and adapt plans as new information emerges.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/overview",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Overview"
    },
    {
        "title": "Google Search",
        "type": "code",
        "content": "pip install langchain-google-community\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Configuration file",
        "type": "text",
        "content": "See the LangGraph configuration file reference for details on all supported keys in the JSON file.\n\nThe LangGraph CLI defaults to using the configuration file langgraph.json in the current directory.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/application-structure",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Application structure"
    },
    {
        "title": "Do not wrapinterruptcalls in try/except",
        "type": "code",
        "content": "def node_a(state: State):\n    # ✅ Good: interrupting first, then handling\n    # error conditions separately\n    interrupt(\"What's your name?\")\n    try:\n        fetch_data()  # This can fail\n    except Exception as e:\n        print(e)\n    return state\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Usage",
        "type": "text",
        "content": "To add short-term memory (thread-level persistence) to an agent, you need to specify a checkpointer when creating an agent.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "pip install -qU langchain-azure-ai azure-cosmos\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Invoke",
        "type": "code",
        "content": "response = model.invoke(\"Why do parrots have colorful feathers?\")\nprint(response)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Get state history",
        "type": "code",
        "content": "graph.get_state_history(config)",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Content block reference",
        "type": "code",
        "content": "\"server_tool_call_chunk\"",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Installation",
        "type": "code",
        "content": "pip install toolbox-langchain\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Graph API",
        "type": "text",
        "content": "Explore LangGraph’s declarative graph-building API.",
        "side_link": "https://docs.langchain.com/oss/python/learn",
        "head_menu_name": "Learn",
        "side_menu_name": "Learn"
    },
    {
        "title": "Model call limit",
        "type": "text",
        "content": "Maximum model calls across all runs in a thread. Defaults to no limit.\n\nMaximum model calls per single invocation. Defaults to no limit.\n\nBehavior when limit is reached. Options: \"end\" (graceful termination) or \"error\" (raise exception)",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Durable execution",
        "type": "text",
        "content": "Durable execution is a technique in which a process or workflow saves its progress at key points, allowing it to pause and later resume exactly where it left off. This is particularly useful in scenarios that require human-in-the-loop , where users can inspect, validate, or modify the process before continuing, and in long-running tasks that might encounter interruptions or errors (e.g., calls to an LLM timing out). By preserving completed work, durable execution enables a process to resume without reprocessing previous steps — even after a significant delay (e.g., a week later).\n\nLangGraph’s built-in persistence layer provides durable execution for workflows, ensuring that the state of each execution step is saved to a durable store. This capability guarantees that if a workflow is interrupted — whether by a system failure or for human-in-the-loop interactions — it can be resumed from its last recorded state.\n\nIf you are using LangGraph with a checkpointer, you already have durable execution enabled. You can pause and resume workflows at any point, even after interruptions or failures.\nTo make the most of durable execution, ensure that your workflow is designed to be deterministic and idempotent and wrap any side effects or non-deterministic operations inside tasks . You can use tasks from both the StateGraph (Graph API) and the Functional API .",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/durable-execution",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Durable execution"
    },
    {
        "title": "Isolate storage by assistant ID",
        "type": "text",
        "content": "For multi-tenant applications, provide an assistant_id to isolate storage:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Enable tracing",
        "type": "text",
        "content": "By default, the trace will be logged to the project with the name default . To configure a custom project name, see Log to a project .",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/observability",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Observability"
    },
    {
        "title": "Azure AI Services individual tools",
        "type": "code",
        "content": "AzureCogsTextAnalyticsHealthTool",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "What you can control",
        "type": "text",
        "content": "To build reliable agents, you need to control what happens at each step of the agent loop, as well as what happens between steps.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Semantic Search",
        "type": "text",
        "content": "Build a semantic search engine over a PDF with LangChain components.",
        "side_link": "https://docs.langchain.com/oss/python/learn",
        "head_menu_name": "Learn",
        "side_menu_name": "Learn"
    },
    {
        "title": "Step 3: Create a search tool",
        "type": "code",
        "content": "import os\nfrom typing import Literal\nfrom tavily import TavilyClient\nfrom deepagents import create_deep_agent\n\ntavily_client = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n\ndef internet_search(\n    query: str,\n    max_results: int = 5,\n    topic: Literal[\"general\", \"news\", \"finance\"] = \"general\",\n    include_raw_content: bool = False,\n):\n    \"\"\"Run a web search\"\"\"\n    return tavily_client.search(\n        query,\n        max_results=max_results,\n        include_raw_content=include_raw_content,\n        topic=topic,\n    )\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/quickstart",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Amazon Athena",
        "type": "text",
        "content": "Amazon Athena is a serverless, interactive analytics service built\non open-source frameworks, supporting open-table and file formats.\n\nSee a usage example .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Google Translate",
        "type": "code",
        "content": "from langchain_google_community import GoogleTranslateTransformer\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "How-to guides",
        "type": "text",
        "content": "Task-oriented instructions for users who know what they want to accomplish",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "Defining state via middleware",
        "type": "text",
        "content": "See the middleware documentation for more details on defining custom state via middleware.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Serialization withpickle",
        "type": "text",
        "content": "The default serializer, JsonPlusSerializer , uses ormsgpack and JSON under the hood, which is not suitable for all types of objects.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Resuming interrupts",
        "type": "code",
        "content": "from langgraph.types import Command\n\n# Initial run - hits the interrupt and pauses\n# thread_id is the persistent pointer (stores a stable ID in production)\nconfig = {\"configurable\": {\"thread_id\": \"thread-1\"}}\nresult = graph.invoke({\"input\": \"data\"}, config=config)\n\n# Check what was interrupted\n# __interrupt__ contains the payload that was passed to interrupt()\nprint(result[\"__interrupt__\"])\n# > [Interrupt(value='Do you approve this action?')]\n\n# Resume with the human's response\n# The resume payload becomes the return value of interrupt() inside the node\ngraph.invoke(Command(resume=True), config=config)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Protocol reference",
        "type": "code",
        "content": "WriteResult(error, path, files_update)",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Don't Store",
        "type": "text",
        "content": "Can you derive it from other data? If yes, compute it when needed instead of storing it in state.\n\nFor our email agent, we need to track:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Semantic Search",
        "type": "text",
        "content": "Beyond simple retrieval, the store also supports semantic search, allowing you to find memories based on meaning rather than exact matches. To enable this, configure the store with an embedding model:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Replay",
        "type": "text",
        "content": "You must pass these when invoking the graph as part of the configurable portion of the config:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Add persistence",
        "type": "text",
        "content": "If you want the subgraph to have its own memory , you can compile it with the appropriate checkpointer option. This is useful in multi-agent systems, if you want agents to keep track of their internal message histories:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-subgraphs",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Subgraphs"
    },
    {
        "title": "BigQuery Vector Search",
        "type": "code",
        "content": "# Note: BigQueryVectorSearch might be in langchain or langchain_community depending on version\n# Check imports in the usage example.\nfrom langchain.vectorstores import BigQueryVectorSearch # Or langchain_community.vectorstores\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Amazon OpenSearch Service",
        "type": "text",
        "content": "Amazon OpenSearch Service performs\ninteractive log analytics, real-time application monitoring, website search, and more. OpenSearch is\nan open source,\ndistributed search and analytics suite derived from Elasticsearch . Amazon OpenSearch Service offers the\nlatest versions of OpenSearch , support for many versions of Elasticsearch , as well as\nvisualization capabilities powered by OpenSearch Dashboards and Kibana .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Summary of changes",
        "type": "text",
        "content": "LangGraph v1 is largely backwards compatible with previous versions. The main change is the deprecation of create_react_agent in favor of LangChain’s new create_agent function.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langgraph-v1",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Bigtable",
        "type": "text",
        "content": "Google Cloud Bigtable is a fully managed NoSQL Big Data database service.\n\nInstall the python package:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Agent jumps",
        "type": "code",
        "content": "class EarlyExitMiddleware(AgentMiddleware):\n    def before_model(self, state: AgentState, runtime) -> dict[str, Any] | None:\n        # Check some condition\n        if should_exit(state):\n            return {\n                \"messages\": [AIMessage(\"Exiting early due to condition.\")],\n                \"jump_to\": \"end\"\n            }\n        return None\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Vertex AI image generator",
        "type": "code",
        "content": "langchain-google-vertexai",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Trajectory Match Evaluator",
        "type": "text",
        "content": "You can also set the tool_args_match_mode property and/or tool_args_match_overrides to customize how the evaluator considers equality between tool calls in the actual trajectory vs. the reference. By default, only tool calls with the same arguments to the same tool are considered equal. Visit the repository for more details.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Serper.dev",
        "type": "text",
        "content": "Google Serper provides API access to Google search results. Requires langchain-community .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Selecting formats",
        "type": "text",
        "content": "Dynamic response format selection adapts schemas based on user preferences, conversation stage, or role—returning simple formats early and detailed formats as complexity increases.\n\nConfigure structured output based on conversation state:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Tool calling",
        "type": "code",
        "content": "# Bind (potentially multiple) tools to the model\nmodel_with_tools = model.bind_tools([get_weather])\n\n# Step 1: Model generates tool calls\nmessages = [{\"role\": \"user\", \"content\": \"What's the weather in Boston?\"}]\nai_msg = model_with_tools.invoke(messages)\nmessages.append(ai_msg)\n\n# Step 2: Execute tools and collect results\nfor tool_call in ai_msg.tool_calls:\n    # Execute the tool with the generated arguments\n    tool_result = get_weather.invoke(tool_call)\n    messages.append(tool_result)\n\n# Step 3: Pass results back to model for final response\nfinal_response = model_with_tools.invoke(messages)\nprint(final_response.text)\n# \"The current weather in Boston is 72°F and sunny.\"\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "HuggingFaceEmbeddings",
        "type": "code",
        "content": "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Overview",
        "type": "text",
        "content": "In LangGraph, Pregel combines actors and channels into a single application. Actors read data from channels and write data to channels. Pregel organizes the execution of the application into multiple steps, following the Pregel Algorithm / Bulk Synchronous Parallel model.\n\nEach step consists of three phases:\n\nRepeat until no actors are selected for execution, or a maximum number of steps is reached.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/pregel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Runtime"
    },
    {
        "title": "LLM tokens",
        "type": "code",
        "content": "stream_mode=\"messages\"",
        "side_link": "https://docs.langchain.com/oss/python/langchain/streaming",
        "head_menu_name": "LangChain",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Similarity search",
        "type": "code",
        "content": "similar_docs = vector_store.similarity_search(\"your query here\")\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Dynamic model",
        "type": "text",
        "content": "Pre-bound models (models with bind_tools already called) are not supported when using structured output. If you need dynamic model selection with structured output, ensure the models passed to the middleware are not pre-bound.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "from langchain_milvus import Milvus\n\nURI = \"./milvus_example.db\"\n\nvector_store = Milvus(\n    embedding_function=embeddings,\n    connection_args={\"uri\": URI},\n    index_params={\"index_type\": \"FLAT\", \"metric_type\": \"L2\"},\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Google Jobs",
        "type": "code",
        "content": "google-search-results",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Write long-term memory from tools",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/long-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Other Google Products",
        "type": "text",
        "content": "Integrations with various Google services beyond the core Cloud Platform.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Integration Testing",
        "type": "text",
        "content": "AgentEvals lets you easily evaluate the trajectory of your agent (the exact sequence of messages, including tool calls) by performing a trajectory match or by using an LLM judge :",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "LLM tool selector",
        "type": "text",
        "content": "Use an LLM to intelligently select relevant tools before calling the main model.\n\nPerfect for:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Vertex AI Vector Search",
        "type": "text",
        "content": "Google Cloud Vertex AI Vector Search from Google Cloud,\nformerly known as Vertex AI Matching Engine , provides the industry’s leading high-scale\nlow latency vector database. These vector databases are commonly\nreferred to as vector similarity-matching or an approximate nearest neighbor (ANN) service.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Quick fix: submit a bugfix",
        "type": "code",
        "content": "git clone https://github.com/your-username/name-of-forked-repo.git\n\n# For instance, for LangChain:\ngit clone https://github.com/parrot123/langchain.git\n\n# For LangGraph:\ngit clone https://github.com/parrot123/langgraph.git\n",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "AWS Lambda",
        "type": "code",
        "content": "from langchain_community.chat_message_histories import DynamoDBChatMessageHistory\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "View subgraph state",
        "type": "code",
        "content": "graph.get_state(config, subgraphs=True)",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-subgraphs",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Subgraphs"
    },
    {
        "title": "Setup",
        "type": "text",
        "content": "Set up LangSmith for LangGraph development Sign up for LangSmith to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph — read more about how to get started here .",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-subgraphs",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Subgraphs"
    },
    {
        "title": "AWS S3 Directory and File",
        "type": "text",
        "content": "Amazon Simple Storage Service (Amazon S3) is an object storage service. AWS S3 Directory AWS S3 Buckets\n\nSee a usage example for S3DirectoryLoader .\n\nSee a usage example for S3FileLoader .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Microsoft Presidio",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Install LangGraph",
        "type": "text",
        "content": "To use LangGraph you will usually want to access LLMs and define tools.\nYou can do this however you see fit.\n\nOne way to do this (which we will use in the docs) is to use LangChain .\n\nInstall LangChain with:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/install",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Install"
    },
    {
        "title": "LLM tokens",
        "type": "code",
        "content": "node: model\ncontent: [{'type': 'tool_call_chunk', 'id': 'call_vbCyBcP8VuneUzyYlSBZZsVa', 'name': 'get_weather', 'args': '', 'index': 0}]\n\n\nnode: model\ncontent: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': '{\"', 'index': 0}]\n\n\nnode: model\ncontent: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': 'city', 'index': 0}]\n\n\nnode: model\ncontent: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': '\":\"', 'index': 0}]\n\n\nnode: model\ncontent: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': 'San', 'index': 0}]\n\n\nnode: model\ncontent: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': ' Francisco', 'index': 0}]\n\n\nnode: model\ncontent: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': '\"}', 'index': 0}]\n\n\nnode: model\ncontent: []\n\n\nnode: tools\ncontent: [{'type': 'text', 'text': \"It's always sunny in San Francisco!\"}]\n\n\nnode: model\ncontent: []\n\n\nnode: model\ncontent: [{'type': 'text', 'text': 'Here'}]\n\n\nnode: model\ncontent: [{'type': 'text', 'text': ''s'}]\n\n\nnode: model\ncontent: [{'type': 'text', 'text': ' what'}]\n\n\nnode: model\ncontent: [{'type': 'text', 'text': ' I'}]\n\n\nnode: model\ncontent: [{'type': 'text', 'text': ' got'}]\n\n\nnode: model\ncontent: [{'type': 'text', 'text': ':'}]\n\n\nnode: model\ncontent: [{'type': 'text', 'text': ' \"'}]\n\n\nnode: model\ncontent: [{'type': 'text', 'text': \"It's\"}]\n\n\nnode: model\ncontent: [{'type': 'text', 'text': ' always'}]\n\n\nnode: model\ncontent: [{'type': 'text', 'text': ' sunny'}]\n\n\nnode: model\ncontent: [{'type': 'text', 'text': ' in'}]\n\n\nnode: model\ncontent: [{'type': 'text', 'text': ' San'}]\n\n\nnode: model\ncontent: [{'type': 'text', 'text': ' Francisco'}]\n\n\nnode: model\ncontent: [{'type': 'text', 'text': '!\"\\n\\n'}]\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/streaming",
        "head_menu_name": "LangChain",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Add metadata to traces",
        "type": "text",
        "content": "You can annotate your traces with custom metadata and tags:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/observability",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Observability"
    },
    {
        "title": "Azure Blob Storage",
        "type": "code",
        "content": "from langchain_azure_storage.document_loaders import AzureBlobStorageLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "BigQuery",
        "type": "code",
        "content": "pip install langchain-google-community[bigquery]\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Core benefits",
        "type": "text",
        "content": "LangGraph provides low-level supporting infrastructure for any long-running, stateful workflow or agent. LangGraph does not abstract prompts or architecture, and provides the following central benefits:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/overview",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Overview"
    },
    {
        "title": "Anthropic prompt caching",
        "type": "text",
        "content": "Reduce costs by caching repetitive prompt prefixes with Anthropic models.\n\nPerfect for:\n\nLearn more about Anthropic Prompt Caching strategies and limitations.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Build a real-world agent",
        "type": "text",
        "content": "Tools let a model interact with external systems by calling functions you define.\nTools can depend on runtime context and also interact with agent memory .\n\nNotice below how the get_user_location tool uses runtime context:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/quickstart",
        "head_menu_name": "LangChain",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Minor changes",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Invocation config",
        "type": "code",
        "content": "response = model.invoke(\n    \"Tell me a joke\",\n    config={\n        \"run_name\": \"joke_generation\",      # Custom name for this run\n        \"tags\": [\"humor\", \"demo\"],          # Tags for categorization\n        \"metadata\": {\"user_id\": \"123\"},     # Custom metadata\n        \"callbacks\": [my_callback_handler], # Callback handlers\n    }\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Use in production",
        "type": "code",
        "content": "pip install -U langgraph langgraph-checkpoint-redis\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Setup",
        "type": "text",
        "content": "To build a workflow or agent, you can use any chat model that supports structured outputs and tool calling. The following example uses Anthropic:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/workflows-agents",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Workflows + agents"
    },
    {
        "title": "Deprecation ofcreate_react_agent",
        "type": "text",
        "content": "The LangGraph create_react_agent prebuilt has been deprecated in favor of LangChain’s create_agent . It provides a simpler interface, and offers greater customization potential through the introduction of middleware.",
        "side_link": "https://docs.langchain.com/oss/python/releases/langgraph-v1",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Tools",
        "type": "text",
        "content": "Just like tool-calling agents, a deep agent gets a set of top level tools that it has access to.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/customization",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Customization"
    },
    {
        "title": "Decision types",
        "type": "text",
        "content": "Use approve to approve the tool call as-is and execute it without changes.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/human-in-the-loop",
        "head_menu_name": "LangChain",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "HuggingFaceInstructEmbeddings",
        "type": "code",
        "content": "HuggingFaceInstructEmbeddings",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Stream subgraph outputs",
        "type": "text",
        "content": "To include outputs from subgraphs in the streamed outputs, you can set the subgraphs option in the stream method of the parent graph. This will stream outputs from both the parent graph and any subgraphs.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-subgraphs",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Subgraphs"
    },
    {
        "title": "7. Test the API",
        "type": "code",
        "content": "pip install langgraph-sdk\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/local-server",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Local server"
    },
    {
        "title": "Subagent spawning",
        "type": "text",
        "content": "A built-in task tool enables agents to spawn specialized subagents for context isolation. This keeps the main agent’s context clean while still going deep on specific subtasks.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/overview",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Overview"
    },
    {
        "title": "Spanner",
        "type": "code",
        "content": "pip install langchain-google-spanner\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Cloud SQL for MySQL",
        "type": "text",
        "content": "Vector store using Cloud SQL for MySQL .\n\nInstall the python package:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Custom middleware",
        "type": "text",
        "content": "For more information, see the complete middleware guide .",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "4. Create a LangGraph config file",
        "type": "text",
        "content": "See the LangGraph configuration file reference for detailed explanations of each key in the JSON object of the configuration file.\n\nSo far, our project structure looks like this:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/studio",
        "head_menu_name": "LangChain",
        "side_menu_name": "Studio"
    },
    {
        "title": "Durability modes",
        "type": "text",
        "content": "LangGraph supports three durability modes that allow you to balance performance and data consistency based on your application’s requirements. The durability modes, from least to most durable, are as follows:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/durable-execution",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Durable execution"
    },
    {
        "title": "Overview",
        "type": "text",
        "content": "This guide shows a typical structure of an application and shows how the required information to deploy an application using the LangSmith is specified.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/application-structure",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Application structure"
    },
    {
        "title": "Static prompt rename",
        "type": "code",
        "content": "from langchain.agents import create_agent\n\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    tools=[check_weather],\n    system_prompt=\"You are a helpful assistant\"\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "pip install -qU langchain-nomic\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Stream multiple modes",
        "type": "text",
        "content": "You can pass a list as the stream_mode parameter to stream multiple modes at once.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Using with subgraphs called as functions",
        "type": "text",
        "content": "When invoking a subgraph within a node, the parent graph will resume execution from the beginning of the node where the subgraph was invoked and the interrupt was triggered. Similarly, the subgraph will also resume from the beginning of the node where interrupt was called.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "AI Message",
        "type": "text",
        "content": "AIMessage objects are returned by the model when calling it, which contains all of the associated metadata in the response.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Firestore (Native Mode)",
        "type": "text",
        "content": "Vector store using Firestore .\n\nInstall the python package:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "LLM tool emulator",
        "type": "text",
        "content": "Emulate tool execution using an LLM for testing purposes, replacing actual tool calls with AI-generated responses.\n\nPerfect for:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Agent progress",
        "type": "code",
        "content": "step: model\ncontent: [{'type': 'tool_call', 'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': 'call_OW2NYNsNSKhRZpjW0wm2Aszd'}]\n\nstep: tools\ncontent: [{'type': 'text', 'text': \"It's always sunny in San Francisco!\"}]\n\nstep: model\ncontent: [{'type': 'text', 'text': 'It's always sunny in San Francisco!'}]\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/streaming",
        "head_menu_name": "LangChain",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Azure Cosmos DB NoSQL",
        "type": "text",
        "content": "Azure Cosmos DB offers a solution for modern apps and intelligent workloads by being very responsive with dynamic and elastic autoscale. It is available\nin every Azure region and can automatically replicate data closer to users. It has SLA guaranteed low-latency and high availability.\n\nSign Up for free to get started today.\n\nSee a usage example .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Graph structure emerges naturally",
        "type": "text",
        "content": "You define the essential connections, and your nodes handle their own routing logic. This keeps control flow explicit and traceable - you can always understand what your agent will do next by looking at the current node.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Custom updates",
        "type": "code",
        "content": "Looking up data for city: San Francisco\nAcquired data for city: San Francisco\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/streaming",
        "head_menu_name": "LangChain",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "from langchain_azure_ai.vectorstores.azure_cosmos_db_mongo_vcore import (\n    AzureCosmosDBMongoVCoreVectorSearch,\n)\n\nvectorstore = AzureCosmosDBMongoVCoreVectorSearch.from_documents(\n    docs,\n    openai_embeddings,\n    collection=collection,\n    index_name=INDEX_NAME,\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Partial execution",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/test",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Test"
    },
    {
        "title": "Step 1: Install dependencies",
        "type": "code",
        "content": "pip install deepagents tavily-python\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/quickstart",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Observability",
        "type": "text",
        "content": "Observability is crucial for understanding how your agents behave in production. With LangChain’s create_agent , you get built-in observability through LangSmith - a powerful platform for tracing, debugging, evaluating, and monitoring your LLM applications.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/observability",
        "head_menu_name": "LangChain",
        "side_menu_name": "Observability"
    },
    {
        "title": "Log probabilities",
        "type": "text",
        "content": "Certain models can be configured to return token-level log probabilities representing the likelihood of a given token by setting the logprobs parameter when initializing the model:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Tool calling",
        "type": "text",
        "content": "Models can request to call tools that perform tasks such as fetching data from a database, searching the web, or running code. Tools are pairings of:\n\nYou may hear the term “function calling”. We use this interchangeably with “tool calling”.\n\nTo make tools that you have defined available for use by a model, you must bind them using bind_tools() . In subsequent invocations, the model can choose to call any of the bound tools as needed.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Chat Completions API",
        "type": "code",
        "content": "model = ChatDeepSeek(\n    model=\"...\",\n    api_key=\"...\",\n    api_base=\"https://openrouter.ai/api/v1\",\n    extra_body={\"reasoning\": {\"enabled\": True}},\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/chat",
        "head_menu_name": "Integrations",
        "side_menu_name": "Chat models"
    },
    {
        "title": "Trim messages",
        "type": "text",
        "content": "To trim message history, use the trim_messages function:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "LLM tool emulator",
        "type": "text",
        "content": "List of tool names (str) or BaseTool instances to emulate. If None (default), ALL tools will be emulated. If empty list, no tools will be emulated.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Cloud SQL for MySQL",
        "type": "code",
        "content": "from langchain_google_cloud_sql_mysql import MySQLVectorStore # MySQLEngine also available\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Prompt caching",
        "type": "text",
        "content": "Prompt caching is often only engaged above a minimum input token threshold. See provider pages for details.\n\nCache usage will be reflected in the usage metadata of the model response.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "values",
        "type": "text",
        "content": "These are the values that will be used to update the state. Note that this update is treated exactly as any update from a node is treated. This means that these values will be passed to the reducer functions, if they are defined for some of the channels in the graph state. This means that update_state does NOT automatically overwrite the channel values for every channel, but only for the channels without reducers. Let’s walk through an example.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Gemma local from Kaggle",
        "type": "code",
        "content": "langchain-google-vertexai",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Azure Cosmos DB for MongoDB (vCore)",
        "type": "code",
        "content": "from langchain_community.vectorstores import AzureCosmosDBVectorSearch\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Featured providers",
        "type": "code",
        "content": "langchain-google-vertexai",
        "side_link": "https://docs.langchain.com/oss/python/integrations/chat",
        "head_menu_name": "Integrations",
        "side_menu_name": "Chat models"
    },
    {
        "title": "Deprecations",
        "type": "code",
        "content": "langchain.agents.AgentState",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langgraph-v1",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Basic Usage",
        "type": "text",
        "content": "Each memory type is a Python class ( Item ) with certain attributes. We can access it as a dictionary by converting via .dict as above.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "ChatHuggingFace",
        "type": "code",
        "content": "from langchain_huggingface import ChatHuggingFace\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Amazon MemoryDB",
        "type": "code",
        "content": "from langchain_aws.vectorstores.inmemorydb import InMemoryVectorStore\n\nvds = InMemoryVectorStore.from_documents(\n            chunks,\n            embeddings,\n            redis_url=\"rediss://cluster_endpoint:6379/ssl=True ssl_cert_reqs=none\",\n            vector_schema=vector_schema,\n            index_name=INDEX_NAME,\n        )\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Embedding models",
        "type": "text",
        "content": "An embedding model turns text into a vector of numbers so that texts with similar meaning land close together in that vector space.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/retrieval",
        "head_menu_name": "LangChain",
        "side_menu_name": "Retrieval"
    },
    {
        "title": "Dynamic runtime context",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import dynamic_prompt, ModelRequest\nfrom langchain.agents import AgentState\n\n\nclass CustomState(AgentState):  \n    user_name: str\n\n@dynamic_prompt\ndef personalized_prompt(request: ModelRequest) -> str:  \n    user_name = request.state.get(\"user_name\", \"User\")\n    return f\"You are a helpful assistant. User's name is {user_name}\"\n\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    tools=[...],\n    state_schema=CustomState,  \n    middleware=[personalized_prompt],  \n)\n\nagent.invoke({\n    \"messages\": \"hi!\",\n    \"user_name\": \"John Smith\"\n})\n",
        "side_link": "https://docs.langchain.com/oss/python/concepts/context",
        "head_menu_name": "Learn",
        "side_menu_name": "Context"
    },
    {
        "title": "Read standardized content",
        "type": "code",
        "content": "from langchain.chat_models import init_chat_model\n\nmodel = init_chat_model(\"gpt-5-nano\")\nresponse = model.invoke(\"Explain AI\")\n\nfor block in response.content_blocks:\n    if block[\"type\"] == \"reasoning\":\n        print(block.get(\"reasoning\"))\n    elif block[\"type\"] == \"text\":\n        print(block.get(\"text\"))\n",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "State is shared memory",
        "type": "text",
        "content": "Store raw data, not formatted text. This lets different nodes use the same information in different ways.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "InMemorySaver Checkpointer",
        "type": "code",
        "content": "from langgraph.checkpoint.memory import InMemorySaver\n\nagent = create_agent(\n    model,\n    tools=[],\n    checkpointer=InMemorySaver()\n)\n\n# First invocation\nagent.invoke(HumanMessage(content=\"I live in Sydney, Australia.\"))\n\n# Second invocation: the first message is persisted (Sydney location), so the model returns GMT+10 time\nagent.invoke(HumanMessage(content=\"What's my local time?\"))\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Document AI",
        "type": "code",
        "content": "pip install langchain-google-community[docai]\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Hugging Face Hub Tools",
        "type": "code",
        "content": "from langchain_community.agent_toolkits.load_tools import load_huggingface_tool\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Invocation",
        "type": "text",
        "content": "You can invoke an agent by passing an update to its State . All agents include a sequence of messages in their state; to invoke the agent, pass a new message:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Custom state schema",
        "type": "code",
        "content": "agent = create_agent(\n    model=\"gpt-4o\",\n    middleware=[CallCounterMiddleware()],\n    tools=[...],\n)\n\n# Invoke with custom state\nresult = agent.invoke({\n    \"messages\": [HumanMessage(\"Hello\")],\n    \"model_call_count\": 0,\n    \"user_id\": \"user-123\",\n})\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Cloud Providers",
        "type": "text",
        "content": "The below document loaders allow you to load documents from your favorite cloud providers.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/document_loaders",
        "head_menu_name": "Integrations",
        "side_menu_name": "Document loaders"
    },
    {
        "title": "Multiple tool calls",
        "type": "text",
        "content": "When the agent calls multiple tools that require approval, all interrupts are batched together in a single interrupt. You must provide decisions for each one in order.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/human-in-the-loop",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Overview",
        "type": "text",
        "content": "LangChain’s create_agent runs on LangGraph’s runtime under the hood.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/runtime",
        "head_menu_name": "LangChain",
        "side_menu_name": "Runtime"
    },
    {
        "title": "Use with any LLM",
        "type": "code",
        "content": "from langgraph.config import get_stream_writer\n\ndef call_arbitrary_model(state):\n    \"\"\"Example node that calls an arbitrary model and streams the output\"\"\"\n    # Get the stream writer to send custom data\n    writer = get_stream_writer()  \n    # Assume you have a streaming client that yields chunks\n    # Generate LLM tokens using your custom streaming client\n    for chunk in your_custom_streaming_client(state[\"topic\"]):\n        # Use the writer to send custom data to the stream\n        writer({\"custom_llm_chunk\": chunk})  \n    return {\"result\": \"completed\"}\n\ngraph = (\n    StateGraph(State)\n    .add_node(call_arbitrary_model)\n    # Add other nodes and edges as needed\n    .compile()\n)\n# Set stream_mode=\"custom\" to receive the custom data in the stream\nfor chunk in graph.stream(\n    {\"topic\": \"cats\"},\n    stream_mode=\"custom\",  \n\n):\n    # The chunk will contain the custom data streamed from the llm\n    print(chunk)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Azure Cosmos DB NoSQL",
        "type": "code",
        "content": "pip install azure-cosmos\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Google Generative AI (Gemini API & AI Studio)",
        "type": "code",
        "content": "pip install -U langchain-google-genai\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Tool use in the ReAct loop",
        "type": "code",
        "content": "================================== Ai Message ==================================\nTool Calls:\n  check_inventory (call_def456)\n Call ID: call_def456\n  Args:\n    product_id: WH-1000XM5\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Tool calling",
        "type": "text",
        "content": "Each ToolMessage returned by the tool includes a tool_call_id that matches the original tool call, helping the model correlate results with requests.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Basic Usage",
        "type": "text",
        "content": "First, let’s showcase this in isolation without using LangGraph.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Agents",
        "type": "text",
        "content": "Agents are typically implemented as an LLM performing actions using tools . They operate in continuous feedback loops, and are used in situations where problems and solutions are unpredictable. Agents have more autonomy than workflows, and can make decisions about the tools they use and how to solve problems. You can still define the available toolset and guidelines for how agents behave.\n\nTo get started with agents, see the quickstart or read more about how they work in LangChain.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/workflows-agents",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Workflows + agents"
    },
    {
        "title": "Amazon MemoryDB",
        "type": "text",
        "content": "Amazon MemoryDB is a durable, in-memory database service that delivers ultra-fast performance. MemoryDB is compatible with Redis OSS, a popular open source data store,\nenabling you to quickly build applications using the same flexible and friendly Redis OSS APIs, and commands that they already use today.\n\nInMemoryVectorStore class provides a vectorstore to connect with Amazon MemoryDB.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Playwright URL Loader",
        "type": "text",
        "content": "Playwright is an open-source automation tool\ndeveloped by Microsoft that allows you to programmatically control and automate\nweb browsers. It is designed for end-to-end testing, scraping, and automating\ntasks across various web browsers such as Chromium , Firefox , and WebKit .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "PII detection",
        "type": "code",
        "content": "apply_to_tool_results",
        "side_link": "https://docs.langchain.com/oss/python/langchain/guardrails",
        "head_menu_name": "LangChain",
        "side_menu_name": "Guardrails"
    },
    {
        "title": "Do not return complex values ininterruptcalls",
        "type": "code",
        "content": "def validate_input(value):\n    return len(value) > 0\n\ndef node_a(state: State):\n    # ❌ Bad: passing a function to interrupt\n    # The function cannot be serialized\n    response = interrupt({\n        \"question\": \"What's your name?\",\n        \"validator\": validate_input  # This will fail\n    })\n    return {\"name\": response}\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Stream Writer",
        "type": "code",
        "content": "from langchain.tools import tool, ToolRuntime\n\n@tool\ndef get_weather(city: str, runtime: ToolRuntime) -> str:\n    \"\"\"Get weather for a given city.\"\"\"\n    writer = runtime.stream_writer\n\n    # Stream custom updates as the tool executes\n    writer(f\"Looking up data for city: {city}\")\n    writer(f\"Acquired data for city: {city}\")\n\n    return f\"It's always sunny in {city}!\"\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "Execution order",
        "type": "code",
        "content": "middleware3.before_agent()",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "AWS",
        "type": "text",
        "content": "Amazon Web Services cloud platform and AI services.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/all_providers",
        "head_menu_name": "Integrations",
        "side_menu_name": "All providers"
    },
    {
        "title": "4. Resume execution from the checkpoint",
        "type": "code",
        "content": "graph.invoke(None, new_config)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-time-travel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Time travel"
    },
    {
        "title": "Content block reference",
        "type": "text",
        "content": "Provider-specific data structure\n\nUsage: For experimental or provider-unique features\n\nAdditional provider-specific content types may be found within the reference documentation of each model provider.\n\nView the canonical type definitions in the API reference .\n\nContent blocks were introduced as a new property on messages in LangChain v1 to standardize content formats across providers while maintaining backward compatibility with existing code. Content blocks are not a replacement for the content property, but rather a new property that can be used to access the content of a message in a standardized format.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Message content",
        "type": "text",
        "content": "Specifying content_blocks when initializing a message will still populate message content , but provides a type-safe interface for doing so.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Dall-E Image Generator",
        "type": "text",
        "content": "Text-to-image generation using OpenAI’s Dall-E models.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/openai",
        "head_menu_name": "Integrations",
        "side_menu_name": "OpenAI"
    },
    {
        "title": "Provider strategy",
        "type": "text",
        "content": "Provider-native structured output provides high reliability and strict validation because the model provider enforces the schema. Use it when available.\n\nIf the provider natively supports structured output for your model choice, it is functionally equivalent to write response_format=ProductReview instead of response_format=ToolStrategy(ProductReview) . In either case, if structured output is not supported, the agent will fall back to a tool calling strategy.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Add short-term memory",
        "type": "code",
        "content": "from langgraph.checkpoint.memory import InMemorySaver  \nfrom langgraph.graph import StateGraph\n\ncheckpointer = InMemorySaver()  \n\nbuilder = StateGraph(...)\ngraph = builder.compile(checkpointer=checkpointer)  \n\ngraph.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"hi! i am Bob\"}]},\n    {\"configurable\": {\"thread_id\": \"1\"}},  \n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Dynamic system prompt",
        "type": "text",
        "content": "For more details on message types and formatting, see Messages . For comprehensive middleware documentation, see Middleware .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Basic Usage",
        "type": "text",
        "content": "Memories are namespaced by a tuple , which in this specific example will be (<user_id>, \"memories\") . The namespace can be any length and represent anything, does not have to be user specific.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Vertex AI image generator",
        "type": "code",
        "content": "from langchain_google_vertexai.vision_models import VertexAIImageGeneratorChat\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Azure AI Search",
        "type": "code",
        "content": "Azure Cognitive Search",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Checkpoints",
        "type": "code",
        "content": "{'foo': '', 'bar': []}",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Stable core APIs",
        "type": "text",
        "content": "Graph primitives (state, nodes, edges) and the execution/runtime model are unchanged, making upgrades straightforward.",
        "side_link": "https://docs.langchain.com/oss/python/releases/langgraph-v1",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "pip install -qU \"langchain[langchain-deepseek]\"\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Read short-term memory in a tool",
        "type": "code",
        "content": "from langchain.agents import create_agent, AgentState\nfrom langchain.tools import tool, ToolRuntime\n\n\nclass CustomState(AgentState):\n    user_id: str\n\n@tool\ndef get_user_info(\n    runtime: ToolRuntime\n) -> str:\n    \"\"\"Look up user info.\"\"\"\n    user_id = runtime.state[\"user_id\"]\n    return \"User is John Smith\" if user_id == \"user_123\" else \"Unknown user\"\n\nagent = create_agent(\n    model=\"gpt-5-nano\",\n    tools=[get_user_info],\n    state_schema=CustomState,\n)\n\nresult = agent.invoke({\n    \"messages\": \"look up user information\",\n    \"user_id\": \"user_123\"\n})\nprint(result[\"messages\"][-1].content)\n# > User is John Smith.\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Checkpoints",
        "type": "code",
        "content": "from langgraph.graph import StateGraph, START, END\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langchain_core.runnables import RunnableConfig\nfrom typing import Annotated\nfrom typing_extensions import TypedDict\nfrom operator import add\n\nclass State(TypedDict):\n    foo: str\n    bar: Annotated[list[str], add]\n\ndef node_a(state: State):\n    return {\"foo\": \"a\", \"bar\": [\"a\"]}\n\ndef node_b(state: State):\n    return {\"foo\": \"b\", \"bar\": [\"b\"]}\n\n\nworkflow = StateGraph(State)\nworkflow.add_node(node_a)\nworkflow.add_node(node_b)\nworkflow.add_edge(START, \"node_a\")\nworkflow.add_edge(\"node_a\", \"node_b\")\nworkflow.add_edge(\"node_b\", END)\n\ncheckpointer = InMemorySaver()\ngraph = workflow.compile(checkpointer=checkpointer)\n\nconfig: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\ngraph.invoke({\"foo\": \"\"}, config)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Legacy code moved tolangchain-classic",
        "type": "text",
        "content": "Existing functionality outside the focus of standard interfaces and agents has been moved to the langchain-classic package. See the Simplified namespace section for details on what’s available in the core langchain package and what moved to langchain-classic .",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Google",
        "type": "text",
        "content": "All LangChain integrations with Google Cloud , Google Gemini and other Google products.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Google Scholar",
        "type": "text",
        "content": "Search academic papers. Requires google-search-results package and SerpApi key.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Azure Cosmos DB for Apache Gremlin",
        "type": "code",
        "content": "pip install gremlinpython\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Prompt chaining",
        "type": "text",
        "content": "Prompt chaining is when each LLM call processes the output of the previous call. It’s often used for performing well-defined tasks that can be broken down into smaller, verifiable steps. Some examples include:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/workflows-agents",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Workflows + agents"
    },
    {
        "title": "Middleware",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Azure OpenAI",
        "type": "code",
        "content": "from langchain_openai import AzureChatOpenAI\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Embedding Models",
        "type": "code",
        "content": "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n\nembeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\nvector = embeddings.embed_query(\"What are embeddings?\")\nprint(vector[:5])\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Multiple structured outputs error",
        "type": "code",
        "content": "from pydantic import BaseModel, Field\nfrom typing import Union\nfrom langchain.agents import create_agent\nfrom langchain.agents.structured_output import ToolStrategy\n\n\nclass ContactInfo(BaseModel):\n    name: str = Field(description=\"Person's name\")\n    email: str = Field(description=\"Email address\")\n\nclass EventDetails(BaseModel):\n    event_name: str = Field(description=\"Name of the event\")\n    date: str = Field(description=\"Event date\")\n\nagent = create_agent(\n    model=\"gpt-5\",\n    tools=[],\n    response_format=ToolStrategy(Union[ContactInfo, EventDetails])  # Default: handle_errors=True\n)\n\nagent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"Extract info: John Doe (john@email.com) is organizing Tech Conference on March 15th\"}]\n})\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Include in State",
        "type": "text",
        "content": "Does it need to persist across steps? If yes, it goes in state.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Custom state schema",
        "type": "text",
        "content": "Middleware can extend the agent’s state with custom properties. Define a custom state type and set it as the state_schema :",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Azure Cosmos DB for MongoDB (vCore)",
        "type": "text",
        "content": "Azure Cosmos DB for MongoDB vCore makes it easy to create a database with full native MongoDB support.\nYou can apply your MongoDB experience and continue to use your favorite MongoDB drivers, SDKs, and tools by pointing your application to the API for MongoDB vCore account’s connection string.\nUse vector search in Azure Cosmos DB for MongoDB vCore to seamlessly integrate your AI-based applications with your data that’s stored in Azure Cosmos DB.\n\nSee detailed configuration instructions .\n\nWe need to install pymongo python package.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Multiple specialized subagents",
        "type": "text",
        "content": "Create specialized subagents for different domains:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Bring-your-own documents",
        "type": "code",
        "content": "ElasticsearchRetriever",
        "side_link": "https://docs.langchain.com/oss/python/integrations/retrievers",
        "head_menu_name": "Integrations",
        "side_menu_name": "Retrievers"
    },
    {
        "title": "Text property",
        "type": "code",
        "content": "# Property access\ntext = response.text\n\n# Deprecated method call\ntext = response.text()\n",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "LangSmith Integration",
        "type": "code",
        "content": "export LANGSMITH_API_KEY=\"your_langsmith_api_key\"\nexport LANGSMITH_TRACING=\"true\"\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Build a basic agent",
        "type": "text",
        "content": "To learn how to trace your agent with LangSmith, see the LangSmith documentation .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/quickstart",
        "head_menu_name": "LangChain",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Tutorial: Retrieval-Augmented Generation (RAG)",
        "type": "text",
        "content": "See how to build a Q&A chatbot that can answer questions grounded in your data using Retrieval-Augmented Generation.\nThis tutorial walks through two approaches:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/retrieval",
        "head_menu_name": "LangChain",
        "side_menu_name": "Retrieval"
    },
    {
        "title": "Dynamic prompts",
        "type": "code",
        "content": "from dataclasses import dataclass\n\nfrom langchain.agents import create_agent\nfrom langchain.agents.middleware import dynamic_prompt, ModelRequest\nfrom langgraph.runtime import Runtime\n\n\n@dataclass\nclass Context:  \n    user_role: str = \"user\"\n\n@dynamic_prompt\ndef dynamic_prompt(request: ModelRequest) -> str:  \n    user_role = request.runtime.context.user_role\n    base_prompt = \"You are a helpful assistant.\"\n\n    if user_role == \"expert\":\n        prompt = (\n            f\"{base_prompt} Provide detailed technical responses.\"\n        )\n    elif user_role == \"beginner\":\n        prompt = (\n            f\"{base_prompt} Explain concepts simply and avoid jargon.\"\n        )\n    else:\n        prompt = base_prompt\n\n    return prompt  \n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=tools,\n    middleware=[dynamic_prompt],  \n    context_schema=Context\n)\n\n# Use with context\nagent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"Explain async programming\"}]},\n    context=Context(user_role=\"expert\")\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Runtime context",
        "type": "code",
        "content": "config[\"configurable\"]",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Overview",
        "type": "text",
        "content": "A vector store stores embedded data and performs similarity search.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "LangGraph runtime",
        "type": "text",
        "content": "This guide explains the runtime at a high level and provides instructions for directly implementing applications with Pregel.\n\nNote: The Pregel runtime is named after Google’s Pregel algorithm , which describes an efficient method for large-scale parallel computation using graphs.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/pregel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Runtime"
    },
    {
        "title": "Tool retry",
        "type": "text",
        "content": "Initial delay in seconds before first retry\n\nMaximum delay in seconds between retries (caps exponential backoff growth)\n\nWhether to add random jitter (±25%) to delay to avoid thundering herd",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Google",
        "type": "code",
        "content": "langchain-google-genai",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Deploy DocumentDB on AWS",
        "type": "text",
        "content": "Amazon DocumentDB (with MongoDB Compatibility) is a fast, reliable, and fully managed database service. Amazon DocumentDB makes it easy to set up, operate, and scale MongoDB-compatible databases in the cloud.\n\nAWS offers services for computing, databases, storage, analytics, and other functionality. For an overview of all AWS services, see Cloud Computing with Amazon Web Services .\n\nSee a usage example .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Human-in-the-Loop",
        "type": "text",
        "content": "The harness pauses agent execution at specified tool calls to allow human approval/modification.\n\nConfiguration:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/harness",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Agent harness"
    },
    {
        "title": "Content block reference",
        "type": "code",
        "content": "{\n    \"type\": \"tool_call\",\n    \"name\": \"search\",\n    \"args\": {\"query\": \"weather\"},\n    \"id\": \"call_123\"\n}\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "ToolRuntime",
        "type": "code",
        "content": "from langgraph.types import Command\nfrom langchain.messages import RemoveMessage\nfrom langgraph.graph.message import REMOVE_ALL_MESSAGES\nfrom langchain.tools import tool, ToolRuntime\n\n# Update the conversation history by removing all messages\n@tool\ndef clear_conversation() -> Command:\n    \"\"\"Clear the conversation history.\"\"\"\n\n    return Command(\n        update={\n            \"messages\": [RemoveMessage(id=REMOVE_ALL_MESSAGES)],\n        }\n    )\n\n# Update the user_name in the agent state\n@tool\ndef update_user_name(\n    new_name: str,\n    runtime: ToolRuntime\n) -> Command:\n    \"\"\"Update the user's name.\"\"\"\n    return Command(update={\"user_name\": new_name})\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "Match decision order to actions",
        "type": "code",
        "content": "if result.get(\"__interrupt__\"):\n    interrupts = result[\"__interrupt__\"][0].value\n    action_requests = interrupts[\"action_requests\"]\n\n    # Create one decision per action, in order\n    decisions = []\n    for action in action_requests:\n        decision = get_user_decision(action)  # Your logic\n        decisions.append(decision)\n\n    result = agent.invoke(\n        Command(resume={\"decisions\": decisions}),\n        config=config\n    )\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/human-in-the-loop",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Stream",
        "type": "text",
        "content": "Most models can stream their output content while it is being generated. By displaying output progressively, streaming significantly improves user experience, particularly for longer responses.\n\nCalling stream() returns an iterator that yields output chunks as they are produced. You can use a loop to process each chunk in real-time:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Human-in-the-loop",
        "type": "text",
        "content": "Mapping of tool names to approval configs. Values can be True (interrupt with default config), False (auto-approve), or an InterruptOnConfig object.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Memorystore for Redis",
        "type": "text",
        "content": "Google Cloud Memorystore for Redis is a fully managed Redis service.\n\nInstall the python package:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Dynamic runtime context",
        "type": "text",
        "content": "Turning on memory Please see the memory guide for more details on how to enable memory. This is a powerful feature that allows you to persist the agent’s state across multiple invocations. Otherwise, the state is scoped only to a single run.",
        "side_link": "https://docs.langchain.com/oss/python/concepts/context",
        "head_menu_name": "Learn",
        "side_menu_name": "Context"
    },
    {
        "title": "Pluggable storage backends",
        "type": "text",
        "content": "The harness abstracts file system operations behind a protocol, allowing different storage strategies for different use cases.\n\nAvailable backends:\n\nStateBackend - Ephemeral in-memory storage\n\nFilesystemBackend - Real filesystem access\n\nStoreBackend - Persistent cross-conversation storage\n\nCompositeBackend - Route different paths to different backends",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/harness",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Agent harness"
    },
    {
        "title": "Text structure-based",
        "type": "text",
        "content": "Text is naturally organized into hierarchical units such as paragraphs, sentences, and words. We can leverage this inherent structure to inform our splitting strategy, creating split that maintain natural language flow, maintain semantic coherence within split, and adapts to varying levels of text granularity. LangChain’s RecursiveCharacterTextSplitter implements this concept:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/splitters",
        "head_menu_name": "Integrations",
        "side_menu_name": "Text splitters"
    },
    {
        "title": "Co-locate Python and JavaScript/TypeScript content",
        "type": "code",
        "content": ":::python\nPython-specific content. In real docs, the preceding backslash (before `python`) is omitted.\n:::\n\n:::js\nJavaScript/TypeScript-specific content. In real docs, the preceding backslash (before `js`) is omitted.\n:::\n\nContent for both languages (not wrapped)\n",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "Stream subgraph outputs",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-subgraphs",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Subgraphs"
    },
    {
        "title": "2. Prepare your agent",
        "type": "code",
        "content": "from langchain.agents import create_agent\n\ndef send_email(to: str, subject: str, body: str):\n    \"\"\"Send an email\"\"\"\n    email = {\n        \"to\": to,\n        \"subject\": subject,\n        \"body\": body\n    }\n    # ... email sending logic\n\n    return f\"Email sent to {to}\"\n\nagent = create_agent(\n    \"gpt-4o\",\n    tools=[send_email],\n    system_prompt=\"You are an email assistant. Always use the send_email tool.\",\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/studio",
        "head_menu_name": "LangChain",
        "side_menu_name": "Studio"
    },
    {
        "title": "Interface",
        "type": "text",
        "content": "LangChain provides a standard interface for text embedding models (e.g., OpenAI, Cohere, Hugging Face) via the Embeddings interface.\n\nTwo main methods are available:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/text_embedding",
        "head_menu_name": "Integrations",
        "side_menu_name": "Embedding models"
    },
    {
        "title": "AlloyDB for PostgreSQL",
        "type": "code",
        "content": "from langchain_google_alloydb_pg import AlloyDBLoader # AlloyDBEngine also available\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "History",
        "type": "text",
        "content": "LangGraph becomes the preferred way to build any AI application that is more than a single LLM call.\n\nAs developers tried to improve the reliability of their applications, they needed more control than the high-level interfaces provided. LangGraph provided that low-level flexibility. Most chains and agents were marked as deprecated in LangChain with guides on how to migrate them to LangGraph. There is still one high-level abstraction created in LangGraph: an agent abstraction. It is built on top of low-level LangGraph and has the same interface as the ReAct agents from LangChain.\n\nModel APIs become more multimodal.\n\nModels started to accept files, images, videos, and more. We updated the langchain-core message format accordingly to allow developers to specify these multimodal inputs in a standard way.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/philosophy",
        "head_menu_name": "LangChain",
        "side_menu_name": "Philosophy"
    },
    {
        "title": "Memory",
        "type": "text",
        "content": "Understand persistence of interactions within and across threads.",
        "side_link": "https://docs.langchain.com/oss/python/learn",
        "head_menu_name": "Learn",
        "side_menu_name": "Learn"
    },
    {
        "title": "Tools and toolkits",
        "type": "text",
        "content": "To see a full list of integrations by component type, refer to the categories in the sidebar.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/overview",
        "head_menu_name": "Integrations",
        "side_menu_name": "Overview"
    },
    {
        "title": "From retrieval to RAG",
        "type": "text",
        "content": "Retrieval allows LLMs to access relevant context at runtime. But most real-world applications go one step further: they integrate retrieval with generation to produce grounded, context-aware answers.\n\nThis is the core idea behind Retrieval-Augmented Generation (RAG) . The retrieval pipeline becomes a foundation for a broader system that combines search with generation.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/retrieval",
        "head_menu_name": "LangChain",
        "side_menu_name": "Retrieval"
    },
    {
        "title": "Quickstart",
        "type": "text",
        "content": "Here are a few pre-built filesystem backends that you can quickly use with your deep agent:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Context",
        "type": "code",
        "content": "from dataclasses import dataclass\nfrom langchain_openai import ChatOpenAI\nfrom langchain.agents import create_agent\nfrom langchain.tools import tool, ToolRuntime\n\n\nUSER_DATABASE = {\n    \"user123\": {\n        \"name\": \"Alice Johnson\",\n        \"account_type\": \"Premium\",\n        \"balance\": 5000,\n        \"email\": \"alice@example.com\"\n    },\n    \"user456\": {\n        \"name\": \"Bob Smith\",\n        \"account_type\": \"Standard\",\n        \"balance\": 1200,\n        \"email\": \"bob@example.com\"\n    }\n}\n\n@dataclass\nclass UserContext:\n    user_id: str\n\n@tool\ndef get_account_info(runtime: ToolRuntime[UserContext]) -> str:\n    \"\"\"Get the current user's account information.\"\"\"\n    user_id = runtime.context.user_id\n\n    if user_id in USER_DATABASE:\n        user = USER_DATABASE[user_id]\n        return f\"Account holder: {user['name']}\\nType: {user['account_type']}\\nBalance: ${user['balance']}\"\n    return \"User not found\"\n\nmodel = ChatOpenAI(model=\"gpt-4o\")\nagent = create_agent(\n    model,\n    tools=[get_account_info],\n    context_schema=UserContext,\n    system_prompt=\"You are a financial assistant.\"\n)\n\nresult = agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my current balance?\"}]},\n    context=UserContext(user_id=\"user123\")\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "Using in LangGraph",
        "type": "code",
        "content": "config: RunnableConfig",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "LangChain v1 migration guide",
        "type": "text",
        "content": "This guide outlines the major changes between LangChain v1 and previous versions.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "pip install -qU langchain-chroma\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "El Carro for Oracle Workloads",
        "type": "text",
        "content": "Google El Carro Oracle Operator runs Oracle databases in Kubernetes.\n\nInstall the python package:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Tool Message",
        "type": "code",
        "content": "# After a model makes a tool call\nai_message = AIMessage(\n    content=[],\n    tool_calls=[{\n        \"name\": \"get_weather\",\n        \"args\": {\"location\": \"San Francisco\"},\n        \"id\": \"call_123\"\n    }]\n)\n\n# Execute tool and create result message\nweather_result = \"Sunny, 72°F\"\ntool_message = ToolMessage(\n    content=weather_result,\n    tool_call_id=\"call_123\"  # Must match the call ID\n)\n\n# Continue conversation\nmessages = [\n    HumanMessage(\"What's the weather in San Francisco?\"),\n    ai_message,  # Model's tool call\n    tool_message,  # Tool execution result\n]\nresponse = model.invoke(messages)  # Model processes the result\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Configuring interrupts",
        "type": "text",
        "content": "You configure it with a mapping of tool actions to the decision types that are allowed for each action. The middleware will interrupt execution when a tool call matches an action in the mapping.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/human-in-the-loop",
        "head_menu_name": "LangChain",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Summarization",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import SummarizationMiddleware\n\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[weather_tool, calculator_tool],\n    middleware=[\n        SummarizationMiddleware(\n            model=\"gpt-4o-mini\",\n            max_tokens_before_summary=4000,  # Trigger summarization at 4000 tokens\n            messages_to_keep=20,  # Keep last 20 messages after summary\n            summary_prompt=\"Custom prompt for summarization...\",  # Optional\n        ),\n    ],\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Azure Cosmos DB NoSQL",
        "type": "text",
        "content": "Azure Cosmos DB for NoSQL now offers vector indexing and search in preview.\nThis feature is designed to handle high-dimensional vectors, enabling efficient and accurate vector search at any scale. You can now store vectors\ndirectly in the documents alongside your data. This means that each document in your database can contain not only traditional schema-free data,\nbut also high-dimensional vectors as other properties of the documents. This colocation of data and vectors allows for efficient indexing and searching,\nas the vectors are stored in the same logical unit as the data they represent. This simplifies data management, AI application architectures, and the\nefficiency of vector-based operations.\n\nSee detail configuration instructions .\n\nWe need to install azure-cosmos python package.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Stream Writer",
        "type": "text",
        "content": "If you use runtime.stream_writer inside your tool, the tool must be invoked within a LangGraph execution context. See Streaming for more details.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "AI Message",
        "type": "code",
        "content": "response = model.invoke(\"Explain AI\")\nprint(type(response))  # <class 'langchain_core.messages.AIMessage'>\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Protocol reference",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Installing AgentEvals",
        "type": "code",
        "content": "pip install agentevals\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Execution order",
        "type": "code",
        "content": "middleware2.after_model()",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Initialization",
        "type": "code",
        "content": "from langchain_core.vectorstores import InMemoryVectorStore\nvector_store = InMemoryVectorStore(embedding=SomeEmbeddingModel())\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Vertex AI Search",
        "type": "code",
        "content": "from langchain_google_community import VertexAISearchSummaryTool\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Bring-your-own documents",
        "type": "code",
        "content": "VertexAISearchRetriever",
        "side_link": "https://docs.langchain.com/oss/python/integrations/retrievers",
        "head_menu_name": "Integrations",
        "side_menu_name": "Retrievers"
    },
    {
        "title": "ChatHuggingFace",
        "type": "text",
        "content": "We can use the Hugging Face LLM classes or directly use the ChatHuggingFace class.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Defining state via middleware",
        "type": "text",
        "content": "Middleware can also define custom state by setting the state_schema attribute.\nThis helps to keep state extensions conceptually scoped to the relevant middleware and tools.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Memory storage",
        "type": "text",
        "content": "This structure enables hierarchical organization of memories. Cross-namespace searching is then supported through content filters.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/long-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Step 5: Wire it together",
        "type": "text",
        "content": "The graph structure is minimal because routing happens inside nodes through Command objects. Each node declares where it can go using type hints like Command[Literal[\"node1\", \"node2\"]] , making the flow explicit and traceable.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Azure AI",
        "type": "code",
        "content": "from langchain_azure_ai.chat_models import AzureAIChatCompletionsModel\n\nllm = AzureAIChatCompletionsModel(\n    model_name=\"gpt-4o\",\n    api_version=\"2024-05-01-preview\",\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Vertex AI",
        "type": "code",
        "content": "langchain-google-vertexai",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Node-style hooks",
        "type": "code",
        "content": "from langchain.agents.middleware import AgentMiddleware, AgentState\nfrom langchain.messages import AIMessage\nfrom langgraph.runtime import Runtime\nfrom typing import Any\n\nclass MessageLimitMiddleware(AgentMiddleware):\n    def __init__(self, max_messages: int = 50):\n        super().__init__()\n        self.max_messages = max_messages\n\n    def before_model(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n        if len(state[\"messages\"]) == self.max_messages:\n            return {\n                \"messages\": [AIMessage(\"Conversation limit reached.\")],\n                \"jump_to\": \"end\"\n            }\n        return None\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Popular providers",
        "type": "code",
        "content": "langchain-elasticsearch",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/overview",
        "head_menu_name": "Integrations",
        "side_menu_name": "Overview"
    },
    {
        "title": "values",
        "type": "code",
        "content": "{\"foo\": 1, \"bar\": [\"a\"]}\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Examples",
        "type": "text",
        "content": "Below are a few different examples to give you a sense of the Pregel API.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/pregel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Runtime"
    },
    {
        "title": "Embedding Models",
        "type": "text",
        "content": "Generate text embeddings using models like gemini-embedding-001 with the GoogleGenerativeAIEmbeddings class.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Azure OpenAI",
        "type": "text",
        "content": "Set the environment variables to get access to the Azure OpenAI service.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Code quality",
        "type": "text",
        "content": "Follow consistent style, documentation, and architecture patterns",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "2. Create a LangGraph app 🌱",
        "type": "code",
        "content": "new-langgraph-project-python",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/local-server",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Local server"
    },
    {
        "title": "Example: Summarization",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import SummarizationMiddleware\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[...],\n    middleware=[\n        SummarizationMiddleware(\n            model=\"gpt-4o-mini\",\n            max_tokens_before_summary=4000,  # Trigger summarization at 4000 tokens\n            messages_to_keep=20,  # Keep last 20 messages after summary\n        ),\n    ],\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Use in subgraphs",
        "type": "text",
        "content": "If your graph contains subgraphs , you only need to provide the checkpointer when compiling the parent graph. LangGraph will automatically propagate the checkpointer to the child subgraphs.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Step 2: Set up your API keys",
        "type": "code",
        "content": "export ANTHROPIC_API_KEY=\"your-api-key\"\nexport TAVILY_API_KEY=\"your-tavily-api-key\"\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/quickstart",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Requirements",
        "type": "text",
        "content": "To leverage durable execution in LangGraph, you need to:\n\nEnable persistence in your workflow by specifying a checkpointer that will save workflow progress.\n\nSpecify a thread identifier when executing a workflow. This will track the execution history for a particular instance of the workflow.\n\nWrap any non-deterministic operations (e.g., random number generation) or operations with side effects (e.g., file writes, API calls) inside @[ task ] to ensure that when a workflow is resumed, these operations are not repeated for the particular run, and instead their results are retrieved from the persistence layer. For more information, see Determinism and Consistent Replay .",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/durable-execution",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Durable execution"
    },
    {
        "title": "Anthropic prompt caching",
        "type": "text",
        "content": "Cache type. Only \"ephemeral\" is currently supported.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "LangGraph ecosystem",
        "type": "text",
        "content": "While LangGraph can be used standalone, it also integrates seamlessly with any LangChain product, giving developers a full suite of tools for building agents. To improve your LLM application development, pair LangGraph with:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/overview",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Overview"
    },
    {
        "title": "Inside middleware",
        "type": "code",
        "content": "from dataclasses import dataclass\n\nfrom langchain.messages import AnyMessage\nfrom langchain.agents import create_agent, AgentState\nfrom langchain.agents.middleware import dynamic_prompt, ModelRequest, before_model, after_model\nfrom langgraph.runtime import Runtime\n\n\n@dataclass\nclass Context:\n    user_name: str\n\n# Dynamic prompts\n@dynamic_prompt\ndef dynamic_system_prompt(request: ModelRequest) -> str:\n    user_name = request.runtime.context.user_name  \n    system_prompt = f\"You are a helpful assistant. Address the user as {user_name}.\"\n    return system_prompt\n\n# Before model hook\n@before_model\ndef log_before_model(state: AgentState, runtime: Runtime[Context]) -> dict | None:  \n    print(f\"Processing request for user: {runtime.context.user_name}\")  \n    return None\n\n# After model hook\n@after_model\ndef log_after_model(state: AgentState, runtime: Runtime[Context]) -> dict | None:  \n    print(f\"Completed request for user: {runtime.context.user_name}\")  \n    return None\n\nagent = create_agent(\n    model=\"gpt-5-nano\",\n    tools=[...],\n    middleware=[dynamic_system_prompt, log_before_model, log_after_model],  \n    context_schema=Context\n)\n\nagent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my name?\"}]},\n    context=Context(user_name=\"John Smith\")\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/runtime",
        "head_menu_name": "LangChain",
        "side_menu_name": "Runtime"
    },
    {
        "title": "RAG Architectures",
        "type": "text",
        "content": "RAG can be implemented in multiple ways, depending on your system’s needs. We outline each type in the sections below.\n\nLatency : Latency is generally more predictable in 2-Step RAG , as the maximum number of LLM calls is known and capped. This predictability assumes that LLM inference time is the dominant factor. However, real-world latency may also be affected by the performance of retrieval steps—such as API response times, network delays, or database queries—which can vary based on the tools and infrastructure in use.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/retrieval",
        "head_menu_name": "LangChain",
        "side_menu_name": "Retrieval"
    },
    {
        "title": "Agent jumps",
        "type": "text",
        "content": "To enable jumping, decorate your hook with @hook_config(can_jump_to=[...]) :",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Development environment",
        "type": "code",
        "content": "cd libs/partners/langchain-{partner}\nuv sync --all-groups\nmake test  # Ensure tests pass before starting development\n",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Trace selectively",
        "type": "text",
        "content": "You may opt to trace specific invocations or parts of your application using LangSmith’s tracing_context context manager:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/observability",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Observability"
    },
    {
        "title": "Mistral on Vertex AI Model Garden",
        "type": "code",
        "content": "from langchain_google_vertexai.model_garden_maas.mistral import VertexModelGardenMistral\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Trajectory Match Evaluator",
        "type": "text",
        "content": "The unordered mode allows the same tool calls in any order, which is helpful when you want to verify that specific information was retrieved but don’t care about the sequence. For example, an agent might need to check both weather and events for a city, but the order doesn’t matter.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Dynamically selecting tools",
        "type": "text",
        "content": "Select relevant tools at runtime to improve performance and accuracy.\n\nBenefits:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "ChatGPTLoader",
        "type": "text",
        "content": "Load conversations.json from your ChatGPT data export folder.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/openai",
        "head_menu_name": "Integrations",
        "side_menu_name": "OpenAI"
    },
    {
        "title": "Tutorial: Build a supervisor agent",
        "type": "text",
        "content": "Learn how to build a personal assistant using the supervisor pattern, where a central supervisor agent coordinates specialized worker agents.\nThis tutorial demonstrates:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/multi-agent",
        "head_menu_name": "LangChain",
        "side_menu_name": "Multi-agent"
    },
    {
        "title": "Semantic Search",
        "type": "code",
        "content": "# Store with specific fields to embed\nstore.put(\n    namespace_for_memory,\n    str(uuid.uuid4()),\n    {\n        \"food_preference\": \"I love Italian cuisine\",\n        \"context\": \"Discussing dinner plans\"\n    },\n    index=[\"food_preference\"]  # Only embed \"food_preferences\" field\n)\n\n# Store without embedding (still retrievable, but not searchable)\nstore.put(\n    namespace_for_memory,\n    str(uuid.uuid4()),\n    {\"system_info\": \"Last updated: 2024-01-01\"},\n    index=False\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Execution order",
        "type": "code",
        "content": "middleware2.before_model()",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Agents",
        "type": "code",
        "content": "from langchain.tools import tool\n\n\n# Define tools\n@tool\ndef multiply(a: int, b: int) -> int:\n    \"\"\"Multiply `a` and `b`.\n\n    Args:\n        a: First int\n        b: Second int\n    \"\"\"\n    return a * b\n\n\n@tool\ndef add(a: int, b: int) -> int:\n    \"\"\"Adds `a` and `b`.\n\n    Args:\n        a: First int\n        b: Second int\n    \"\"\"\n    return a + b\n\n\n@tool\ndef divide(a: int, b: int) -> float:\n    \"\"\"Divide `a` and `b`.\n\n    Args:\n        a: First int\n        b: Second int\n    \"\"\"\n    return a / b\n\n\n# Augment the LLM with tools\ntools = [add, multiply, divide]\ntools_by_name = {tool.name: tool for tool in tools}\nllm_with_tools = llm.bind_tools(tools)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/workflows-agents",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Workflows + agents"
    },
    {
        "title": "Provider strategy",
        "type": "text",
        "content": "Some model providers support structured output natively through their APIs (currently only OpenAI and Grok). This is the most reliable method when available.\n\nTo use this strategy, configure a ProviderStrategy :",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Error handling strategies",
        "type": "text",
        "content": "If handle_errors is a string, the agent will always prompt the model to re-try with a fixed tool message:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Firestore (Datastore Mode)",
        "type": "code",
        "content": "pip install langchain-google-datastore\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Recording & Replaying HTTP Calls",
        "type": "text",
        "content": "The first time you run this test, your agent will make real network calls and pytest will generate a cassette file test_agent_trajectory.yaml in the tests/cassettes directory. Subsequent runs will use that cassette to mock the real network calls, granted the agent’s requests don’t change from the previous run. If they do, the test will fail and you’ll need to delete the cassette and rerun the test to record fresh interactions.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "HuggingFaceEmbeddings",
        "type": "text",
        "content": "We can use the HuggingFaceEmbeddings class to run open source embedding models locally.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Custom middleware",
        "type": "code",
        "content": "from dataclasses import dataclass\nfrom typing import Callable\n\nfrom langchain_openai import ChatOpenAI\n\nfrom langchain.agents.middleware import (\n    AgentMiddleware,\n    ModelRequest\n)\nfrom langchain.agents.middleware.types import ModelResponse\n\n@dataclass\nclass Context:\n    user_expertise: str = \"beginner\"\n\nclass ExpertiseBasedToolMiddleware(AgentMiddleware):\n    def wrap_model_call(\n        self,\n        request: ModelRequest,\n        handler: Callable[[ModelRequest], ModelResponse]\n    ) -> ModelResponse:\n        user_level = request.runtime.context.user_expertise\n\n        if user_level == \"expert\":\n            # More powerful model\n            model = ChatOpenAI(model=\"gpt-5\")\n            tools = [advanced_search, data_analysis]\n        else:\n            # Less powerful model\n            model = ChatOpenAI(model=\"gpt-5-nano\")\n            tools = [simple_search, basic_calculator]\n\n        request.model = model\n        request.tools = tools\n        return handler(request)\n\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    tools=[\n        simple_search,\n        advanced_search,\n        basic_calculator,\n        data_analysis\n    ],\n    middleware=[ExpertiseBasedToolMiddleware()],\n    context_schema=Context\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Google Search",
        "type": "text",
        "content": "Perform web searches using Google Custom Search Engine (CSE). Requires GOOGLE_API_KEY and GOOGLE_CSE_ID .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "pip install -qU langchain-google-genai\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Install LangGraph",
        "type": "code",
        "content": "pip install -U langgraph\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/install",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Install"
    },
    {
        "title": "Install LangChain",
        "type": "code",
        "content": "pip install -U langchain\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/install",
        "head_menu_name": "LangChain",
        "side_menu_name": "Install"
    },
    {
        "title": "values",
        "type": "code",
        "content": "from typing import Annotated\nfrom typing_extensions import TypedDict\nfrom operator import add\n\nclass State(TypedDict):\n    foo: int\n    bar: Annotated[list[str], add]\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Basic usage example",
        "type": "code",
        "content": "{'refineTopic': {'topic': 'ice cream and cats'}}\n{'generateJoke': {'joke': 'This is a joke about ice cream and cats'}}\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Interface",
        "type": "code",
        "content": "yield_keys(prefix: Optional[str] = None) -> Iterator[str]",
        "side_link": "https://docs.langchain.com/oss/python/integrations/stores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Key-value stores"
    },
    {
        "title": "AlloyDB for PostgreSQL",
        "type": "code",
        "content": "pip install langchain-google-alloydb-pg\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "from langchain_postgres import PGVector\n\nvector_store = PGVector(\n    embeddings=embeddings,\n    collection_name=\"my_docs\",\n    connection=\"postgresql+psycopg://...\"\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Stream multiple modes",
        "type": "code",
        "content": "stream_mode=[\"updates\", \"custom\"]",
        "side_link": "https://docs.langchain.com/oss/python/langchain/streaming",
        "head_menu_name": "LangChain",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Azure ML Chat Online Endpoint",
        "type": "text",
        "content": "See the documentation here for accessing chat\nmodels hosted with Azure Machine Learning .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Implementing our email agent nodes",
        "type": "code",
        "content": "def search_documentation(state: EmailAgentState) -> Command[Literal[\"draft_response\"]]:\n    \"\"\"Search knowledge base for relevant information\"\"\"\n\n    # Build search query from classification\n    classification = state.get('classification', {})\n    query = f\"{classification.get('intent', '')} {classification.get('topic', '')}\"\n\n    try:\n        # Implement your search logic here\n        # Store raw search results, not formatted text\n        search_results = [\n            \"Reset password via Settings > Security > Change Password\",\n            \"Password must be at least 12 characters\",\n            \"Include uppercase, lowercase, numbers, and symbols\"\n        ]\n    except SearchAPIError as e:\n        # For recoverable search errors, store error and continue\n        search_results = [f\"Search temporarily unavailable: {str(e)}\"]\n\n    return Command(\n        update={\"search_results\": search_results},  # Store raw results or error\n        goto=\"draft_response\"\n    )\n\ndef bug_tracking(state: EmailAgentState) -> Command[Literal[\"draft_response\"]]:\n    \"\"\"Create or update bug tracking ticket\"\"\"\n\n    # Create ticket in your bug tracking system\n    ticket_id = \"BUG-12345\"  # Would be created via API\n\n    return Command(\n        update={\n            \"search_results\": [f\"Bug ticket {ticket_id} created\"],\n            \"current_step\": \"bug_tracked\"\n        },\n        goto=\"draft_response\"\n    )\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "ZeroxPDFLoader",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/document_loaders",
        "head_menu_name": "Integrations",
        "side_menu_name": "Document loaders"
    },
    {
        "title": "Configuring interrupts",
        "type": "text",
        "content": "When invoking the agent, pass a config that includes the thread ID to associate execution with a conversation thread.\nSee the LangGraph interrupts documentation for details.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/human-in-the-loop",
        "head_menu_name": "LangChain",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Best practices",
        "type": "code",
        "content": "SummarizationMiddleware",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "LLMs and augmentations",
        "type": "text",
        "content": "Workflows and agentic systems are based on LLMs and the various augmentations you add to them. Tool calling , structured outputs , and short term memory are a few options for tailoring LLMs to your needs.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/workflows-agents",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Workflows + agents"
    },
    {
        "title": "Use persistent stores in production",
        "type": "code",
        "content": "# ❌ Development only - data lost on restart\nstore = InMemoryStore()\n\n# ✅ Production - data persists\nfrom langgraph.store.postgres import PostgresStore\nstore = PostgresStore(connection_string=os.environ[\"DATABASE_URL\"])\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Bigtable",
        "type": "code",
        "content": "from langchain_google_bigtable import BigtableLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Write long-term memory from tools",
        "type": "code",
        "content": "from dataclasses import dataclass\nfrom typing_extensions import TypedDict\n\nfrom langchain.agents import create_agent\nfrom langchain.tools import tool, ToolRuntime\nfrom langgraph.store.memory import InMemoryStore\n\n\n# InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production.\nstore = InMemoryStore() \n\n@dataclass\nclass Context:\n    user_id: str\n\n# TypedDict defines the structure of user information for the LLM\nclass UserInfo(TypedDict):\n    name: str\n\n# Tool that allows agent to update user information (useful for chat applications)\n@tool\ndef save_user_info(user_info: UserInfo, runtime: ToolRuntime[Context]) -> str:\n    \"\"\"Save user info.\"\"\"\n    # Access the store - same as that provided to `create_agent`\n    store = runtime.store \n    user_id = runtime.context.user_id \n    # Store data in the store (namespace, key, data)\n    store.put((\"users\",), user_id, user_info) \n    return \"Successfully saved user info.\"\n\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    tools=[save_user_info],\n    store=store, \n    context_schema=Context\n)\n\n# Run the agent\nagent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"My name is John Smith\"}]},\n    # user_id passed in context to identify whose information is being updated\n    context=Context(user_id=\"user_123\") \n)\n\n# You can access the store directly to get the value\nstore.get((\"users\",), \"user_123\").value\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/long-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Basic usage example",
        "type": "code",
        "content": "for chunk in graph.stream(inputs, stream_mode=\"updates\"):\n    print(chunk)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Spanner",
        "type": "text",
        "content": "Google Cloud Spanner is a fully managed, globally distributed relational database service.\n\nInstall the python package:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "LangGraph runtime",
        "type": "text",
        "content": "Pregel implements LangGraph’s runtime, managing the execution of LangGraph applications.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/pregel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Runtime"
    },
    {
        "title": "SerpApi",
        "type": "text",
        "content": "See a usage example and authorization instructions .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Basic Usage",
        "type": "text",
        "content": "We can read out memories in our namespace using the store.search method, which will return all memories for a given user as a list. The most recent memory is the last in the list.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Writes",
        "type": "text",
        "content": "Tool results can be used to help an agent complete a given task. Tools can both return results directly to the model\nand update the memory of the agent to make important context available to future steps.\n\nWrite to State to track session-specific information using Command:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Multiple specialized subagents",
        "type": "text",
        "content": "Workflow:\n\nEach subagent works with clean context focused only on its task.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "HuggingFaceEndpoint",
        "type": "text",
        "content": "We can use the HuggingFaceEndpoint class to run open source models via serverless Inference Providers or via dedicated Inference Endpoints .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Filter by LLM invocation",
        "type": "text",
        "content": "You can associate tags with LLM invocations to filter the streamed tokens by LLM invocation.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Azure SQL Database",
        "type": "text",
        "content": "Sign Up for free to get started today.\n\nSee a usage example .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "LLMs",
        "type": "text",
        "content": "Access the same Gemini models using the (legacy) LLM\ninterface with the GoogleGenerativeAI class.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Cloud Storage",
        "type": "text",
        "content": "Cloud Storage is a managed service for storing unstructured data.\n\nInstall with GCS dependencies:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Bing Search API",
        "type": "code",
        "content": "from langchain_community.utilities import BingSearchAPIWrapper\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Custom updates",
        "type": "text",
        "content": "To stream updates from tools as they are executed, you can use get_stream_writer .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/streaming",
        "head_menu_name": "LangChain",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Anthropic prompt caching",
        "type": "text",
        "content": "Minimum number of messages before caching starts\n\nBehavior when using non-Anthropic models. Options: \"ignore\" , \"warn\" , or \"raise\"",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "External index",
        "type": "text",
        "content": "The below retrievers will search over an external index (e.g., constructed from Internet data or similar).",
        "side_link": "https://docs.langchain.com/oss/python/integrations/retrievers",
        "head_menu_name": "Integrations",
        "side_menu_name": "Retrievers"
    },
    {
        "title": "BigQuery Vector Search",
        "type": "code",
        "content": "pip install google-cloud-bigquery\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Hugging Face model loader",
        "type": "text",
        "content": "This loader interfaces with the Hugging Face Models API to fetch\nand load model metadata and README files.\nThe API allows you to search and filter models based on\nspecific criteria such as model tags, authors, and more.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Read long-term memory in tools",
        "type": "code",
        "content": "from dataclasses import dataclass\n\nfrom langchain_core.runnables import RunnableConfig\nfrom langchain.agents import create_agent\nfrom langchain.tools import tool, ToolRuntime\nfrom langgraph.store.memory import InMemoryStore\n\n\n@dataclass\nclass Context:\n    user_id: str\n\n# InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production.\nstore = InMemoryStore() \n\n# Write sample data to the store using the put method\nstore.put( \n    (\"users\",),  # Namespace to group related data together (users namespace for user data)\n    \"user_123\",  # Key within the namespace (user ID as key)\n    {\n        \"name\": \"John Smith\",\n        \"language\": \"English\",\n    }  # Data to store for the given user\n)\n\n@tool\ndef get_user_info(runtime: ToolRuntime[Context]) -> str:\n    \"\"\"Look up user info.\"\"\"\n    # Access the store - same as that provided to `create_agent`\n    store = runtime.store \n    user_id = runtime.context.user_id\n    # Retrieve data from store - returns StoreValue object with value and metadata\n    user_info = store.get((\"users\",), user_id) \n    return str(user_info.value) if user_info else \"Unknown user\"\n\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    tools=[get_user_info],\n    # Pass store to agent - enables agent to access store when running tools\n    store=store, \n    context_schema=Context\n)\n\n# Run the agent\nagent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"look up user information\"}]},\n    context=Context(user_id=\"user_123\") \n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/long-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Human-in-the-loop",
        "type": "text",
        "content": "Pause agent execution for human approval before sensitive actions",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Specify a backend",
        "type": "code",
        "content": "lambda rt: StateBackend(rt)",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Error handling strategies",
        "type": "code",
        "content": "================================= Tool Message =================================\nName: ToolStrategy\n\nError: <error message>\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Installation",
        "type": "text",
        "content": "To get started, install the Toolbox server and client .\n\nConfigure a tools.yaml to define your tools, and then execute toolbox to start the server:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Document AI Warehouse",
        "type": "code",
        "content": "DocumentAIWarehouseRetriever",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Tool call limit",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import ToolCallLimitMiddleware\n\n\n# Limit all tool calls\nglobal_limiter = ToolCallLimitMiddleware(thread_limit=20, run_limit=10)\n\n# Limit specific tool\nsearch_limiter = ToolCallLimitMiddleware(\n    tool_name=\"search\",\n    thread_limit=5,\n    run_limit=3,\n)\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[...],\n    middleware=[global_limiter, search_limiter],\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Add metadata to traces",
        "type": "code",
        "content": "with ls.tracing_context(\n    project_name=\"email-agent-test\",\n    enabled=True,\n    tags=[\"production\", \"email-assistant\", \"v1.0\"],\n    metadata={\"user_id\": \"user_123\", \"session_id\": \"session_456\", \"environment\": \"production\"}):\n    response = agent.invoke(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"Send a welcome email\"}]}\n    )\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/observability",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Observability"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "pip install -qU langchain-mongodb\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Caching",
        "type": "text",
        "content": "The main supported way to initialize a CacheBackedEmbeddings is from_bytes_store . It takes the following parameters:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/text_embedding",
        "head_menu_name": "Integrations",
        "side_menu_name": "Embedding models"
    },
    {
        "title": "Vertex AI Search",
        "type": "code",
        "content": "from langchain_google_community import VertexAIMultiTurnSearchRetriever\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "1. Create a repository on GitHub",
        "type": "text",
        "content": "Your application’s code must reside in a GitHub repository to be deployed on LangSmith. Both public and private repositories are supported. For this quickstart, first make sure your app is LangGraph-compatible by following the local server setup guide . Then, push your code to the repository.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/deploy",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Deploy"
    },
    {
        "title": "Stream graph state",
        "type": "code",
        "content": "for chunk in graph.stream(\n    {\"topic\": \"ice cream\"},\n    stream_mode=\"updates\",  \n):\n    print(chunk)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Google Lens",
        "type": "code",
        "content": "from langchain_community.tools.google_lens import GoogleLensQueryRun\nfrom langchain_community.utilities.google_lens import GoogleLensAPIWrapper\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Use descriptive paths",
        "type": "text",
        "content": "Organize long-term files with clear, hierarchical paths:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Gmail",
        "type": "text",
        "content": "Google Gmail is a free email service provided by Google.\nThis toolkit works with emails through the Gmail API .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Security focused",
        "type": "text",
        "content": "Prioritize secure coding practices and vulnerability prevention",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Standard content blocks",
        "type": "text",
        "content": "A new content_blocks property that provides unified access to modern LLM features across providers.",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Schema validation error",
        "type": "text",
        "content": "When structured output doesn’t match the expected schema, the agent provides specific error feedback:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Reasoning",
        "type": "text",
        "content": "Newer models are capable of performing multi-step reasoning to arrive at a conclusion. This involves breaking down complex problems into smaller, more manageable steps.\n\nIf supported by the underlying model, you can surface this reasoning process to better understand how the model arrived at its final answer.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Summarize messages",
        "type": "text",
        "content": "See SummarizationMiddleware for more configuration options.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "PDFs",
        "type": "text",
        "content": "The below document loaders allow you to load PDF documents.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/document_loaders",
        "head_menu_name": "Integrations",
        "side_menu_name": "Document loaders"
    },
    {
        "title": "Text-to-Speech",
        "type": "code",
        "content": "pip install google-cloud-text-to-speech langchain-google-community\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "LLM-as-judge",
        "type": "text",
        "content": "Use a LLM to qualitatively validate your agent’s execution trajectory. The “judge” LLM reviews the agent’s decisions against a prompt rubric (which can include a reference trajectory).\n\nMore flexible and can assess nuanced aspects like efficiency and appropriateness, but requires an LLM call and is less deterministic. Use when you want to evaluate the overall quality and reasonableness of the agent’s trajectory without strict tool call or ordering requirements.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Dependencies",
        "type": "text",
        "content": "A dependencies key in the LangGraph configuration file that specifies the dependencies required to run the LangGraph application.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/application-structure",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Application structure"
    },
    {
        "title": "Conceptual Overviews",
        "type": "text",
        "content": "These guides explain the core concepts and APIs underlying LangChain and LangGraph.",
        "side_link": "https://docs.langchain.com/oss/python/learn",
        "head_menu_name": "Learn",
        "side_menu_name": "Learn"
    },
    {
        "title": "System Message",
        "type": "text",
        "content": "A SystemMessage represent an initial set of instructions that primes the model’s behavior. You can use a system message to set the tone, define the model’s role, and establish guidelines for responses.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "import getpass\nimport os\n\nif not os.environ.get(\"GOOGLE_API_KEY\"):\n  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n\nfrom langchain_google_genai import GoogleGenerativeAIEmbeddings\n\nembeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Code examples",
        "type": "code",
        "content": "def filter_unknown_users(users: list[str], known_users: set[str]) -> list[str]:\n    \"\"\"Filter out users that are not in the known users set.\n\n    Args:\n        users: List of user identifiers to filter.\n        known_users: Set of known/valid user identifiers.\n\n    Returns:\n        List of users that are not in the known_users set.\n\n    Raises:\n        ValueError: If users list contains invalid identifiers.\n    \"\"\"\n    return [user for user in users if user not in known_users]\n",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "Stream",
        "type": "code",
        "content": "full = None  # None | AIMessageChunk\nfor chunk in model.stream(\"What color is the sky?\"):\n    full = chunk if full is None else full + chunk\n    print(full.text)\n\n# The\n# The sky\n# The sky is\n# The sky is typically\n# The sky is typically blue\n# ...\n\nprint(full.content_blocks)\n# [{\"type\": \"text\", \"text\": \"The sky is typically blue...\"}]\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Adding documents",
        "type": "text",
        "content": "Add Document objects (holding page_content and optional metadata) like so:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Where to customize",
        "type": "code",
        "content": "\"subagent1_description\"",
        "side_link": "https://docs.langchain.com/oss/python/langchain/multi-agent",
        "head_menu_name": "LangChain",
        "side_menu_name": "Multi-agent"
    },
    {
        "title": "Rate limiting",
        "type": "text",
        "content": "Many chat model providers impose a limit on the number of invocations that can be made in a given time period. If you hit a rate limit, you will typically receive a rate limit error response from the provider, and will need to wait before making more requests.\n\nTo help manage rate limits, chat model integrations accept a rate_limiter parameter that can be provided during initialization to control the rate at which requests are made.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Provider strategy",
        "type": "text",
        "content": "The schema defining the structured output format. Supports:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Cloud Storage",
        "type": "code",
        "content": "from langchain_google_community import GCSFileLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Interface",
        "type": "text",
        "content": "Base stores are designed to work multiple key-value pairs at once for efficiency. This saves on network round-trips and may allow for more efficient batch operations in the underlying store.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/stores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Key-value stores"
    },
    {
        "title": "Step 5: Wire it together",
        "type": "text",
        "content": "Now we connect our nodes into a working graph. Since our nodes handle their own routing decisions, we only need a few essential edges.\n\nTo enable human-in-the-loop with interrupt() , we need to compile with a checkpointer to save state between runs:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Simplified package",
        "type": "text",
        "content": "The langchain package namespace has been significantly reduced in v1 to focus on essential building blocks for agents. The streamlined package makes it easier to discover and use the core functionality.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Stream subgraph outputs",
        "type": "code",
        "content": "((), {'node_1': {'foo': 'hi! foo'}})\n(('node_2:dfddc4ba-c3c5-6887-5012-a243b5b377c2',), {'subgraph_node_1': {'bar': 'bar'}})\n(('node_2:dfddc4ba-c3c5-6887-5012-a243b5b377c2',), {'subgraph_node_2': {'foo': 'hi! foobar'}})\n((), {'node_2': {'foo': 'hi! foobar'}})\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "HuggingFaceInferenceAPIEmbeddings",
        "type": "code",
        "content": "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Azure AI",
        "type": "code",
        "content": "pip install -U langchain-azure-ai\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Checkpoints",
        "type": "code",
        "content": "{'foo': 'b', 'bar': ['a', 'b']}",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "6. Test your application in Studio",
        "type": "code",
        "content": ">    - LangGraph Studio Web UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/local-server",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Local server"
    },
    {
        "title": "1. Run the graph",
        "type": "code",
        "content": "How about \"The Secret Life of Socks in the Dryer\"? You know, exploring the mysterious phenomenon of how socks go into the laundry as pairs but come out as singles. Where do they go? Are they starting new lives elsewhere? Is there a sock paradise we don't know about? There's a lot of comedic potential in the everyday mystery that unites us all!\n\n# The Secret Life of Socks in the Dryer\n\nI finally discovered where all my missing socks go after the dryer. Turns out they're not missing at all—they've just eloped with someone else's socks from the laundromat to start new lives together.\n\nMy blue argyle is now living in Bermuda with a red polka dot, posting vacation photos on Sockstagram and sending me lint as alimony.\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-time-travel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Time travel"
    },
    {
        "title": "Procedural memory",
        "type": "code",
        "content": "# Node that *uses* the instructions\ndef call_model(state: State, store: BaseStore):\n    namespace = (\"agent_instructions\", )\n    instructions = store.get(namespace, key=\"agent_a\")[0]\n    # Application logic\n    prompt = prompt_template.format(instructions=instructions.value[\"instructions\"])\n    ...\n\n# Node that updates instructions\ndef update_instructions(state: State, store: BaseStore):\n    namespace = (\"instructions\",)\n    instructions = store.search(namespace)[0]\n    # Memory logic\n    prompt = prompt_template.format(instructions=instructions.value[\"instructions\"], conversation=state[\"messages\"])\n    output = llm.invoke(prompt)\n    new_instructions = output['new_instructions']\n    store.put((\"agent_instructions\",), \"agent_a\", {\"instructions\": new_instructions})\n    ...\n",
        "side_link": "https://docs.langchain.com/oss/python/concepts/memory",
        "head_menu_name": "Learn",
        "side_menu_name": "Memory"
    },
    {
        "title": "Azure Container Apps dynamic sessions",
        "type": "text",
        "content": "We need to get the POOL_MANAGEMENT_ENDPOINT environment variable from the Azure Container Apps service.\nSee the instructions here .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Use in production",
        "type": "text",
        "content": "You need to call store.setup() the first time you’re using Redis store",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Build a real-world agent",
        "type": "text",
        "content": "In production, use a persistent checkpointer that saves to a database.\nSee Add and manage memory for more details.\n\nNow assemble your agent with all the components and run it!",
        "side_link": "https://docs.langchain.com/oss/python/langchain/quickstart",
        "head_menu_name": "LangChain",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Standard content blocks",
        "type": "text",
        "content": "LangChain provides a standard representation for message content that works across providers.\n\nMessage objects implement a content_blocks property that will lazily parse the content attribute into a standard, type-safe representation. For example, messages generated from ChatAnthropic or ChatOpenAI will include thinking or reasoning blocks in the format of the respective provider, but can be lazily parsed into a consistent ReasoningContentBlock representation:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Agent jumps",
        "type": "text",
        "content": "Important: When jumping from before_model or after_model , jumping to \"model\" will cause all before_model middleware to run again.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Use in production",
        "type": "text",
        "content": "Setup To use the MongoDB checkpointer, you will need a MongoDB cluster. Follow this guide to create a cluster if you don’t already have one.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Azure AI Data",
        "type": "code",
        "content": "Azure Data Lake gen 2",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Default message format for OpenAI Responses API",
        "type": "text",
        "content": "When interacting with the Responses API, langchain-openai now defaults to storing response items in message content . To restore previous behavior, set the LC_OUTPUT_VERSION environment variable to v0 , or specify output_version=\"v0\" when instantiating ChatOpenAI .",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Quick start",
        "type": "text",
        "content": "No extra code is needed to log a trace to LangSmith. Just run your agent code as you normally would:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/observability",
        "head_menu_name": "LangChain",
        "side_menu_name": "Observability"
    },
    {
        "title": "Data sources",
        "type": "text",
        "content": "Throughout this process, your agent accesses (reads / writes) different sources of data:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Graphs",
        "type": "text",
        "content": "You can specify one or more graphs in the configuration file. Each graph is identified by a name (which should be unique) and a path for either: (1) the compiled graph or (2) a function that makes a graph is defined.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/application-structure",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Application structure"
    },
    {
        "title": "Context",
        "type": "text",
        "content": "Access immutable configuration and contextual data like user IDs, session details, or application-specific configuration through runtime.context .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "Interrupt decision types",
        "type": "text",
        "content": "The available decision types for each tool depend on the policy you configure in interrupt_on .\nWhen multiple tool calls are paused at the same time, each action requires a separate decision.\nDecisions must be provided in the same order as the actions appear in the interrupt request.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/human-in-the-loop",
        "head_menu_name": "LangChain",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Model fallback",
        "type": "text",
        "content": "Automatically fallback to alternative models when the primary model fails.\n\nPerfect for:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "5. Launch LangGraph server 🚀",
        "type": "text",
        "content": "The langgraph dev command starts LangGraph Server in an in-memory mode. This mode is suitable for development and testing purposes. For production use, deploy LangGraph Server with access to a persistent storage backend. For more information, see the Platform setup overview .",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/local-server",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Local server"
    },
    {
        "title": "High-level API",
        "type": "code",
        "content": "{'topic': <langgraph.channels.last_value.LastValue at 0x7d05e3294d80>,\n 'content': <langgraph.channels.last_value.LastValue at 0x7d05e3295040>,\n 'score': <langgraph.channels.last_value.LastValue at 0x7d05e3295980>,\n '__start__': <langgraph.channels.ephemeral_value.EphemeralValue at 0x7d05e3297e00>,\n 'write_essay': <langgraph.channels.ephemeral_value.EphemeralValue at 0x7d05e32960c0>,\n 'score_essay': <langgraph.channels.ephemeral_value.EphemeralValue at 0x7d05e2d8ab80>,\n 'branch:__start__:__self__:write_essay': <langgraph.channels.ephemeral_value.EphemeralValue at 0x7d05e32941c0>,\n 'branch:__start__:__self__:score_essay': <langgraph.channels.ephemeral_value.EphemeralValue at 0x7d05e2d88800>,\n 'branch:write_essay:__self__:write_essay': <langgraph.channels.ephemeral_value.EphemeralValue at 0x7d05e3295ec0>,\n 'branch:write_essay:__self__:score_essay': <langgraph.channels.ephemeral_value.EphemeralValue at 0x7d05e2d8ac00>,\n 'branch:score_essay:__self__:write_essay': <langgraph.channels.ephemeral_value.EphemeralValue at 0x7d05e2d89700>,\n 'branch:score_essay:__self__:score_essay': <langgraph.channels.ephemeral_value.EphemeralValue at 0x7d05e2d8b400>,\n 'start:write_essay': <langgraph.channels.ephemeral_value.EphemeralValue at 0x7d05e2d8b280>}\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/pregel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Runtime"
    },
    {
        "title": "Google Translate",
        "type": "text",
        "content": "First, we need to install the langchain-google-community with translate dependencies.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Execution order",
        "type": "text",
        "content": "When using multiple middleware, understanding execution order is important:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Install",
        "type": "code",
        "content": "langchain-mcp-adapters",
        "side_link": "https://docs.langchain.com/oss/python/langchain/mcp",
        "head_menu_name": "LangChain",
        "side_menu_name": "Model Context Protocol (MCP)"
    },
    {
        "title": "Azure AI Services individual tools",
        "type": "code",
        "content": "AzureCogsFormRecognizerTool",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "El Carro for Oracle Workloads",
        "type": "code",
        "content": "pip install langchain-google-el-carro\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Subagent middleware",
        "type": "text",
        "content": "In addition to any user-defined subagents, the main agent has access to a general-purpose subagent at all times. This subagent has the same instructions as the main agent and all the tools it has access to. The primary purpose of the general-purpose subagent is context isolation—the main agent can delegate a complex task to this subagent and get a concise answer back without bloat from intermediate tool calls.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/middleware",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Keep system prompts detailed",
        "type": "text",
        "content": "Include specific guidance on how to use tools and format outputs:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "from langchain_pinecone import PineconeVectorStore\nfrom pinecone import Pinecone\n\npc = Pinecone(api_key=...)\nindex = pc.Index(index_name)\n\nvector_store = PineconeVectorStore(embedding=embeddings, index=index)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Local development",
        "type": "text",
        "content": "For customization or local development, you can run Agent Chat UI locally:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/ui",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Agent Chat UI"
    },
    {
        "title": "Basic configuration",
        "type": "text",
        "content": "The interrupt_on parameter accepts a dictionary mapping tool names to interrupt configurations. Each tool can be configured with:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/human-in-the-loop",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Delete messages",
        "type": "code",
        "content": "from langchain.messages import RemoveMessage\nfrom langchain.agents import create_agent, AgentState\nfrom langchain.agents.middleware import after_model\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.runtime import Runtime\nfrom langchain_core.runnables import RunnableConfig\n\n\n@after_model\ndef delete_old_messages(state: AgentState, runtime: Runtime) -> dict | None:\n    \"\"\"Remove old messages to keep conversation manageable.\"\"\"\n    messages = state[\"messages\"]\n    if len(messages) > 2:\n        # remove the earliest two messages\n        return {\"messages\": [RemoveMessage(id=m.id) for m in messages[:2]]}\n    return None\n\n\nagent = create_agent(\n    \"gpt-5-nano\",\n    tools=[],\n    system_prompt=\"Please be concise and to the point.\",\n    middleware=[delete_old_messages],\n    checkpointer=InMemorySaver(),\n)\n\nconfig: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n\nfor event in agent.stream(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"hi! I'm bob\"}]},\n    config,\n    stream_mode=\"values\",\n):\n    print([(message.type, message.content) for message in event[\"messages\"]])\n\nfor event in agent.stream(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what's my name?\"}]},\n    config,\n    stream_mode=\"values\",\n):\n    print([(message.type, message.content) for message in event[\"messages\"]])\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Supported models",
        "type": "text",
        "content": "LangChain supports all major model providers, including OpenAI, Anthropic, Google, Azure, AWS Bedrock, and more. Each provider offers a variety of models with different capabilities. For a full list of supported models in LangChain, see the integrations page .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Evaluators",
        "type": "text",
        "content": "Evaluate model outputs using Vertex AI.\n\nRequires langchain-google-vertexai .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "6. View your agent in Studio",
        "type": "text",
        "content": "Your agent will be accessible via API ( http://127.0.0.1:2024 ) and the Studio UI https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024 :",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/studio",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Studio"
    },
    {
        "title": "The /memories/ path convention",
        "type": "code",
        "content": "# Transient file (lost after thread ends)\nagent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"Write draft to /draft.txt\"}]\n})\n\n# Persistent file (survives across threads)\nagent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"Save final report to /memories/report.txt\"}]\n})\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Testing individual nodes and edges",
        "type": "text",
        "content": "Compiled LangGraph agents expose references to each individual node as graph.nodes . You can take advantage of this to test individual nodes within your agent. Note that this will bypass any checkpointers passed when compiling the graph:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/test",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Test"
    },
    {
        "title": "Google Drive",
        "type": "code",
        "content": "from langchain_googledrive.utilities.google_drive import GoogleDriveAPIWrapper\nfrom langchain_googledrive.tools.google_drive.tool import GoogleDriveSearchTool\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Batch",
        "type": "code",
        "content": "responses = model.batch([\n    \"Why do parrots have colorful feathers?\",\n    \"How do airplanes fly?\",\n    \"What is quantum computing?\"\n])\nfor response in responses:\n    print(response)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Wrap-style hooks",
        "type": "text",
        "content": "Intercept execution and control when the handler is called:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "\"exit\"",
        "type": "text",
        "content": "Changes are persisted only when graph execution completes (either successfully or with an error). This provides the best performance for long-running graphs but means intermediate state is not saved, so you cannot recover from mid-execution failures or interrupt the graph execution.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/durable-execution",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Durable execution"
    },
    {
        "title": "Configuration",
        "type": "text",
        "content": "subagents should be a list of dictionaries or CompiledSubAgent objects. There are two types:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Bedrock Chat",
        "type": "code",
        "content": "from langchain_aws import ChatBedrock\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Encryption",
        "type": "code",
        "content": "import sqlite3\n\nfrom langgraph.checkpoint.serde.encrypted import EncryptedSerializer\nfrom langgraph.checkpoint.sqlite import SqliteSaver\n\nserde = EncryptedSerializer.from_pycryptodome_aes()  # reads LANGGRAPH_AES_KEY\ncheckpointer = SqliteSaver(sqlite3.connect(\"checkpoint.db\"), serde=serde)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "AlloyDB for PostgreSQL",
        "type": "code",
        "content": "from langchain_google_alloydb_pg import AlloyDBVectorStore # AlloyDBEngine also available\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Standard content blocks",
        "type": "code",
        "content": "ReasoningContentBlock",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Best practices",
        "type": "code",
        "content": "LLMToolSelectorMiddleware",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Setup",
        "type": "code",
        "content": "import os\nimport getpass\n\nfrom langchain_anthropic import ChatAnthropic\n\ndef _set_env(var: str):\n    if not os.environ.get(var):\n        os.environ[var] = getpass.getpass(f\"{var}: \")\n\n\n_set_env(\"ANTHROPIC_API_KEY\")\n\nllm = ChatAnthropic(model=\"claude-sonnet-4-5-20250929\")\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/workflows-agents",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Workflows + agents"
    },
    {
        "title": "Structured outputs",
        "type": "code",
        "content": "from pydantic import BaseModel, Field\n\nclass Actor(BaseModel):\n    name: str\n    role: str\n\nclass MovieDetails(BaseModel):\n    title: str\n    year: int\n    cast: list[Actor]\n    genres: list[str]\n    budget: float | None = Field(None, description=\"Budget in millions USD\")\n\nmodel_with_structure = model.with_structured_output(MovieDetails)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Basic usage example",
        "type": "code",
        "content": "from typing import TypedDict\nfrom langgraph.graph import StateGraph, START, END\n\nclass State(TypedDict):\n    topic: str\n    joke: str\n\ndef refine_topic(state: State):\n    return {\"topic\": state[\"topic\"] + \" and cats\"}\n\ndef generate_joke(state: State):\n    return {\"joke\": f\"This is a joke about {state['topic']}\"}\n\ngraph = (\n    StateGraph(State)\n    .add_node(refine_topic)\n    .add_node(generate_joke)\n    .add_edge(START, \"refine_topic\")\n    .add_edge(\"refine_topic\", \"generate_joke\")\n    .add_edge(\"generate_joke\", END)\n    .compile()\n)\n\n# The stream() method returns an iterator that yields streamed outputs\nfor chunk in graph.stream(  \n    {\"topic\": \"ice cream\"},\n    # Set stream_mode=\"updates\" to stream only the updates to the graph state after each node\n    # Other stream modes are also available. See supported stream modes for details\n    stream_mode=\"updates\",  \n):\n    print(chunk)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Trajectory Match Evaluator",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.tools import tool\nfrom langchain.messages import HumanMessage, AIMessage, ToolMessage\nfrom agentevals.trajectory.match import create_trajectory_match_evaluator\n\n\n@tool\ndef get_weather(city: str):\n    \"\"\"Get weather information for a city.\"\"\"\n    return f\"It's 75 degrees and sunny in {city}.\"\n\n@tool\ndef get_events(city: str):\n    \"\"\"Get events happening in a city.\"\"\"\n    return f\"Concert at the park in {city} tonight.\"\n\nagent = create_agent(\"gpt-4o\", tools=[get_weather, get_events])\n\nevaluator = create_trajectory_match_evaluator(  \n    trajectory_match_mode=\"unordered\",  \n)  \n\ndef test_multiple_tools_any_order():\n    result = agent.invoke({\n        \"messages\": [HumanMessage(content=\"What's happening in SF today?\")]\n    })\n\n    # Reference shows tools called in different order than actual execution\n    reference_trajectory = [\n        HumanMessage(content=\"What's happening in SF today?\"),\n        AIMessage(content=\"\", tool_calls=[\n            {\"id\": \"call_1\", \"name\": \"get_events\", \"args\": {\"city\": \"SF\"}},\n            {\"id\": \"call_2\", \"name\": \"get_weather\", \"args\": {\"city\": \"SF\"}},\n        ]),\n        ToolMessage(content=\"Concert at the park in SF tonight.\", tool_call_id=\"call_1\"),\n        ToolMessage(content=\"It's 75 degrees and sunny in SF.\", tool_call_id=\"call_2\"),\n        AIMessage(content=\"Today in SF: 75 degrees and sunny with a concert at the park tonight.\"),\n    ]\n\n    evaluation = evaluator(\n        outputs=result[\"messages\"],\n        reference_outputs=reference_trajectory,\n    )\n    # {\n    #     'key': 'trajectory_unordered_match',\n    #     'score': True,\n    # }\n    assert evaluation[\"score\"] is True\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Azure AI Search",
        "type": "text",
        "content": "Azure AI Search is a cloud search service\nthat gives developers infrastructure, APIs, and tools for information retrieval of vector, keyword, and hybrid\nqueries at scale. See here for usage examples.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Disable streaming for specific chat models",
        "type": "code",
        "content": "from langchain.chat_models import init_chat_model\n\nmodel = init_chat_model(\n    \"claude-sonnet-4-5-20250929\",\n    # Set disable_streaming=True to disable streaming for the chat model\n    disable_streaming=True\n\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Contributing to code",
        "type": "text",
        "content": "Code contributions are always welcome! Whether you’re fixing bugs, adding features, or improving performance, your contributions help deliver a better developer experience for thousands of developers.\n\nBefore submitting large new features or refactors , please first discuss your ideas in the forum . This ensures alignment with project goals and prevents duplicate work.\n\nThis does not apply to bugfixes or small improvements, which you can contribute directly via pull requests. Be sure to link any relevant issues in your PR description. Use closing keywords to automatically close issues when the PR is merged.\n\nNew integrations should follow the integration guidelines .",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "View thread state",
        "type": "code",
        "content": "StateSnapshot(\n    values={'messages': [HumanMessage(content=\"hi! I'm bob\"), AIMessage(content='Hi Bob! How are you doing today?), HumanMessage(content=\"what's my name?\"), AIMessage(content='Your name is Bob.')]}, next=(),\n    config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f029ca3-1f5b-6704-8004-820c16b69a5a'}},\n    metadata={\n        'source': 'loop',\n        'writes': {'call_model': {'messages': AIMessage(content='Your name is Bob.')}},\n        'step': 4,\n        'parents': {},\n        'thread_id': '1'\n    },\n    created_at='2025-05-05T16:01:24.680462+00:00',\n    parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f029ca3-1790-6b0a-8003-baf965b6a38f'}},\n    tasks=(),\n    interrupts=()\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Vertex AI Vector Search",
        "type": "code",
        "content": "Vertex AI Matching Engine",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Context editing",
        "type": "text",
        "content": "Token count that triggers the edit\n\nMinimum tokens to reclaim\n\nNumber of recent tool results to preserve\n\nWhether to clear tool call parameters\n\nList of tool names to exclude from clearing\n\nPlaceholder text for cleared outputs",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Cloud SQL for SQL Server",
        "type": "code",
        "content": "pip install langchain-google-cloud-sql-mssql\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Use in production",
        "type": "code",
        "content": "from langgraph.store.postgres import PostgresStore\n\nDB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\nwith PostgresStore.from_conn_string(DB_URI) as store:  \n    builder = StateGraph(...)\n    graph = builder.compile(store=store)  \n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Bing Search",
        "type": "code",
        "content": "from langchain_community.tools.bing_search import BingSearchResults\nfrom langchain_community.utilities import BingSearchAPIWrapper\n\napi_wrapper = BingSearchAPIWrapper()\ntool = BingSearchResults(api_wrapper=api_wrapper)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "PII detection",
        "type": "text",
        "content": "LangChain provides built-in middleware for detecting and handling Personally Identifiable Information (PII) in conversations. This middleware can detect common PII types like emails, credit cards, IP addresses, and more.\n\nPII detection middleware is helpful for cases such as health care and financial applications with compliance requirements, customer service agents that need to sanitize logs, and generally any application handling sensitive user data.\n\nThe PII middleware supports multiple strategies for handling detected PII:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/guardrails",
        "head_menu_name": "LangChain",
        "side_menu_name": "Guardrails"
    },
    {
        "title": "LangGraph",
        "type": "text",
        "content": "Thank you for helping make LangChain better! 🦜❤️\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/contributing/overview",
        "head_menu_name": "Contribute",
        "side_menu_name": "Overview"
    },
    {
        "title": "Write short-term memory from tools",
        "type": "code",
        "content": "from langchain.tools import tool, ToolRuntime\nfrom langchain_core.runnables import RunnableConfig\nfrom langchain.messages import ToolMessage\nfrom langchain.agents import create_agent, AgentState\nfrom langgraph.types import Command\nfrom pydantic import BaseModel\n\n\nclass CustomState(AgentState):  \n    user_name: str\n\nclass CustomContext(BaseModel):\n    user_id: str\n\n@tool\ndef update_user_info(\n    runtime: ToolRuntime[CustomContext, CustomState],\n) -> Command:\n    \"\"\"Look up and update user info.\"\"\"\n    user_id = runtime.context.user_id  \n    name = \"John Smith\" if user_id == \"user_123\" else \"Unknown user\"\n    return Command(update={\n        \"user_name\": name,\n        # update the message history\n        \"messages\": [\n            ToolMessage(\n                \"Successfully looked up user information\",\n                tool_call_id=runtime.tool_call_id\n            )\n        ]\n    })\n\n@tool\ndef greet(\n    runtime: ToolRuntime[CustomContext, CustomState]\n) -> str:\n    \"\"\"Use this to greet the user once you found their info.\"\"\"\n    user_name = runtime.state[\"user_name\"]\n    return f\"Hello {user_name}!\"\nagent = create_agent(\n    model=\"gpt-5-nano\",\n    tools=[update_user_info, greet],\n    state_schema=CustomState,\n    context_schema=CustomContext,  \n)\n\nagent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"greet the user\"}]},\n    context=CustomContext(user_id=\"user_123\"),\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Use in production",
        "type": "text",
        "content": "You need to call checkpointer.setup() the first time you’re using Postgres checkpointer",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Add a graph as a node",
        "type": "code",
        "content": "from typing_extensions import TypedDict\nfrom langgraph.graph.state import StateGraph, START\n\n# Define subgraph\nclass SubgraphState(TypedDict):\n    foo: str  # shared with parent graph state\n    bar: str  # private to SubgraphState\n\ndef subgraph_node_1(state: SubgraphState):\n    return {\"bar\": \"bar\"}\n\ndef subgraph_node_2(state: SubgraphState):\n    # note that this node is using a state key ('bar') that is only available in the subgraph\n    # and is sending update on the shared state key ('foo')\n    return {\"foo\": state[\"foo\"] + state[\"bar\"]}\n\nsubgraph_builder = StateGraph(SubgraphState)\nsubgraph_builder.add_node(subgraph_node_1)\nsubgraph_builder.add_node(subgraph_node_2)\nsubgraph_builder.add_edge(START, \"subgraph_node_1\")\nsubgraph_builder.add_edge(\"subgraph_node_1\", \"subgraph_node_2\")\nsubgraph = subgraph_builder.compile()\n\n# Define parent graph\nclass ParentState(TypedDict):\n    foo: str\n\ndef node_1(state: ParentState):\n    return {\"foo\": \"hi! \" + state[\"foo\"]}\n\nbuilder = StateGraph(ParentState)\nbuilder.add_node(\"node_1\", node_1)\nbuilder.add_node(\"node_2\", subgraph)\nbuilder.add_edge(START, \"node_1\")\nbuilder.add_edge(\"node_1\", \"node_2\")\ngraph = builder.compile()\n\nfor chunk in graph.stream({\"foo\": \"foo\"}):\n    print(chunk)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-subgraphs",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Subgraphs"
    },
    {
        "title": "All integration providers",
        "type": "text",
        "content": "Browse the complete collection of integrations available for Python. LangChain Python offers the most extensive ecosystem with 1000+ integrations across LLMs, chat models, retrievers, vector stores, document loaders, and more.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/all_providers",
        "head_menu_name": "Integrations",
        "side_menu_name": "All providers"
    },
    {
        "title": "Invoke a graph from a node",
        "type": "code",
        "content": "((), {'node_1': {'foo': 'hi! foo'}})\n(('node_2:9c36dd0f-151a-cb42-cbad-fa2f851f9ab7',), {'grandchild_1': {'my_grandchild_key': 'hi Bob, how are you'}})\n(('node_2:9c36dd0f-151a-cb42-cbad-fa2f851f9ab7',), {'grandchild_2': {'bar': 'hi! foobaz'}})\n((), {'node_2': {'foo': 'hi! foobaz'}})\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-subgraphs",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Subgraphs"
    },
    {
        "title": "Protocol reference",
        "type": "code",
        "content": "grep_raw(pattern: str, path: Optional[str] = None, glob: Optional[str] = None) -> list[GrepMatch] | str",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Chat models",
        "type": "code",
        "content": "ChatGoogleGenerativeAI",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Hugging Face Text-to-Speech Model Inference.",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Using SubAgent",
        "type": "code",
        "content": "import os\nfrom typing import Literal\nfrom tavily import TavilyClient\nfrom deepagents import create_deep_agent\n\ntavily_client = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n\ndef internet_search(\n    query: str,\n    max_results: int = 5,\n    topic: Literal[\"general\", \"news\", \"finance\"] = \"general\",\n    include_raw_content: bool = False,\n):\n    \"\"\"Run a web search\"\"\"\n    return tavily_client.search(\n        query,\n        max_results=max_results,\n        include_raw_content=include_raw_content,\n        topic=topic,\n    )\n\nresearch_subagent = {\n    \"name\": \"research-agent\",\n    \"description\": \"Used to research more in depth questions\",\n    \"system_prompt\": \"You are a great researcher\",\n    \"tools\": [internet_search],\n    \"model\": \"openai:gpt-4o\",  # Optional override, defaults to main agent model\n}\nsubagents = [research_subagent]\n\nagent = create_deep_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    subagents=subagents\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Bugfixes",
        "type": "text",
        "content": "For bugfix contributions:\n\nCreate a minimal test case that demonstrates the bug. Maintainers and other contributors should be able to run this test and see the failure without additional setup or modification\n\nAdd unit tests that would fail without your fix\n\nMake the minimal change necessary to resolve the issue\n\nEnsure that tests pass and no regressions are introduced\n\nUpdate docstrings if behavior changes, add comments for complex logic",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Batch",
        "type": "text",
        "content": "See the RunnableConfig reference for a full list of supported attributes.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Base URL or proxy",
        "type": "code",
        "content": "model = init_chat_model(\n    model=\"MODEL_NAME\",\n    model_provider=\"openai\",\n    base_url=\"BASE_URL\",\n    api_key=\"YOUR_API_KEY\",\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Short-term vs. long-term filesystem",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom deepagents.middleware import FilesystemMiddleware\nfrom langgraph.store.memory import InMemoryStore\n\nstore = InMemoryStore()\n\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    store=store,\n    middleware=[\n        FilesystemMiddleware(\n            long_term_memory=True,\n            custom_tool_descriptions={\n                \"ls\": \"Use the ls tool when...\",\n                \"read_file\": \"Use the read_file tool to...\"\n            }  # Optional: Custom descriptions for filesystem tools\n        ),\n    ],\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/middleware",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Recording & Replaying HTTP Calls",
        "type": "code",
        "content": "@pytest.mark.vcr()\ndef test_agent_trajectory():\n    # ...\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Dynamic model",
        "type": "code",
        "content": "from langchain_openai import ChatOpenAI\nfrom langchain.agents import create_agent\nfrom langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n\n\nbasic_model = ChatOpenAI(model=\"gpt-4o-mini\")\nadvanced_model = ChatOpenAI(model=\"gpt-4o\")\n\n@wrap_model_call\ndef dynamic_model_selection(request: ModelRequest, handler) -> ModelResponse:\n    \"\"\"Choose model based on conversation complexity.\"\"\"\n    message_count = len(request.state[\"messages\"])\n\n    if message_count > 10:\n        # Use an advanced model for longer conversations\n        model = advanced_model\n    else:\n        model = basic_model\n\n    request.model = model\n    return handler(request)\n\nagent = create_agent(\n    model=basic_model,  # Default model\n    tools=tools,\n    middleware=[dynamic_model_selection]\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Tools",
        "type": "text",
        "content": "Tools let the model interact with databases, APIs, and external systems. How you define and select tools directly impacts whether the model can complete tasks effectively.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "PII detection",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import PIIMiddleware\n\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[...],\n    middleware=[\n        # Redact emails in user input\n        PIIMiddleware(\"email\", strategy=\"redact\", apply_to_input=True),\n        # Mask credit cards (show last 4 digits)\n        PIIMiddleware(\"credit_card\", strategy=\"mask\", apply_to_input=True),\n        # Custom PII type with regex\n        PIIMiddleware(\n            \"api_key\",\n            detector=r\"sk-[a-zA-Z0-9]{32}\",\n            strategy=\"block\",  # Raise error if detected\n        ),\n    ],\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Deleting documents",
        "type": "code",
        "content": "vector_store.delete(ids=[\"id1\"])\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Configurable models",
        "type": "code",
        "content": "[\n    {\n        'name': 'GetPopulation',\n        'args': {'location': 'Los Angeles, CA'},\n        'id': 'call_Ga9m8FAArIyEjItHmztPYA22',\n        'type': 'tool_call'\n    },\n    {\n        'name': 'GetPopulation',\n        'args': {'location': 'New York, NY'},\n        'id': 'call_jh2dEvBaAHRaw5JUDthOs7rt',\n        'type': 'tool_call'\n    }\n]\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Control the output from the subagent",
        "type": "code",
        "content": "from typing import Annotated\nfrom langchain.agents import AgentState\nfrom langchain.tools import InjectedToolCallId\nfrom langgraph.types import Command\n\n\n@tool(\n    \"subagent1_name\",\n    description=\"subagent1_description\"\n)\n# We need to pass the `tool_call_id` to the sub agent so it can use it to respond with the tool call result\ndef call_subagent1(\n    query: str,\n    tool_call_id: Annotated[str, InjectedToolCallId],\n# You need to return a `Command` object to include more than just a final tool call\n) -> Command:\n    result = subagent1.invoke({\n        \"messages\": [{\"role\": \"user\", \"content\": query}]\n    })\n    return Command(update={\n        # This is the example state key we are passing back\n        \"example_state_key\": result[\"example_state_key\"],\n        \"messages\": [\n            ToolMessage(\n                content=result[\"messages\"][-1].content,\n                # We need to include the tool call id so it matches up with the right tool call\n                tool_call_id=tool_call_id\n            )\n        ]\n    })\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/multi-agent",
        "head_menu_name": "LangChain",
        "side_menu_name": "Multi-agent"
    },
    {
        "title": "Tool use in the ReAct loop",
        "type": "code",
        "content": "================================= Tool Message =================================\n\nProduct WH-1000XM5: 10 units in stock\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Common patterns",
        "type": "text",
        "content": "With short-term memory enabled, long conversations can exceed the LLM’s context window. Common solutions are:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Inside tools",
        "type": "code",
        "content": "from dataclasses import dataclass\nfrom langchain.tools import tool, ToolRuntime  \n\n@dataclass\nclass Context:\n    user_id: str\n\n@tool\ndef fetch_user_email_preferences(runtime: ToolRuntime[Context]) -> str:  \n    \"\"\"Fetch the user's email preferences from the store.\"\"\"\n    user_id = runtime.context.user_id  \n\n    preferences: str = \"The user prefers you to write a brief and polite email.\"\n    if runtime.store:  \n        if memory := runtime.store.get((\"users\",), user_id):  \n            preferences = memory.value[\"preferences\"]\n\n    return preferences\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/runtime",
        "head_menu_name": "LangChain",
        "side_menu_name": "Runtime"
    },
    {
        "title": "SystemMessageto string",
        "type": "text",
        "content": "If using SystemMessage objects in the system prompt, extract the string content:",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Listing files",
        "type": "text",
        "content": "Files from the Store are prefixed with /memories/ in listings.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "import getpass\nimport os\n\nif not os.environ.get(\"PPLX_API_KEY\"):\n  os.environ[\"PPLX_API_KEY\"] = getpass.getpass(\"Enter API key for Perplexity: \")\n\nfrom langchain.chat_models import init_chat_model\n\nmodel = init_chat_model(\"llama-3.1-sonar-small-128k-online\", model_provider=\"perplexity\")\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "2. Identify a checkpoint",
        "type": "code",
        "content": "('write_joke',)\n{'topic': 'How about \"The Secret Life of Socks in the Dryer\"? You know, exploring the mysterious phenomenon of how socks go into the laundry as pairs but come out as singles. Where do they go? Are they starting new lives elsewhere? Is there a sock paradise we don\\\\'t know about? There\\\\'s a lot of comedic potential in the everyday mystery that unites us all!'}\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-time-travel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Time travel"
    },
    {
        "title": "Using in LangGraph",
        "type": "text",
        "content": "We invoke the graph with a thread_id , as before, and also with a user_id , which we’ll use to namespace our memories to this particular user as we showed above.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "\"sync\"",
        "type": "text",
        "content": "Changes are persisted synchronously before the next step starts. This ensures that every checkpoint is written before continuing execution, providing high durability at the cost of some performance overhead.\n\nYou can specify the durability mode when calling any graph execution method:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/durable-execution",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Durable execution"
    },
    {
        "title": "Content block reference",
        "type": "text",
        "content": "URL pointing to the video location.\n\nBase64-encoded video data.\n\nReference ID to an externally stored video file (e.g., in a provider’s file system or in a bucket).\n\nVideo MIME type (e.g., video/mp4 , video/webm )",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Installation and Setup",
        "type": "text",
        "content": "See detail configuration instructions .\n\nWe need to install the pymongo python package.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "HuggingFacePipeline",
        "type": "code",
        "content": "from langchain_huggingface import HuggingFacePipeline\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Stream graph state",
        "type": "code",
        "content": "from typing import TypedDict\nfrom langgraph.graph import StateGraph, START, END\n\n\nclass State(TypedDict):\n  topic: str\n  joke: str\n\n\ndef refine_topic(state: State):\n    return {\"topic\": state[\"topic\"] + \" and cats\"}\n\n\ndef generate_joke(state: State):\n    return {\"joke\": f\"This is a joke about {state['topic']}\"}\n\ngraph = (\n  StateGraph(State)\n  .add_node(refine_topic)\n  .add_node(generate_joke)\n  .add_edge(START, \"refine_topic\")\n  .add_edge(\"refine_topic\", \"generate_joke\")\n  .add_edge(\"generate_joke\", END)\n  .compile()\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "In production",
        "type": "code",
        "content": "from langchain.agents import create_agent\n\nfrom langgraph.checkpoint.postgres import PostgresSaver  \n\n\nDB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\nwith PostgresSaver.from_conn_string(DB_URI) as checkpointer:\n    checkpointer.setup() # auto create tables in PostgresSql\n    agent = create_agent(\n        \"gpt-5\",\n        [get_user_info],\n        checkpointer=checkpointer,  \n    )\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Long-term memory",
        "type": "text",
        "content": "Deep agents come with a local filesystem to offload memory. This filesystem is stored in state and is therefore transient to a single thread —files are lost when the conversation ends.\n\nYou can extend deep agents with long-term memory by providing a LangGraph Store and setting use_longterm_memory=True . This enables persistent storage that survives across threads and conversations.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "HuggingFaceInferenceAPIEmbeddings",
        "type": "text",
        "content": "We can use the HuggingFaceInferenceAPIEmbeddings class to run open source embedding models via Inference Providers .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "After model",
        "type": "code",
        "content": "from langchain.messages import RemoveMessage\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langchain.agents import create_agent, AgentState\nfrom langchain.agents.middleware import after_model\nfrom langgraph.runtime import Runtime\n\n\n@after_model\ndef validate_response(state: AgentState, runtime: Runtime) -> dict | None:\n    \"\"\"Remove messages containing sensitive words.\"\"\"\n    STOP_WORDS = [\"password\", \"secret\"]\n    last_message = state[\"messages\"][-1]\n    if any(word in last_message.content for word in STOP_WORDS):\n        return {\"messages\": [RemoveMessage(id=last_message.id)]}\n    return None\n\nagent = create_agent(\n    model=\"gpt-5-nano\",\n    tools=[],\n    middleware=[validate_response],\n    checkpointer=InMemorySaver(),\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Google Search",
        "type": "code",
        "content": "langchain-google-community",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Execution order",
        "type": "code",
        "content": "middleware2.before_agent()",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "AWS S3 Directory and File",
        "type": "code",
        "content": "from langchain_community.document_loaders import S3DirectoryLoader, S3FileLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Azure SQL Database",
        "type": "text",
        "content": "Azure SQL Database is a robust service that combines scalability, security, and high availability, providing all the benefits of a modern database solution.  It also provides a dedicated Vector data type & built-in functions that simplifies the storage and querying of vector embeddings directly within a relational database. This eliminates the need for separate vector databases and related integrations, increasing the security of your solutions while reducing the overall complexity.\n\nBy leveraging your current SQL Server databases for vector search, you can enhance data capabilities while minimizing expenses and avoiding the challenges of transitioning to new systems.\n\nSee detail configuration instructions .\n\nWe need to install the langchain-sqlserver python package.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "System prompt",
        "type": "text",
        "content": "You can shape how your agent approaches tasks by providing a prompt. The system_prompt parameter can be provided as a string:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Office 365 individual tools",
        "type": "text",
        "content": "You can use individual tools from the Office 365 Toolkit:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Validating human input",
        "type": "code",
        "content": "from langgraph.types import interrupt\n\ndef get_age_node(state: State):\n    prompt = \"What is your age?\"\n\n    while True:\n        answer = interrupt(prompt)  # payload surfaces in result[\"__interrupt__\"]\n\n        # Validate the input\n        if isinstance(answer, int) and answer > 0:\n            # Valid input - continue\n            break\n        else:\n            # Invalid input - ask again with a more specific prompt\n            prompt = f\"'{answer}' is not a valid age. Please enter a positive number.\"\n\n    return {\"age\": answer}\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "User preferences",
        "type": "text",
        "content": "Store user preferences that persist across sessions:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "How it works",
        "type": "text",
        "content": "LangChain chat models can also stream semantic events using astream_events() .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Example: Summarization",
        "type": "code",
        "content": "SummarizationMiddleware",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Execution lifecycle",
        "type": "text",
        "content": "The middleware defines an after_model hook that runs after the model generates a response but before any tool calls are executed:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/human-in-the-loop",
        "head_menu_name": "LangChain",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Invoke",
        "type": "text",
        "content": "The most straightforward way to call a model is to use invoke() with a single message or a list of messages.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Memory (Store)",
        "type": "text",
        "content": "Tools can access and update the store through ToolRuntime :",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "Cross-thread persistence",
        "type": "text",
        "content": "Files in /memories/ can be accessed from any thread:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Trajectory Match Evaluator",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.tools import tool\nfrom langchain.messages import HumanMessage, AIMessage, ToolMessage\nfrom agentevals.trajectory.match import create_trajectory_match_evaluator\n\n\n@tool\ndef get_weather(city: str):\n    \"\"\"Get weather information for a city.\"\"\"\n    return f\"It's 75 degrees and sunny in {city}.\"\n\n@tool\ndef get_detailed_forecast(city: str):\n    \"\"\"Get detailed weather forecast for a city.\"\"\"\n    return f\"Detailed forecast for {city}: sunny all week.\"\n\nagent = create_agent(\"gpt-4o\", tools=[get_weather, get_detailed_forecast])\n\nevaluator = create_trajectory_match_evaluator(  \n    trajectory_match_mode=\"superset\",  \n)  \n\ndef test_agent_calls_required_tools_plus_extra():\n    result = agent.invoke({\n        \"messages\": [HumanMessage(content=\"What's the weather in Boston?\")]\n    })\n\n    # Reference only requires get_weather, but agent may call additional tools\n    reference_trajectory = [\n        HumanMessage(content=\"What's the weather in Boston?\"),\n        AIMessage(content=\"\", tool_calls=[\n            {\"id\": \"call_1\", \"name\": \"get_weather\", \"args\": {\"city\": \"Boston\"}},\n        ]),\n        ToolMessage(content=\"It's 75 degrees and sunny in Boston.\", tool_call_id=\"call_1\"),\n        AIMessage(content=\"The weather in Boston is 75 degrees and sunny.\"),\n    ]\n\n    evaluation = evaluator(\n        outputs=result[\"messages\"],\n        reference_outputs=reference_trajectory,\n    )\n    # {\n    #     'key': 'trajectory_superset_match',\n    #     'score': True,\n    #     'comment': None,\n    # }\n    assert evaluation[\"score\"] is True\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Azure Cosmos DB NoSQL",
        "type": "code",
        "content": "from langchain_community.vectorstores import AzureCosmosDBNoSQLVectorSearch\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Disable streaming for specific chat models",
        "type": "code",
        "content": "disable_streaming=True",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Error handling strategies",
        "type": "code",
        "content": "================================= Tool Message =================================\nName: ToolStrategy\n\nMultiple structured outputs were returned. Pick the most relevant one.\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Delete messages",
        "type": "text",
        "content": "You can delete messages from the graph state to manage the message history. This is useful when you want to remove specific messages or clear the entire message history.\n\nTo delete messages from the graph state, you can use the RemoveMessage . For RemoveMessage to work, you need to use a state key with add_messages reducer , like MessagesState .",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Filesystem middleware",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom deepagents.middleware.filesystem import FilesystemMiddleware\n\n# FilesystemMiddleware is included by default in create_deep_agent\n# You can customize it if building a custom agent\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    middleware=[\n        FilesystemMiddleware(\n            long_term_memory=False,  # Enables access to long-term memory, defaults to False. You must attach a store to use long-term memory.\n            system_prompt=\"Write to the filesystem when...\",  # Optional custom addition to the system prompt\n            custom_tool_descriptions={\n                \"ls\": \"Use the ls tool when...\",\n                \"read_file\": \"Use the read_file tool to...\"\n            }  # Optional: Custom descriptions for filesystem tools\n        ),\n    ],\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/middleware",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Overview",
        "type": "text",
        "content": "LangChain agents use LangGraph persistence to enable long-term memory. This is a more advanced topic and requires knowledge of LangGraph to use.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/long-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "WRITER",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/splitters",
        "head_menu_name": "Integrations",
        "side_menu_name": "Text splitters"
    },
    {
        "title": "values",
        "type": "text",
        "content": "The foo key (channel) is completely changed (because there is no reducer specified for that channel, so update_state overwrites it). However, there is a reducer specified for the bar key, and so it appends \"b\" to the state of bar .",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Filter by node",
        "type": "text",
        "content": "To stream tokens only from specific nodes, use stream_mode=\"messages\" and filter the outputs by the langgraph_node field in the streamed metadata:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Mocking Chat Model",
        "type": "code",
        "content": "model.invoke(\"hello, again!\")\n# AIMessage(content='bar', ...)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "High-level API",
        "type": "text",
        "content": "LangGraph provides two high-level APIs for creating a Pregel application: the StateGraph (Graph API) and the Functional API .\n\nThe StateGraph (Graph API) is a higher-level abstraction that simplifies the creation of Pregel applications. It allows you to define a graph of nodes and edges. When you compile the graph, the StateGraph API automatically creates the Pregel application for you.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/pregel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Runtime"
    },
    {
        "title": "Delete all checkpoints for a thread",
        "type": "code",
        "content": "thread_id = \"1\"\ncheckpointer.delete_thread(thread_id)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Knowledge base",
        "type": "code",
        "content": "# Conversation 1: Learn about a project\nagent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"We're building a web app with React. Save project notes.\"}]\n})\n\n# Conversation 2: Use that knowledge\nagent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"What framework are we using?\"}]\n})\n# Agent reads /memories/project_notes.txt from previous conversation\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Memory Store",
        "type": "text",
        "content": "LangGraph API handles stores automatically When using the LangGraph API, you don’t need to implement or configure stores manually. The API handles all storage infrastructure for you behind the scenes.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Vertex AI image captioning",
        "type": "text",
        "content": "Implementation of the Image Captioning model as a chat. Requires langchain-google-vertexai .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Stream subgraph outputs",
        "type": "code",
        "content": "for chunk in graph.stream(\n    {\"foo\": \"foo\"},\n    # Set subgraphs=True to stream outputs from subgraphs\n    subgraphs=True,  \n    stream_mode=\"updates\",\n):\n    print(chunk)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Hugging Face",
        "type": "text",
        "content": "All LangChain integrations with Hugging Face Hub and libraries like transformers , sentence transformers , and datasets .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "from langchain_ollama import OllamaEmbeddings\n\nembeddings = OllamaEmbeddings(model=\"llama3\")\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "2. Define state",
        "type": "code",
        "content": "from langchain.messages import AnyMessage\nfrom typing_extensions import TypedDict, Annotated\nimport operator\n\n\nclass MessagesState(TypedDict):\n    messages: Annotated[list[AnyMessage], operator.add]\n    llm_calls: int\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/quickstart",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "ToolRuntime",
        "type": "text",
        "content": "ToolRuntime : A unified parameter that provides tools access to state, context, store, streaming, config, and tool call ID. This replaces the older pattern of using separate InjectedState , InjectedStore , get_runtime , and InjectedToolCallId annotations.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "1. Define tools and model",
        "type": "code",
        "content": "from langchain.tools import tool\nfrom langchain.chat_models import init_chat_model\n\n\nmodel = init_chat_model(\n    \"claude-sonnet-4-5-20250929\",\n    temperature=0\n)\n\n\n# Define tools\n@tool\ndef multiply(a: int, b: int) -> int:\n    \"\"\"Multiply `a` and `b`.\n\n    Args:\n        a: First int\n        b: Second int\n    \"\"\"\n    return a * b\n\n\n@tool\ndef add(a: int, b: int) -> int:\n    \"\"\"Adds `a` and `b`.\n\n    Args:\n        a: First int\n        b: Second int\n    \"\"\"\n    return a + b\n\n\n@tool\ndef divide(a: int, b: int) -> float:\n    \"\"\"Divide `a` and `b`.\n\n    Args:\n        a: First int\n        b: Second int\n    \"\"\"\n    return a / b\n\n\n# Augment the LLM with tools\ntools = [add, multiply, divide]\ntools_by_name = {tool.name: tool for tool in tools}\nmodel_with_tools = model.bind_tools(tools)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/quickstart",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Inside middleware",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/runtime",
        "head_menu_name": "LangChain",
        "side_menu_name": "Runtime"
    },
    {
        "title": "Static model",
        "type": "text",
        "content": "Model instances give you complete control over configuration. Use them when you need to set specific parameters like temperature , max_tokens , timeouts , base_url , and other provider-specific settings. Refer to the reference to see available params and methods on your model.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Additional resources",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Gmail",
        "type": "code",
        "content": "from langchain_google_community import GMailLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Trim messages",
        "type": "text",
        "content": "Most LLMs have a maximum supported context window (denominated in tokens). One way to decide when to truncate messages is to count the tokens in the message history and truncate whenever it approaches that limit. If you’re using LangChain, you can use the trim messages utility and specify the number of tokens to keep from the list, as well as the strategy (e.g., keep the last max_tokens ) to use for handling the boundary.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Custom guardrails",
        "type": "text",
        "content": "For more sophisticated guardrails, you can create custom middleware that runs before or after the agent executes. This gives you full control over validation logic, content filtering, and safety checks.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/guardrails",
        "head_menu_name": "LangChain",
        "side_menu_name": "Guardrails"
    },
    {
        "title": "Writing standard",
        "type": "text",
        "content": "Reference documentation has different standards - see the reference docs contributing guide for details.",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "pip install -qU langchain-qdrant\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Add long-term memory",
        "type": "code",
        "content": "from langgraph.store.memory import InMemoryStore  \nfrom langgraph.graph import StateGraph\n\nstore = InMemoryStore()  \n\nbuilder = StateGraph(...)\ngraph = builder.compile(store=store)  \n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Tool calling",
        "type": "text",
        "content": "Some model providers offer built-in tools that can be enabled via model or invocation parameters (e.g. ChatOpenAI , ChatAnthropic ). Check the respective provider reference for details.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Update state",
        "type": "text",
        "content": "In addition to re-playing the graph from specific checkpoints , we can also edit the graph state. We do this using update_state . This method accepts three different arguments:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "4. Create a.envfile",
        "type": "code",
        "content": "LANGSMITH_API_KEY=lsv2...\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/local-server",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Local server"
    },
    {
        "title": "PlayWright Browser individual tools",
        "type": "text",
        "content": "You can use individual tools from the PlayWright Browser Toolkit.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Simplified namespace",
        "type": "text",
        "content": "The langchain namespace has been streamlined to focus on essential building blocks for agents, with legacy functionality moved to langchain-classic .",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Standard content",
        "type": "code",
        "content": "message.content_blocks",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Chat Completions API",
        "type": "text",
        "content": "This is a known limitation with ChatOpenAI and will be addressed in a future release.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/chat",
        "head_menu_name": "Integrations",
        "side_menu_name": "Chat models"
    },
    {
        "title": "Example block shapes",
        "type": "code",
        "content": "# Text block\ntext_block = {\n    \"type\": \"text\",\n    \"text\": \"Hello world\",\n}\n\n# Image block\nimage_block = {\n    \"type\": \"image\",\n    \"url\": \"https://example.com/image.png\",\n    \"mime_type\": \"image/png\",\n}\n",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Recording & Replaying HTTP Calls",
        "type": "text",
        "content": "The --record-mode=once option records HTTP interactions on the first run and replays them on subsequent runs.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Wrap-style hooks",
        "type": "code",
        "content": "from langchain.agents.middleware import AgentMiddleware, ModelRequest, ModelResponse\nfrom langchain.chat_models import init_chat_model\nfrom typing import Callable\n\nclass DynamicModelMiddleware(AgentMiddleware):\n    def wrap_model_call(\n        self,\n        request: ModelRequest,\n        handler: Callable[[ModelRequest], ModelResponse],\n    ) -> ModelResponse:\n        # Use different model based on conversation length\n        if len(request.messages) > 10:\n            request.model = init_chat_model(\"gpt-4o\")\n        else:\n            request.model = init_chat_model(\"gpt-4o-mini\")\n\n        return handler(request)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Retrievers",
        "type": "text",
        "content": "A retriever is an interface that returns documents given an unstructured query.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/retrieval",
        "head_menu_name": "LangChain",
        "side_menu_name": "Retrieval"
    },
    {
        "title": "Context",
        "type": "text",
        "content": "Tools can access runtime context through ToolRuntime :",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "Add metadata to traces",
        "type": "code",
        "content": "response = agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"Send a welcome email\"}]},\n    config={\n        \"tags\": [\"production\", \"email-assistant\", \"v1.0\"],\n        \"metadata\": {\n            \"user_id\": \"user_123\",\n            \"session_id\": \"session_456\",\n            \"environment\": \"production\"\n        }\n    }\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/observability",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Observability"
    },
    {
        "title": "Vertex AI callback handler",
        "type": "code",
        "content": "from langchain_google_vertexai.callbacks import VertexAICallbackHandler\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Azure AI Search",
        "type": "code",
        "content": "from langchain_community.retrievers import AzureAISearchRetriever\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Adding documents",
        "type": "code",
        "content": "vector_store.add_documents(documents=[doc1, doc2], ids=[\"id1\", \"id2\"])\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Python reference",
        "type": "text",
        "content": "A good reference should:\n\nSee the contributing guide for Python reference docs .",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "Side effects called beforeinterruptmust be idempotent",
        "type": "text",
        "content": "As an example, you might have an API call to update a record inside of a node. If interrupt is called after that call is made, it will be re-run multiple times when the node is resumed, potentially overwriting the initial update or creating duplicate records.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Use semantic search",
        "type": "text",
        "content": "Enable semantic search in your graph’s memory store to let graph agents search for items in the store by semantic similarity.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Vertex AI visual QnA",
        "type": "code",
        "content": "from langchain_google_vertexai.vision_models import VertexAIVisualQnAChat\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Server-side tool use",
        "type": "text",
        "content": "Some providers support server-side tool-calling loops: models can interact with web search, code interpreters, and other tools and analyze the results in a single conversational turn.\n\nIf a model invokes a tool server-side, the content of the response message will include content representing the invocation and result of the tool. Accessing the content blocks of the response will return the server-side tool calls and results in a provider-agnostic format:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "pip install -qU langchain-aws\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Document AI Warehouse",
        "type": "code",
        "content": "langchain-google-community",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Enable tracing",
        "type": "code",
        "content": "export LANGSMITH_TRACING=true\nexport LANGSMITH_API_KEY=<your-api-key>\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/observability",
        "head_menu_name": "LangChain",
        "side_menu_name": "Observability"
    },
    {
        "title": "Easy to use, highly flexible agent",
        "type": "text",
        "content": "LangChain’s agent abstraction is designed to be easy to get started with, letting you build a simple agent in under 10 lines of code. But it also provides enough flexibility to allow you to do all the context engineering your heart desires.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/overview",
        "head_menu_name": "LangChain",
        "side_menu_name": "Overview"
    },
    {
        "title": "Build a basic agent",
        "type": "code",
        "content": "from langchain.agents import create_agent\n\ndef get_weather(city: str) -> str:\n    \"\"\"Get weather for a given city.\"\"\"\n    return f\"It's always sunny in {city}!\"\n\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    tools=[get_weather],\n    system_prompt=\"You are a helpful assistant\",\n)\n\n# Run the agent\nagent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/quickstart",
        "head_menu_name": "LangChain",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Seamless with LangChain v1",
        "type": "code",
        "content": "pip install -U langgraph\n",
        "side_link": "https://docs.langchain.com/oss/python/releases/langgraph-v1",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Azure AI Document Intelligence",
        "type": "code",
        "content": "Azure Form Recognizer",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Side effects called beforeinterruptmust be idempotent",
        "type": "code",
        "content": "def node_a(state: State):\n    # ✅ Good: using upsert operation which is idempotent\n    # Running this multiple times will have the same result\n    db.upsert_user(\n        user_id=state[\"user_id\"],\n        status=\"pending_approval\"\n    )\n\n    approved = interrupt(\"Approve this change?\")\n\n    return {\"approved\": approved}\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Defaultmax_tokensinlangchain-anthropic",
        "type": "text",
        "content": "The max_tokens parameter in langchain-anthropic now defaults to higher values based on the model chosen, rather than the previous default of 1024 . If you relied on the old default, explicitly set max_tokens=1024 .",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Standard model interface",
        "type": "text",
        "content": "Different providers have unique APIs for interacting with models, including the format of responses. LangChain standardizes how you interact with models so that you can seamlessly swap providers and avoid lock-in.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/overview",
        "head_menu_name": "LangChain",
        "side_menu_name": "Overview"
    },
    {
        "title": "Content block reference",
        "type": "text",
        "content": "Name of the tool being called\n\nPartial tool arguments (may be incomplete JSON)\n\nTool call identifier\n\nPosition of this chunk in the stream\n\nPurpose: Malformed calls, intended to catch JSON parsing errors.\n\nAlways \"invalid_tool_call\"",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "View subgraph state",
        "type": "text",
        "content": "Available only when interrupted Subgraph state can only be viewed when the subgraph is interrupted . Once you resume the graph, you won’t be able to access the subgraph state.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-subgraphs",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Subgraphs"
    },
    {
        "title": "Test",
        "type": "text",
        "content": "After you’ve prototyped your LangGraph agent, a natural next step is to add tests. This guide covers some useful patterns you can use when writing unit tests.\n\nNote that this guide is LangGraph-specific and covers scenarios around graphs with custom structures - if you are just getting started, check out this section that uses LangChain’s built-in create_agent instead.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/test",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Test"
    },
    {
        "title": "Add persistence",
        "type": "code",
        "content": "from langgraph.graph import START, StateGraph\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom typing_extensions import TypedDict\n\nclass State(TypedDict):\n    foo: str\n\n# Subgraph\n\ndef subgraph_node_1(state: State):\n    return {\"foo\": state[\"foo\"] + \"bar\"}\n\nsubgraph_builder = StateGraph(State)\nsubgraph_builder.add_node(subgraph_node_1)\nsubgraph_builder.add_edge(START, \"subgraph_node_1\")\nsubgraph = subgraph_builder.compile()\n\n# Parent graph\n\nbuilder = StateGraph(State)\nbuilder.add_node(\"node_1\", subgraph)\nbuilder.add_edge(START, \"node_1\")\n\ncheckpointer = MemorySaver()\ngraph = builder.compile(checkpointer=checkpointer)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-subgraphs",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Subgraphs"
    },
    {
        "title": "Caching",
        "type": "code",
        "content": "query_embedding_cache",
        "side_link": "https://docs.langchain.com/oss/python/integrations/text_embedding",
        "head_menu_name": "Integrations",
        "side_menu_name": "Embedding models"
    },
    {
        "title": "Chat models",
        "type": "code",
        "content": "from langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain.messages import HumanMessage\n\nllm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n\n# Simple text invocation\nresult = llm.invoke(\"Sing a ballad of LangChain.\")\nprint(result.content)\n\n# Multimodal invocation with gemini-pro-vision\nmessage = HumanMessage(\n    content=[\n        {\n            \"type\": \"text\",\n            \"text\": \"What's in this image?\",\n        },\n        {\"type\": \"image_url\", \"image_url\": \"https://picsum.photos/seed/picsum/200/300\"},\n    ]\n)\nresult = llm.invoke([message])\nprint(result.content)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Implementation",
        "type": "code",
        "content": "from langchain.tools import tool\nfrom langchain.agents import create_agent\n\n\nsubagent1 = create_agent(model=\"...\", tools=[...])\n\n@tool(\n    \"subagent1_name\",\n    description=\"subagent1_description\"\n)\ndef call_subagent1(query: str):\n    result = subagent1.invoke({\n        \"messages\": [{\"role\": \"user\", \"content\": query}]\n    })\n    return result[\"messages\"][-1].content\n\nagent = create_agent(model=\"...\", tools=[call_subagent1])\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/multi-agent",
        "head_menu_name": "LangChain",
        "side_menu_name": "Multi-agent"
    },
    {
        "title": "Dynamic cross-conversation context",
        "type": "text",
        "content": "Dynamic cross-conversation context represents persistent, mutable data that spans across multiple conversations or sessions and is managed through the LangGraph store. This includes user profiles, preferences, and historical interactions. The LangGraph store acts as long-term memory across multiple runs. This can be used to read or update persistent facts (e.g., user profiles, preferences, prior interactions).",
        "side_link": "https://docs.langchain.com/oss/python/concepts/context",
        "head_menu_name": "Learn",
        "side_menu_name": "Context"
    },
    {
        "title": "Model",
        "type": "code",
        "content": "\"claude-sonnet-4-5-20250929\"",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/customization",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Customization"
    },
    {
        "title": "Writing memories",
        "type": "text",
        "content": "There are two primary methods for agents to write memories: “in the hot path” and “in the background” .",
        "side_link": "https://docs.langchain.com/oss/python/concepts/memory",
        "head_menu_name": "Learn",
        "side_menu_name": "Memory"
    },
    {
        "title": "Use in production",
        "type": "code",
        "content": "from langchain.chat_models import init_chat_model\nfrom langgraph.graph import StateGraph, MessagesState, START\nfrom langgraph.checkpoint.mongodb import MongoDBSaver  \n\nmodel = init_chat_model(model=\"claude-haiku-4-5-20251001\")\n\nDB_URI = \"localhost:27017\"\nwith MongoDBSaver.from_conn_string(DB_URI) as checkpointer:  \n\n    def call_model(state: MessagesState):\n        response = model.invoke(state[\"messages\"])\n        return {\"messages\": response}\n\n    builder = StateGraph(MessagesState)\n    builder.add_node(call_model)\n    builder.add_edge(START, \"call_model\")\n\n    graph = builder.compile(checkpointer=checkpointer)  \n\n    config = {\n        \"configurable\": {\n            \"thread_id\": \"1\"\n        }\n    }\n\n    for chunk in graph.stream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"hi! I'm bob\"}]},\n        config,  \n        stream_mode=\"values\"\n    ):\n        chunk[\"messages\"][-1].pretty_print()\n\n    for chunk in graph.stream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what's my name?\"}]},\n        config,  \n        stream_mode=\"values\"\n    ):\n        chunk[\"messages\"][-1].pretty_print()\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Tool Context",
        "type": "text",
        "content": "Tools are special in that they both read and write context.\n\nIn the most basic case, when a tool executes, it receives the LLM’s request parameters and returns a tool message back. The tool does its work and produces a result.\n\nTools can also fetch important information for the model that allows it to perform and complete tasks.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Tool calls",
        "type": "text",
        "content": "When models make tool calls , they’re included in the AIMessage :",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "2. Create a LangGraph app 🌱",
        "type": "text",
        "content": "Create a new app from the new-langgraph-project-python template . This template demonstrates a single-node application you can extend with your own logic.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/local-server",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Local server"
    },
    {
        "title": "Stream custom data",
        "type": "text",
        "content": "No get_stream_writer in async for Python < 3.11 In async code running on Python < 3.11, get_stream_writer will not work.\nInstead, add a writer parameter to your node or tool and pass it manually.\nSee Async with Python < 3.11 for usage examples.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Semantic memory",
        "type": "text",
        "content": "Semantic memory , both in humans and AI agents, involves the retention of specific facts and concepts. In humans, it can include information learned in school and the understanding of concepts and their relationships. For AI agents, semantic memory is often used to personalize applications by remembering facts or concepts from past interactions.\n\nSemantic memory is different from “semantic search,” which is a technique for finding similar content using “meaning” (usually as embeddings). Semantic memory is a term from psychology, referring to storing facts and knowledge, while semantic search is a method for retrieving information based on meaning rather than exact matches.\n\nSemantic memories can be managed in different ways:",
        "side_link": "https://docs.langchain.com/oss/python/concepts/memory",
        "head_menu_name": "Learn",
        "side_menu_name": "Memory"
    },
    {
        "title": "Checkpointer interface",
        "type": "code",
        "content": "graph.get_state_history()",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Amazon API Gateway",
        "type": "code",
        "content": "from langchain_community.llms import AmazonAPIGateway\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Migration guide",
        "type": "text",
        "content": "See our migration guide for help updating your code to LangChain v1.",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Custom tool message content",
        "type": "code",
        "content": "================================ Human Message =================================\n\nFrom our meeting: Sarah needs to update the project timeline as soon as possible\n================================== Ai Message ==================================\nTool Calls:\n  MeetingAction (call_1)\n Call ID: call_1\n  Args:\n    task: Update the project timeline\n    assignee: Sarah\n    priority: high\n================================= Tool Message =================================\nName: MeetingAction\n\nAction item captured and added to meeting notes!\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Batch",
        "type": "text",
        "content": "Batching a collection of independent requests to a model can significantly improve performance and reduce costs, as the processing can be done in parallel:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Azure SQL Database",
        "type": "code",
        "content": "from langchain_sqlserver import SQLServer_VectorStore\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Cloud Providers",
        "type": "code",
        "content": "TencentCOSDirectoryLoader",
        "side_link": "https://docs.langchain.com/oss/python/integrations/document_loaders",
        "head_menu_name": "Integrations",
        "side_menu_name": "Document loaders"
    },
    {
        "title": "Prompt",
        "type": "code",
        "content": "================================ Human Message =================================\n\nWhat is the weather in SF?\n================================== Ai Message ==================================\nTool Calls:\n  get_weather (call_WFQlOGn4b2yoJrv7cih342FG)\n Call ID: call_WFQlOGn4b2yoJrv7cih342FG\n  Args:\n    city: San Francisco\n================================= Tool Message =================================\nName: get_weather\n\nThe weather in San Francisco is always sunny!\n================================== Ai Message ==================================\n\nHi John Smith, the weather in San Francisco is always sunny!\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Streaming node name rename",
        "type": "text",
        "content": "When streaming events from agents, the node name has changed from \"agent\" to \"model\" to better reflect the node’s purpose.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Checkpoints",
        "type": "text",
        "content": "Note that we bar channel values contain outputs from both nodes as we have a reducer for bar channel.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Vertex AI image generator",
        "type": "text",
        "content": "Generates an image from a prompt. Requires langchain-google-vertexai .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Planning middleware",
        "type": "text",
        "content": "Planning is integral to solving complex problems. If you’ve used Claude Code recently, you’ll notice how it writes out a to-do list before tackling complex, multi-part tasks. You’ll also notice how it can adapt and update this to-do list on the fly as more information comes in.\n\nTodoListMiddleware provides your agent with a tool specifically for updating this to-do list. Before and while it executes a multi-part task, the agent is prompted to use the write_todos tool to keep track of what it’s doing and what still needs to be done.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/middleware",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Gemma local from Kaggle",
        "type": "code",
        "content": "from langchain_google_vertexai.gemma import GemmaLocalKaggle\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Cloud SQL for PostgreSQL",
        "type": "code",
        "content": "from langchain_google_cloud_sql_pg import PostgresVectorStore # PostgresEngine also available\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Tool and provider strategies",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.structured_output import ToolStrategy, ProviderStrategy\nfrom pydantic import BaseModel\n\n\nclass OutputSchema(BaseModel):\n    summary: str\n    sentiment: str\n\n# Using ToolStrategy\nagent = create_agent(\n    model=\"gpt-4o-mini\",\n    tools=tools,\n    # explicitly using tool strategy\n    response_format=ToolStrategy(OutputSchema)  \n)\n",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Tool call limit",
        "type": "text",
        "content": "Specific tool to limit. If not provided, limits apply to all tools.\n\nMaximum tool calls across all runs in a thread. Defaults to no limit.\n\nMaximum tool calls per single invocation. Defaults to no limit.\n\nBehavior when limit is reached. Options: \"end\" (graceful termination) or \"error\" (raise exception)",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Try out your agent",
        "type": "code",
        "content": "# Test with an urgent billing issue\ninitial_state = {\n    \"email_content\": \"I was charged twice for my subscription! This is urgent!\",\n    \"sender_email\": \"customer@example.com\",\n    \"email_id\": \"email_123\",\n    \"messages\": []\n}\n\n# Run with a thread_id for persistence\nconfig = {\"configurable\": {\"thread_id\": \"customer_123\"}}\nresult = app.invoke(initial_state, config)\n# The graph will pause at human_review\nprint(f\"Draft ready for review: {result['draft_response'][:100]}...\")\n\n# When ready, provide human input to resume\nfrom langgraph.types import Command\n\nhuman_response = Command(\n    resume={\n        \"approved\": True,\n        \"edited_response\": \"We sincerely apologize for the double charge. I've initiated an immediate refund...\"\n    }\n)\n\n# Resume execution\nfinal_result = app.invoke(human_response, config)\nprint(f\"Email sent successfully!\")\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Cloud SQL for MySQL",
        "type": "code",
        "content": "pip install langchain-google-cloud-sql-mysql\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "What's new in v1",
        "type": "text",
        "content": "LangGraph v1 is a stability-focused release for the agent runtime. It keeps the core graph APIs and execution model unchanged, while refining type safety, docs, and developer ergonomics.\n\nIt’s designed to work hand-in-hand with LangChain v1 (whose create_agent is built on LangGraph) so you can start high-level and drop down to granular control when needed.",
        "side_link": "https://docs.langchain.com/oss/python/releases/langgraph-v1",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Errors are part of the flow",
        "type": "text",
        "content": "Transient failures get retries, LLM-recoverable errors loop back with context, user-fixable problems pause for input, and unexpected errors bubble up for debugging.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Testing requirements",
        "type": "text",
        "content": "Integration tests require access to external services/ provider APIs (which can cost money) and therefore are not run by default.\n\nNot every code change will require an integration test, but keep in mind that we’ll require/ run integration tests separately as apart of our review process.\n\nLocation : tests/integration_tests/",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Dynamic system prompt",
        "type": "code",
        "content": "from typing import TypedDict\n\nfrom langchain.agents import create_agent\nfrom langchain.agents.middleware import dynamic_prompt, ModelRequest\n\n\nclass Context(TypedDict):\n    user_role: str\n\n@dynamic_prompt\ndef user_role_prompt(request: ModelRequest) -> str:\n    \"\"\"Generate system prompt based on user role.\"\"\"\n    user_role = request.runtime.context.get(\"user_role\", \"user\")\n    base_prompt = \"You are a helpful assistant.\"\n\n    if user_role == \"expert\":\n        return f\"{base_prompt} Provide detailed technical responses.\"\n    elif user_role == \"beginner\":\n        return f\"{base_prompt} Explain concepts simply and avoid jargon.\"\n\n    return base_prompt\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[web_search],\n    middleware=[user_role_prompt],\n    context_schema=Context\n)\n\n# The system prompt will be set dynamically based on context\nresult = agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"Explain machine learning\"}]},\n    context={\"user_role\": \"expert\"}\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Nodes are functions",
        "type": "text",
        "content": "They take state, do work, and return updates. When they need to make routing decisions, they specify both the state updates and the next destination.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Subagent not being called",
        "type": "code",
        "content": "agent = create_deep_agent(\n    system_prompt=\"\"\"...your instructions...\n\n    IMPORTANT: For complex tasks, delegate to your subagents using the task() tool.\n    This keeps your context clean and improves results.\"\"\",\n    subagents=[...]\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Thinking in LangGraph",
        "type": "text",
        "content": "LangGraph can change how you think about the agents you build. When you build an agent with LangGraph, you will first break it apart into discrete steps called nodes . Then, you will describe the different decisions and transitions for each of your nodes. Finally, you will connect your nodes together through a shared state that each node can read from and write to. In this tutorial, we’ll guide you through the thought process of building a customer support email agent with LangGraph.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "1. Run the graph",
        "type": "code",
        "content": "config = {\n    \"configurable\": {\n        \"thread_id\": uuid.uuid4(),\n    }\n}\nstate = graph.invoke({}, config)\n\nprint(state[\"topic\"])\nprint()\nprint(state[\"joke\"])\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-time-travel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Time travel"
    },
    {
        "title": "Quickstart",
        "type": "text",
        "content": "This quickstart demonstrates how to build a calculator agent using the LangGraph Graph API or the Functional API.\n\nFor conceptual information, see Graph API overview and Functional API overview .\n\nFor this example, you will need to set up a Claude (Anthropic) account and get an API key. Then, set the ANTHROPIC_API_KEY environment variable in your terminal.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/quickstart",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Cloud Vision loader",
        "type": "code",
        "content": "pip install langchain-google-community[vision]\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Microsoft Office 365 email and calendar",
        "type": "code",
        "content": "from langchain_community.agent_toolkits import O365Toolkit\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Bring-your-own documents",
        "type": "code",
        "content": "AmazonKnowledgeBasesRetriever",
        "side_link": "https://docs.langchain.com/oss/python/integrations/retrievers",
        "head_menu_name": "Integrations",
        "side_menu_name": "Retrievers"
    },
    {
        "title": "Overview",
        "type": "text",
        "content": "Memory is a system that remembers information about previous interactions. For AI agents, memory is crucial because it lets them remember previous interactions, learn from feedback, and adapt to user preferences. As agents tackle more complex tasks with numerous user interactions, this capability becomes essential for both efficiency and user satisfaction.\n\nShort term memory lets your application remember previous interactions within a single thread or conversation.\n\nA thread organizes multiple interactions in a session, similar to the way email groups messages in a single conversation.\n\nConversation history is the most common form of short-term memory. Long conversations pose a challenge to today’s LLMs; a full history may not fit inside an LLM’s context window, resulting in an context loss or errors.\n\nEven if your model supports the full context length, most LLMs still perform poorly over long contexts. They get “distracted” by stale or off-topic content, all while suffering from slower response times and higher costs.\n\nChat models accept context using messages , which include instructions (a system message) and inputs (human messages). In chat applications, messages alternate between human inputs and model responses, resulting in a list of messages that grows longer over time. Because context windows are limited, many applications can benefit from using techniques to remove or “forget” stale information.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Examples",
        "type": "text",
        "content": "While most users will interact with Pregel through the StateGraph API or the @entrypoint decorator, it is possible to interact with Pregel directly.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/pregel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Runtime"
    },
    {
        "title": "References",
        "type": "text",
        "content": "Technical descriptions of APIs and implementation details",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "Document what gets persisted",
        "type": "code",
        "content": "system_prompt=\"\"\"You have access to two types of storage:\n\nSHORT-TERM (paths without /memories/):\n- Current conversation notes\n- Temporary scratch work\n- Draft documents\n\nLONG-TERM (paths starting with /memories/):\n- User preferences and settings\n- Completed reports and documents\n- Knowledge that should persist across conversations\n- Project state and progress\n\nAlways use /memories/ for information that should survive beyond this conversation.\"\"\"\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Google Trends",
        "type": "code",
        "content": "from langchain_community.tools.google_trends import GoogleTrendsQueryRun\nfrom langchain_community.utilities.google_trends import GoogleTrendsAPIWrapper\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Streaming",
        "type": "text",
        "content": "LangChain implements a streaming system to surface real-time updates.\n\nStreaming is crucial for enhancing the responsiveness of applications built on LLMs. By displaying output progressively, even before a complete response is ready, streaming significantly improves user experience (UX), particularly when dealing with the latency of LLMs.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/streaming",
        "head_menu_name": "LangChain",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Interrupts",
        "type": "text",
        "content": "Interrupts allow you to pause graph execution at specific points and wait for external input before continuing. This enables human-in-the-loop patterns where you need external input to proceed. When an interrupt is triggered, LangGraph saves the graph state using its persistence layer and waits indefinitely until you resume execution.\n\nInterrupts work by calling the interrupt() function at any point in your graph nodes. The function accepts any JSON-serializable value which is surfaced to the caller. When you’re ready to continue, you resume execution by re-invoking the graph using Command , which then becomes the return value of the interrupt() call from inside the node.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Responding to interrupts",
        "type": "text",
        "content": "When you invoke the agent, it runs until it either completes or an interrupt is raised. An interrupt is triggered when a tool call matches the policy you configured in interrupt_on . In that case, the invocation result will include an __interrupt__ field with the actions that require review. You can then present those actions to a reviewer and resume execution once decisions are provided.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/human-in-the-loop",
        "head_menu_name": "LangChain",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "LLM-as-Judge Evaluator",
        "type": "text",
        "content": "For more configurability over how the LLM evaluates the trajectory, visit the repository .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Human-in-the-loop",
        "type": "text",
        "content": "Pause agent execution for human approval, editing, or rejection of tool calls before they execute.\n\nPerfect for:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Response Format",
        "type": "text",
        "content": "The structured response is returned in the structured_response key of the agent’s final state.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Memory",
        "type": "text",
        "content": "Agents maintain conversation history automatically through the message state. You can also configure the agent to use a custom state schema to remember additional information during the conversation.\n\nInformation stored in the state can be thought of as the short-term memory of the agent:\n\nCustom state schemas must extend AgentState as a TypedDict .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Tools",
        "type": "text",
        "content": "Tools give agents the ability to take actions. Agents go beyond simple model-only tool binding by facilitating:\n\nFor more information, see Tools .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "create_agent",
        "type": "code",
        "content": "from langchain.agents import create_agent\n\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    tools=[search_web, analyze_data, send_email],\n    system_prompt=\"You are a helpful research assistant.\"\n)\n\nresult = agent.invoke({\n    \"messages\": [\n        {\"role\": \"user\", \"content\": \"Research AI safety trends\"}\n    ]\n})\n",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Google",
        "type": "code",
        "content": "langchain-google-vertexai",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Batch",
        "type": "code",
        "content": "model.batch(\n    list_of_inputs,\n    config={\n        'max_concurrency': 5,  # Limit to 5 parallel calls\n    }\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Setup",
        "type": "code",
        "content": "%%capture --no-stderr\npip install --quiet -U langgraph langchain_anthropic\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-time-travel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Time travel"
    },
    {
        "title": "Supervisor Agent",
        "type": "text",
        "content": "Build a personal assistant that delegates to sub-agents.",
        "side_link": "https://docs.langchain.com/oss/python/learn",
        "head_menu_name": "Learn",
        "side_menu_name": "Learn"
    },
    {
        "title": "Persistence",
        "type": "text",
        "content": "Conversations automatically persist across sessions with built-in checkpointing",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Vertex AI Model Garden",
        "type": "code",
        "content": "langchain-google-vertexai",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "AzureOpenAIEmbeddings",
        "type": "text",
        "content": "Wrapper for OpenAI embedding models hosted on Azure.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/openai",
        "head_menu_name": "Integrations",
        "side_menu_name": "OpenAI"
    },
    {
        "title": "Replay",
        "type": "text",
        "content": "It’s also possible to play-back a prior graph execution. If we invoke a graph with a thread_id and a checkpoint_id , then we will re-play the previously executed steps before a checkpoint that corresponds to the checkpoint_id , and only execute the steps after the checkpoint.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Interface",
        "type": "text",
        "content": "LangChain provides a unified interface for vector stores, allowing you to:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Basic usage",
        "type": "code",
        "content": "from langchain.chat_models import init_chat_model\nfrom langchain.messages import HumanMessage, AIMessage, SystemMessage\n\nmodel = init_chat_model(\"gpt-5-nano\")\n\nsystem_msg = SystemMessage(\"You are a helpful assistant.\")\nhuman_msg = HumanMessage(\"Hello, how are you?\")\n\n# Use with chat models\nmessages = [system_msg, human_msg]\nresponse = model.invoke(messages)  # Returns AIMessage\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Benefits",
        "type": "text",
        "content": "For more information, see our guide on content blocks .",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "LLMs",
        "type": "text",
        "content": "You can also use the (legacy) string-in, string-out LLM\ninterface.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Control the output from the subagent",
        "type": "text",
        "content": "Two common strategies for shaping what the main agent receives back from a subagent:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/multi-agent",
        "head_menu_name": "LangChain",
        "side_menu_name": "Multi-agent"
    },
    {
        "title": "Messages",
        "type": "text",
        "content": "The full list of messages (conversation history) sent to the LLM.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Amazon OpenSearch Service",
        "type": "code",
        "content": "from langchain_community.vectorstores import OpenSearchVectorSearch\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Messages",
        "type": "text",
        "content": "Transient vs Persistent Message Updates:\n\nThe examples above use wrap_model_call to make transient updates - modifying what messages are sent to the model for a single call without changing what’s saved in state.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Approve or reject",
        "type": "text",
        "content": "When you resume the graph, pass true to approve or false to reject:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Text prompts",
        "type": "code",
        "content": "response = model.invoke(\"Write a haiku about spring\")\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Document what gets persisted",
        "type": "text",
        "content": "In system prompts, clarify when to use long-term vs short-term storage:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Side effects called beforeinterruptmust be idempotent",
        "type": "code",
        "content": "def node_a(state: State):\n    # ❌ Bad: creating a new record before interrupt\n    # This will create duplicate records on each resume\n    audit_id = db.create_audit_log({\n        \"user_id\": state[\"user_id\"],\n        \"action\": \"pending_approval\",\n        \"timestamp\": datetime.now()\n    })\n\n    approved = interrupt(\"Approve this change?\")\n\n    return {\"approved\": approved, \"audit_id\": audit_id}\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Persistence",
        "type": "text",
        "content": "LangGraph has a built-in persistence layer, implemented through checkpointers. When you compile a graph with a checkpointer, the checkpointer saves a checkpoint of the graph state at every super-step. Those checkpoints are saved to a thread , which can be accessed after graph execution. Because threads allow access to graph’s state after execution, several powerful capabilities including human-in-the-loop, memory, time travel, and fault-tolerance are all possible. Below, we’ll discuss each of these concepts in more detail.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Summarize messages",
        "type": "text",
        "content": "Then, you can generate a summary of the chat history, using any existing summary as context for the next summary. This summarize_conversation node can be called after some number of messages have accumulated in the messages state key.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Execution order",
        "type": "code",
        "content": "agent = create_agent(\n    model=\"gpt-4o\",\n    middleware=[middleware1, middleware2, middleware3],\n    tools=[...],\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Amazon Kendra",
        "type": "text",
        "content": "Amazon Kendra is an intelligent search service\nprovided by Amazon Web Services ( AWS ). It utilizes advanced natural language processing (NLP) and machine\nlearning algorithms to enable powerful search capabilities across various data sources within an organization. Kendra is designed to help users find the information they need quickly and accurately,\nimproving productivity and decision-making.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Stream custom data",
        "type": "text",
        "content": "To send custom user-defined data from inside a LangGraph node or tool, follow these steps:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Google Cloud",
        "type": "code",
        "content": "pip install langchain-google-vertexai\n# pip install langchain-google-community[...] # For other services\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Structured output",
        "type": "text",
        "content": "Structured output allows agents to return data in a specific, predictable format. Instead of parsing natural language responses, you get structured data in the form of JSON objects, Pydantic models, or dataclasses that your application can directly use.\n\nLangChain’s create_agent handles structured output automatically. The user sets their desired structured output schema, and when the model generates the structured data, it’s captured, validated, and returned in the 'structured_response' key of the agent’s state.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "SageMaker Tracking",
        "type": "code",
        "content": "from langchain_community.callbacks import SageMakerCallbackHandler\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Migrate tocreate_agent",
        "type": "code",
        "content": "config[\"configurable\"]",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Step 5: Wire it together",
        "type": "code",
        "content": "Command[Literal[\"node1\", \"node2\"]]",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Use anonymizers to prevent logging of sensitive data in traces",
        "type": "text",
        "content": "You may want to mask sensitive data to prevent it from being logged to LangSmith. You can create anonymizers and apply them to\nyour graph using configuration. This example will redact anything matching the Social Security Number format XXX-XX-XXXX from traces sent to LangSmith.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/observability",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Observability"
    },
    {
        "title": "Build a basic agent",
        "type": "text",
        "content": "Start by creating a simple agent that can answer questions and call tools. The agent will use Claude Sonnet 4.5 as its language model, a basic weather function as a tool, and a simple prompt to guide its behavior.\n\nFor this example, you will need to set up a Claude (Anthropic) account and get an API key. Then, set the ANTHROPIC_API_KEY environment variable in your terminal.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/quickstart",
        "head_menu_name": "LangChain",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Using in LangGraph",
        "type": "text",
        "content": "With this all in place, we use the in_memory_store in LangGraph. The in_memory_store works hand-in-hand with the checkpointer: the checkpointer saves state to threads, as discussed above, and the in_memory_store allows us to store arbitrary information for access across threads. We compile the graph with both the checkpointer and the in_memory_store as follows.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Approve or reject",
        "type": "text",
        "content": "One of the most common uses of interrupts is to pause before a critical action and ask for approval. For example, you might want to ask a human to approve an API call, a database change, or any other important decision.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Tutorial: Semantic search",
        "type": "text",
        "content": "Learn how to create a searchable knowledge base from your own data using LangChain’s document loaders, embeddings, and vector stores.\nIn this tutorial, you’ll build a search engine over a PDF, enabling retrieval of passages relevant to a query. You’ll also implement a minimal RAG workflow on top of this engine to see how external knowledge can be integrated into LLM reasoning.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/retrieval",
        "head_menu_name": "LangChain",
        "side_menu_name": "Retrieval"
    },
    {
        "title": "Use in production",
        "type": "text",
        "content": "In production, use a checkpointer backed by a database:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Using in LangGraph",
        "type": "text",
        "content": "We can access the memories and use them in our model call.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Code examples",
        "type": "text",
        "content": "Always test code examples before publishing. Never include real API keys or secrets.\n\nRequirements for code examples:\n\nInclude complete, runnable examples that users can copy and execute without errors\n\nUse realistic data instead of placeholder values like “foo” or “example”\n\nShow proper error handling and edge case management\n\nAdd explanatory comments for complex logic\n\nExample of a well-documented function:",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "Overview",
        "type": "code",
        "content": "\"Fetched 10/100 records\"",
        "side_link": "https://docs.langchain.com/oss/python/langchain/streaming",
        "head_menu_name": "LangChain",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Batch",
        "type": "text",
        "content": "Send multiple requests to a model in a batch for more efficient processing.\n\nIn addition to chat models, LangChain provides support for other adjacent technologies, such as embedding models and vector stores. See the integrations page for details.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "3. Environment variables",
        "type": "text",
        "content": "Create a .env file in the root of your project and fill in the necessary API keys. We’ll need to set the LANGSMITH_API_KEY environment variable to the API key you get from LangSmith .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/studio",
        "head_menu_name": "LangChain",
        "side_menu_name": "Studio"
    },
    {
        "title": "Google Cloud",
        "type": "code",
        "content": "langchain-google-community",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Content block reference",
        "type": "text",
        "content": "Content blocks are represented (either when creating a message or accessing the content_blocks property) as a list of typed dictionaries. Each item in the list must adhere to one of the following block types:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Use with chat models",
        "type": "text",
        "content": "Refer to the below guides to learn more:\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Async Support",
        "type": "text",
        "content": "All agentevals evaluators support Python asyncio. For evaluators that use factory functions, async versions are available by adding async after create_ in the function name.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Custom tool name",
        "type": "text",
        "content": "By default, the tool name comes from the function name. Override it when you need something more descriptive:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "Test",
        "type": "text",
        "content": "Agentic applications let an LLM decide its own next steps to solve a problem. That flexibility is powerful, but the model’s black-box nature makes it hard to predict how a tweak in one part of your agent will affect the rest. To build production-ready agents, thorough testing is essential.\n\nThere are a few approaches to testing your agents:\n\nUnit tests exercise small, deterministic pieces of your agent in isolation using in-memory fakes so you can assert exact behavior quickly and deterministically.\n\nIntegration tests test the agent using real network calls to confirm that components work together, credentials and schemas line up, and latency is acceptable.\n\nAgentic applications tend to lean more on integration because they chain multiple components together and must deal with flakiness due to the nondeterministic nature of LLMs.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Development environment",
        "type": "text",
        "content": "Set up a development environment for the package(s) you’re working on.\n\nFor changes to langchain-core :",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Tool calling",
        "type": "text",
        "content": "See the tools guide for details and other options for creating tools.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Delete messages",
        "type": "code",
        "content": "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n\ndef delete_messages(state):\n    return {\"messages\": [RemoveMessage(id=REMOVE_ALL_MESSAGES)]}  \n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Content block reference",
        "type": "text",
        "content": "Output of the executed tool.\n\nPurpose: Provider-specific escape hatch\n\nAlways \"non_standard\"",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Planning",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import TodoListMiddleware\nfrom langchain.messages import HumanMessage\n\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[...],\n    middleware=[TodoListMiddleware()],\n)\n\nresult = agent.invoke({\"messages\": [HumanMessage(\"Help me refactor my codebase\")]})\nprint(result[\"todos\"])  # Array of todo items with status tracking\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Relationship to the LangChain ecosystem",
        "type": "text",
        "content": "Deep agents is built on top of:\n\nDeep agents applications can be deployed via LangSmith Deployment and monitored with LangSmith Observability .",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/overview",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Overview"
    },
    {
        "title": "Data Steps",
        "type": "text",
        "content": "When a step needs to retrieve information from external sources:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "LLM tokens",
        "type": "code",
        "content": "from dataclasses import dataclass\n\nfrom langchain.chat_models import init_chat_model\nfrom langgraph.graph import StateGraph, START\n\n\n@dataclass\nclass MyState:\n    topic: str\n    joke: str = \"\"\n\n\nmodel = init_chat_model(model=\"gpt-4o-mini\")\n\ndef call_model(state: MyState):\n    \"\"\"Call the LLM to generate a joke about a topic\"\"\"\n    # Note that message events are emitted even when the LLM is run using .invoke rather than .stream\n    model_response = model.invoke(  \n        [\n            {\"role\": \"user\", \"content\": f\"Generate a joke about {state.topic}\"}\n        ]\n    )\n    return {\"joke\": model_response.content}\n\ngraph = (\n    StateGraph(MyState)\n    .add_node(call_model)\n    .add_edge(START, \"call_model\")\n    .compile()\n)\n\n# The \"messages\" stream mode returns an iterator of tuples (message_chunk, metadata)\n# where message_chunk is the token streamed by the LLM and metadata is a dictionary\n# with information about the graph node where the LLM was called and other information\nfor message_chunk, metadata in graph.stream(\n    {\"topic\": \"ice cream\"},\n    stream_mode=\"messages\",  \n):\n    if message_chunk.content:\n        print(message_chunk.content, end=\"|\", flush=True)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Static runtime context",
        "type": "text",
        "content": "See Agents for details.\n\nThe Runtime object can be used to access static context and other utilities like the active store and stream writer.\nSee the @[ Runtime ][langgraph.runtime.Runtime] documentation for details.",
        "side_link": "https://docs.langchain.com/oss/python/concepts/context",
        "head_menu_name": "Learn",
        "side_menu_name": "Context"
    },
    {
        "title": "High-level API",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/pregel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Runtime"
    },
    {
        "title": "Task delegation (subagents)",
        "type": "text",
        "content": "The harness allows the main agent to create ephemeral “subagents” for isolated multi-step tasks.\n\nWhy it’s useful:\n\nHow it works:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/harness",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Agent harness"
    },
    {
        "title": "Chat Completions API",
        "type": "text",
        "content": "Certain model providers offer endpoints that are compatible with OpenAI’s Chat Completions API . In such case, you can use ChatOpenAI with a custom base_url to connect to these endpoints.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/chat",
        "head_menu_name": "Integrations",
        "side_menu_name": "Chat models"
    },
    {
        "title": "Stream multiple modes",
        "type": "text",
        "content": "You can specify multiple streaming modes by passing stream mode as a list: stream_mode=[\"updates\", \"custom\"] :",
        "side_link": "https://docs.langchain.com/oss/python/langchain/streaming",
        "head_menu_name": "LangChain",
        "side_menu_name": "Streaming"
    },
    {
        "title": "5. Define end logic",
        "type": "text",
        "content": "The conditional edge function is used to route to the tool node or end based upon whether the LLM made a tool call.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/quickstart",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Get state",
        "type": "text",
        "content": "When interacting with the saved graph state, you must specify a thread identifier . You can view the latest state of the graph by calling graph.get_state(config) . This will return a StateSnapshot object that corresponds to the latest checkpoint associated with the thread ID provided in the config or a checkpoint associated with a checkpoint ID for the thread, if provided.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Actors",
        "type": "text",
        "content": "An actor is a PregelNode . It subscribes to channels, reads data from them, and writes data to them. It can be thought of as an actor in the Pregel algorithm. PregelNodes implement LangChain’s Runnable interface.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/pregel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Runtime"
    },
    {
        "title": "Firestore (Native Mode)",
        "type": "code",
        "content": "pip install langchain-google-firestore\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Amazon OpenSearch Service",
        "type": "code",
        "content": "pip install boto3 requests requests-aws4auth\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Interrupts",
        "type": "code",
        "content": "config={\"configurable\": {\"thread_id\": ...}}",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Amazon Textract",
        "type": "code",
        "content": "from langchain_community.document_loaders import AmazonTextractPDFLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Where to go from here",
        "type": "text",
        "content": "This was an introduction to thinking about building agents with LangGraph. You can extend this foundation with:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Google",
        "type": "code",
        "content": "langchain-google-community",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Connect to your agent",
        "type": "text",
        "content": "Once configured, Agent Chat UI will automatically fetch and display any interrupted threads from your agent.\n\nAgent Chat UI has out-of-the-box support for rendering tool calls and tool result messages. To customize what messages are shown, see Hiding Messages in the Chat .\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/ui",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agent Chat UI"
    },
    {
        "title": "Cloud Storage",
        "type": "text",
        "content": "Load from a directory or a specific file:\n\nSee directory usage example .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Basic Usage",
        "type": "code",
        "content": "memories = in_memory_store.search(namespace_for_memory)\nmemories[-1].dict()\n{'value': {'food_preference': 'I like pizza'},\n 'key': '07e0caf4-1631-47b7-b15f-65515d4c1843',\n 'namespace': ['1', 'memories'],\n 'created_at': '2024-10-02T17:22:31.590602+00:00',\n 'updated_at': '2024-10-02T17:22:31.590605+00:00'}\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Page structure",
        "type": "code",
        "content": "---\ntitle: \"Clear, specific title\"\n---\n",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "Manage short-term memory",
        "type": "text",
        "content": "With short-term memory enabled, long conversations can exceed the LLM’s context window. Common solutions are:\n\nThis allows the agent to keep track of the conversation without exceeding the LLM’s context window.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Message metadata",
        "type": "code",
        "content": "human_msg = HumanMessage(\n    content=\"Hello!\",\n    name=\"alice\",  # Optional: identify different users\n    id=\"msg_123\",  # Optional: unique identifier for tracing\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Stream graph state",
        "type": "text",
        "content": "Use this to stream only the state updates returned by the nodes after each step. The streamed outputs include the name of the node as well as the update.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "PlayWright Browser Toolkit",
        "type": "code",
        "content": "from langchain_community.agent_toolkits import PlayWrightBrowserToolkit\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Vertex AI Vector Search",
        "type": "text",
        "content": "Alias for VectorSearchVectorStore storing documents/index in GCS.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "HuggingFaceInferenceAPIEmbeddings",
        "type": "code",
        "content": "HuggingFaceInferenceAPIEmbeddings",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Microsoft Presidio",
        "type": "code",
        "content": "pip install langchain-experimental openai presidio-analyzer presidio-anonymizer spacy Faker\npython -m spacy download en_core_web_lg\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Trajectory Match Evaluator",
        "type": "text",
        "content": "AgentEvals offers the create_trajectory_match_evaluator function to match your agent’s trajectory against a reference trajectory. There are four modes to choose from:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Rate limiting",
        "type": "code",
        "content": "from langchain_core.rate_limiters import InMemoryRateLimiter\n\nrate_limiter = InMemoryRateLimiter(\n    requests_per_second=0.1,  # 1 request every 10s\n    check_every_n_seconds=0.1,  # Check every 100ms whether allowed to make a request\n    max_bucket_size=10,  # Controls the maximum burst size.\n)\n\nmodel = init_chat_model(\n    model=\"gpt-5\",\n    model_provider=\"openai\",\n    rate_limiter=rate_limiter  \n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "4. Create a LangGraph config file",
        "type": "code",
        "content": "my-app/\n├── src\n│   └── agent.py\n├── .env\n└── langgraph.json\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/studio",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Studio"
    },
    {
        "title": "Prebuilt memory tools",
        "type": "text",
        "content": "LangMem is a LangChain-maintained library that offers tools for managing long-term memories in your agent. See the LangMem documentation for usage examples.\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Testing individual nodes and edges",
        "type": "code",
        "content": "import pytest\n\nfrom typing_extensions import TypedDict\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.checkpoint.memory import MemorySaver\n\ndef create_graph() -> StateGraph:\n    class MyState(TypedDict):\n        my_key: str\n\n    graph = StateGraph(MyState)\n    graph.add_node(\"node1\", lambda state: {\"my_key\": \"hello from node1\"})\n    graph.add_node(\"node2\", lambda state: {\"my_key\": \"hello from node2\"})\n    graph.add_edge(START, \"node1\")\n    graph.add_edge(\"node1\", \"node2\")\n    graph.add_edge(\"node2\", END)\n    return graph\n\ndef test_individual_node_execution() -> None:\n    # Will be ignored in this example\n    checkpointer = MemorySaver()\n    graph = create_graph()\n    compiled_graph = graph.compile(checkpointer=checkpointer)\n    # Only invoke node 1\n    result = compiled_graph.nodes[\"node1\"].invoke(\n        {\"my_key\": \"initial_value\"},\n    )\n    assert result[\"my_key\"] == \"hello from node1\"\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/test",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Test"
    },
    {
        "title": "3. Environment variables",
        "type": "text",
        "content": "Create a .env file in the root of your project and fill in the necessary API keys. We’ll need to set the LANGSMITH_API_KEY environment variable to the API key you get from LangSmith .",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/studio",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Studio"
    },
    {
        "title": "How to propose changes to the documentation",
        "type": "text",
        "content": "With a large userbase, it can be hard for our small team to keep up with all the feature requests and bug fixes. If you have the skills and time, we would love your help!",
        "side_link": "https://docs.langchain.com/oss/python/contributing/overview",
        "head_menu_name": "Contribute",
        "side_menu_name": "Overview"
    },
    {
        "title": "Delete messages",
        "type": "code",
        "content": "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n\ndef delete_messages(state):\n    return {\"messages\": [RemoveMessage(id=REMOVE_ALL_MESSAGES)]}  \n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Prompt caching (Anthropic)",
        "type": "text",
        "content": "The harness enables Anthropic’s prompt caching feature to reduce redundant token processing.\n\nHow it works:\n\nWhy it’s useful:\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/harness",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Agent harness"
    },
    {
        "title": "Context management",
        "type": "text",
        "content": "File system tools ( ls , read_file , write_file , edit_file ) allow agents to offload large context to memory, preventing context window overflow and enabling work with variable-length tool results.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/overview",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Overview"
    },
    {
        "title": "Trim messages",
        "type": "code",
        "content": "from langchain_core.messages.utils import (\n    trim_messages,  \n    count_tokens_approximately  \n)\nfrom langchain.chat_models import init_chat_model\nfrom langgraph.graph import StateGraph, START, MessagesState\n\nmodel = init_chat_model(\"claude-sonnet-4-5-20250929\")\nsummarization_model = model.bind(max_tokens=128)\n\ndef call_model(state: MessagesState):\n    messages = trim_messages(  \n        state[\"messages\"],\n        strategy=\"last\",\n        token_counter=count_tokens_approximately,\n        max_tokens=128,\n        start_on=\"human\",\n        end_on=(\"human\", \"tool\"),\n    )\n    response = model.invoke(messages)\n    return {\"messages\": [response]}\n\ncheckpointer = InMemorySaver()\nbuilder = StateGraph(MessagesState)\nbuilder.add_node(call_model)\nbuilder.add_edge(START, \"call_model\")\ngraph = builder.compile(checkpointer=checkpointer)\n\nconfig = {\"configurable\": {\"thread_id\": \"1\"}}\ngraph.invoke({\"messages\": \"hi, my name is bob\"}, config)\ngraph.invoke({\"messages\": \"write a short poem about cats\"}, config)\ngraph.invoke({\"messages\": \"now do the same but for dogs\"}, config)\nfinal_response = graph.invoke({\"messages\": \"what's my name?\"}, config)\n\nfinal_response[\"messages\"][-1].pretty_print()\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Use the same thread ID",
        "type": "text",
        "content": "When resuming, you must use the same config with the same thread_id :",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/human-in-the-loop",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Install",
        "type": "code",
        "content": "pip install -U langgraph\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/overview",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Overview"
    },
    {
        "title": "Delete messages",
        "type": "text",
        "content": "You can delete messages from the graph state to manage the message history.\n\nThis is useful when you want to remove specific messages or clear the entire message history.\n\nTo delete messages from the graph state, you can use the RemoveMessage .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "See also",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Prebuilt middleware",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import (\n    PIIMiddleware,\n    SummarizationMiddleware,\n    HumanInTheLoopMiddleware\n)\n\n\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    tools=[read_email, send_email],\n    middleware=[\n        PIIMiddleware(\"email\", strategy=\"redact\", apply_to_input=True),\n        PIIMiddleware(\n            \"phone_number\",\n            detector=(\n                r\"(?:\\+?\\d{1,3}[\\s.-]?)?\"\n                r\"(?:\\(?\\d{2,4}\\)?[\\s.-]?)?\"\n                r\"\\d{3,4}[\\s.-]?\\d{4}\"\n\t\t\t),\n\t\t\tstrategy=\"block\"\n        ),\n        SummarizationMiddleware(\n            model=\"claude-sonnet-4-5-20250929\",\n            max_tokens_before_summary=500\n        ),\n        HumanInTheLoopMiddleware(\n            interrupt_on={\n                \"send_email\": {\n                    \"allowed_decisions\": [\"approve\", \"edit\", \"reject\"]\n                }\n            }\n        ),\n    ]\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "pip install -qU langchain-ibm\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Serialization withpickle",
        "type": "text",
        "content": "If you want to fallback to pickle for objects not currently supported by our msgpack encoder (such as Pandas dataframes),\nyou can use the pickle_fallback argument of the JsonPlusSerializer :",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Prompted output removed",
        "type": "text",
        "content": "Prompted output is no longer supported via the response_format argument. Compared to strategies\nlike artificial tool calling and provider native structured output, prompted output has not proven to be particularly reliable.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Namespace",
        "type": "code",
        "content": "langchain.chat_models",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Tailor configurations by risk",
        "type": "code",
        "content": "interrupt_on = {\n    # High risk: full control (approve, edit, reject)\n    \"delete_file\": {\"allowed_decisions\": [\"approve\", \"edit\", \"reject\"]},\n    \"send_email\": {\"allowed_decisions\": [\"approve\", \"edit\", \"reject\"]},\n\n    # Medium risk: no editing allowed\n    \"write_file\": {\"allowed_decisions\": [\"approve\", \"reject\"]},\n\n    # Low risk: no interrupts\n    \"read_file\": False,\n    \"list_files\": False,\n}\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/human-in-the-loop",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Text prompts",
        "type": "text",
        "content": "Text prompts are strings - ideal for straightforward generation tasks where you don’t need to retain conversation history.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Key Concepts",
        "type": "text",
        "content": "To deploy using the LangSmith, the following information should be provided:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/application-structure",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Application structure"
    },
    {
        "title": "Featured providers",
        "type": "text",
        "content": "While all these LangChain classes support the indicated advanced feature , you may have to open the provider-specific documentation to learn which hosted models or backends support the feature.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/chat",
        "head_menu_name": "Integrations",
        "side_menu_name": "Chat models"
    },
    {
        "title": "Rules of interrupts",
        "type": "text",
        "content": "When execution resumes (after you provide the requested input), the runtime restarts the entire node from the beginning—it does not resume from the exact line where interrupt was called. This means any code that ran before the interrupt will execute again. Because of this, there’s a few important rules to follow when working with interrupts to ensure they behave as expected.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Basic Usage",
        "type": "text",
        "content": "We use the store.put method to save memories to our namespace in the store. When we do this, we specify the namespace, as defined above, and a key-value pair for the memory: the key is simply a unique identifier for the memory ( memory_id ) and the value (a dictionary) is the memory itself.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Defining state via middleware",
        "type": "text",
        "content": "Use middleware to define custom state when your custom state needs to be accessed by specific middleware hooks and tools attached to said middleware.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Usage",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langgraph.checkpoint.memory import InMemorySaver  \n\n\nagent = create_agent(\n    \"gpt-5\",\n    [get_user_info],\n    checkpointer=InMemorySaver(),  \n)\n\nagent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"Hi! My name is Bob.\"}]},\n    {\"configurable\": {\"thread_id\": \"1\"}},  \n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Local development",
        "type": "code",
        "content": "# Create a new Agent Chat UI project\nnpx create-agent-chat-app --project-name my-chat-ui\ncd my-chat-ui\n\n# Install dependencies and start\npnpm install\npnpm dev\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/ui",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Agent Chat UI"
    },
    {
        "title": "Add policy hooks",
        "type": "text",
        "content": "Enforce enterprise rules by subclassing or wrapping a backend.\n\nBlock writes/edits under selected prefixes (subclass):",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Multimodal",
        "type": "code",
        "content": "response = model.invoke(\"Create a picture of a cat\")\nprint(response.content_blocks)\n# [\n#     {\"type\": \"text\", \"text\": \"Here's a picture of a cat\"},\n#     {\"type\": \"image\", \"base64\": \"...\", \"mime_type\": \"image/jpeg\"},\n# ]\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Bing Search API",
        "type": "text",
        "content": "Microsoft Bing , commonly referred to as Bing or Bing Search ,\nis a web search engine owned and operated by Microsoft .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Parameters",
        "type": "code",
        "content": "model = init_chat_model(\n    \"claude-sonnet-4-5-20250929\",\n    # Kwargs passed to the model:\n    temperature=0.7,\n    timeout=30,\n    max_tokens=1000,\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Decorator-based middleware",
        "type": "code",
        "content": "from langchain.agents.middleware import before_model, after_model, wrap_model_call\nfrom langchain.agents.middleware import AgentState, ModelRequest, ModelResponse, dynamic_prompt\nfrom langchain.messages import AIMessage\nfrom langchain.agents import create_agent\nfrom langgraph.runtime import Runtime\nfrom typing import Any, Callable\n\n\n# Node-style: logging before model calls\n@before_model\ndef log_before_model(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n    print(f\"About to call model with {len(state['messages'])} messages\")\n    return None\n\n# Node-style: validation after model calls\n@after_model(can_jump_to=[\"end\"])\ndef validate_output(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n    last_message = state[\"messages\"][-1]\n    if \"BLOCKED\" in last_message.content:\n        return {\n            \"messages\": [AIMessage(\"I cannot respond to that request.\")],\n            \"jump_to\": \"end\"\n        }\n    return None\n\n# Wrap-style: retry logic\n@wrap_model_call\ndef retry_model(\n    request: ModelRequest,\n    handler: Callable[[ModelRequest], ModelResponse],\n) -> ModelResponse:\n    for attempt in range(3):\n        try:\n            return handler(request)\n        except Exception as e:\n            if attempt == 2:\n                raise\n            print(f\"Retry {attempt + 1}/3 after error: {e}\")\n\n# Wrap-style: dynamic prompts\n@dynamic_prompt\ndef personalized_prompt(request: ModelRequest) -> str:\n    user_id = request.runtime.context.get(\"user_id\", \"guest\")\n    return f\"You are a helpful assistant for user {user_id}. Be concise and friendly.\"\n\n# Use decorators in agent\nagent = create_agent(\n    model=\"gpt-4o\",\n    middleware=[log_before_model, validate_output, retry_model, personalized_prompt],\n    tools=[...],\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "7. Test the API",
        "type": "code",
        "content": "from langgraph_sdk import get_client\nimport asyncio\n\nclient = get_client(url=\"http://localhost:2024\")\n\nasync def main():\n    async for chunk in client.runs.stream(\n        None,  # Threadless run\n        \"agent\", # Name of assistant. Defined in langgraph.json.\n        input={\n        \"messages\": [{\n            \"role\": \"human\",\n            \"content\": \"What is LangGraph?\",\n            }],\n        },\n    ):\n        print(f\"Receiving new event of type: {chunk.event}...\")\n        print(chunk.data)\n        print(\"\\n\\n\")\n\nasyncio.run(main())\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/local-server",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Local server"
    },
    {
        "title": "langchain-classic",
        "type": "code",
        "content": "pip install langchain-classic\n",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Advanced schema definition",
        "type": "code",
        "content": "from pydantic import BaseModel, Field\nfrom typing import Literal\n\nclass WeatherInput(BaseModel):\n    \"\"\"Input for weather queries.\"\"\"\n    location: str = Field(description=\"City name or coordinates\")\n    units: Literal[\"celsius\", \"fahrenheit\"] = Field(\n        default=\"celsius\",\n        description=\"Temperature unit preference\"\n    )\n    include_forecast: bool = Field(\n        default=False,\n        description=\"Include 5-day forecast\"\n    )\n\n@tool(args_schema=WeatherInput)\ndef get_weather(location: str, units: str = \"celsius\", include_forecast: bool = False) -> str:\n    \"\"\"Get current weather and optional forecast.\"\"\"\n    temp = 22 if units == \"celsius\" else 72\n    result = f\"Current weather in {location}: {temp} degrees {units[0].upper()}\"\n    if include_forecast:\n        result += \"\\nNext 5 days: Sunny\"\n    return result\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "Getting started",
        "type": "code",
        "content": "import pytest\n\nfrom typing_extensions import TypedDict\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.checkpoint.memory import MemorySaver\n\ndef create_graph() -> StateGraph:\n    class MyState(TypedDict):\n        my_key: str\n\n    graph = StateGraph(MyState)\n    graph.add_node(\"node1\", lambda state: {\"my_key\": \"hello from node1\"})\n    graph.add_node(\"node2\", lambda state: {\"my_key\": \"hello from node2\"})\n    graph.add_edge(START, \"node1\")\n    graph.add_edge(\"node1\", \"node2\")\n    graph.add_edge(\"node2\", END)\n    return graph\n\ndef test_basic_agent_execution() -> None:\n    checkpointer = MemorySaver()\n    graph = create_graph()\n    compiled_graph = graph.compile(checkpointer=checkpointer)\n    result = compiled_graph.invoke(\n        {\"my_key\": \"initial_value\"},\n        config={\"configurable\": {\"thread_id\": \"1\"}}\n    )\n    assert result[\"my_key\"] == \"hello from node2\"\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/test",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Test"
    },
    {
        "title": "Google Drive",
        "type": "text",
        "content": "Tools for interacting with Google Drive.\n\nInstall required packages:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Azure AI Document Intelligence",
        "type": "code",
        "content": "pip install azure-ai-documentintelligence\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Amazon API Gateway",
        "type": "text",
        "content": "Amazon API Gateway is a fully managed service that makes it easy for\ndevelopers to create, publish, maintain, monitor, and secure APIs at any scale. APIs act as the “front door”\nfor applications to access data, business logic, or functionality from your backend services. Using API Gateway , you can create RESTful APIs and WebSocket APIs that enable real-time two-way communication\napplications. API Gateway supports containerized and serverless workloads, as well as web applications.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Image captions",
        "type": "code",
        "content": "from langchain_community.document_loaders import ImageCaptionLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Web Browsing",
        "type": "text",
        "content": "The following table shows tools that can be used to automate tasks in web browsers:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/tools",
        "head_menu_name": "Integrations",
        "side_menu_name": "Tools and toolkits"
    },
    {
        "title": "Log to a project",
        "type": "code",
        "content": "import langsmith as ls\n\nwith ls.tracing_context(project_name=\"email-agent-test\", enabled=True):\n    response = agent.invoke({\n        \"messages\": [{\"role\": \"user\", \"content\": \"Send a welcome email\"}]\n    })\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/observability",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Observability"
    },
    {
        "title": "Serialize standard content",
        "type": "code",
        "content": "export LC_OUTPUT_VERSION=v1\n",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Recording & Replaying HTTP Calls",
        "type": "code",
        "content": "[pytest]\nmarkers =\n    vcr: record/replay HTTP via VCR\naddopts = --record-mode=once\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "pip install -qU langchain-openai\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Get state",
        "type": "code",
        "content": "# get the latest state snapshot\nconfig = {\"configurable\": {\"thread_id\": \"1\"}}\ngraph.get_state(config)\n\n# get a state snapshot for a specific checkpoint_id\nconfig = {\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1ef663ba-28fe-6528-8002-5a559208592c\"}}\ngraph.get_state(config)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Seamless with LangChain v1",
        "type": "text",
        "content": "LangChain’s create_agent runs on LangGraph. Use LangChain for a fast start; drop to LangGraph for custom orchestration.",
        "side_link": "https://docs.langchain.com/oss/python/releases/langgraph-v1",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Invocation",
        "type": "text",
        "content": "A chat model must be invoked to generate an output. There are three primary invocation methods, each suited to different use cases.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Stream subgraph outputs",
        "type": "text",
        "content": "To include outputs from subgraphs in the streamed outputs, you can set subgraphs=True in the .stream() method of the parent graph. This will stream outputs from both the parent graph and any subgraphs.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Amazon Comprehend Moderation Chain",
        "type": "text",
        "content": "Amazon Comprehend is a natural-language processing (NLP) service that\nuses machine learning to uncover valuable insights and connections in text.\n\nWe need to install the boto3 and nltk libraries.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Interrupt decision types",
        "type": "text",
        "content": "When editing tool arguments, make changes conservatively. Significant modifications to the original arguments may cause the model to re-evaluate its approach and potentially execute the tool multiple times or take unexpected actions.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/human-in-the-loop",
        "head_menu_name": "LangChain",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Migrate tocreate_agent",
        "type": "code",
        "content": "langchain.agents.create_agent",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "HuggingFaceBgeEmbeddings",
        "type": "code",
        "content": "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Subgraphs",
        "type": "text",
        "content": "This guide explains the mechanics of using subgraphs. A subgraph is a graph that is used as a node in another graph.\n\nSubgraphs are useful for:\n\nWhen adding subgraphs, you need to define how the parent graph and the subgraph communicate:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-subgraphs",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Subgraphs"
    },
    {
        "title": "Azure Container Apps dynamic sessions",
        "type": "code",
        "content": "from langchain_azure_dynamic_sessions import SessionsPythonREPLTool\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "LangSmith Integration",
        "type": "code",
        "content": "from langsmith import Client\nfrom agentevals.trajectory.llm import create_trajectory_llm_as_judge, TRAJECTORY_ACCURACY_PROMPT\n\nclient = Client()\n\ntrajectory_evaluator = create_trajectory_llm_as_judge(\n    model=\"openai:o3-mini\",\n    prompt=TRAJECTORY_ACCURACY_PROMPT,\n)\n\ndef run_agent(inputs):\n    \"\"\"Your agent function that returns trajectory messages.\"\"\"\n    return agent.invoke(inputs)[\"messages\"]\n\nexperiment_results = client.evaluate(\n    run_agent,\n    data=\"your_dataset_name\",\n    evaluators=[trajectory_evaluator]\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Runtime context",
        "type": "text",
        "content": "The old config[\"configurable\"] pattern still works for backward compatibility, but using the new context parameter is recommended for new applications or applications migrating to v1.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "FilesystemBackend (local disk)",
        "type": "code",
        "content": "from deepagents.backends import FilesystemBackend\n\nagent = create_deep_agent(\n    backend=FilesystemBackend(root_dir=\"/Users/nh/Desktop/\")\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Models",
        "type": "text",
        "content": "LLMs are powerful AI tools that can interpret and generate text like humans. They’re versatile enough to write content, translate languages, summarize, and answer questions without needing specialized training for each task.\n\nIn addition to text generation, many models support:\n\nModels are the reasoning engine of agents . They drive the agent’s decision-making process, determining which tools to call, how to interpret results, and when to provide a final answer.\n\nThe quality and capabilities of the model you choose directly impact your agent’s reliability and performance. Different models excel at different tasks - some are better at following complex instructions, others at structured reasoning, and some support larger context windows for handling more information.\n\nLangChain’s standard model interfaces give you access to many different provider integrations, which makes it easy to experiment with and switch between models to find the best fit for your case.\n\nFor provider-specific integration information and capabilities, see the provider’s chat model page .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Stream subgraph outputs",
        "type": "code",
        "content": "(\"parent_node:<task_id>\", \"child_node:<task_id>\")",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "PII detection",
        "type": "text",
        "content": "See the middleware documentation for complete details on PII detection capabilities.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/guardrails",
        "head_menu_name": "LangChain",
        "side_menu_name": "Guardrails"
    },
    {
        "title": "Access",
        "type": "text",
        "content": "When creating an agent with create_agent , you can specify a context_schema to define the structure of the context stored in the agent Runtime .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/runtime",
        "head_menu_name": "LangChain",
        "side_menu_name": "Runtime"
    },
    {
        "title": "Defining tools",
        "type": "text",
        "content": "Each tool needs a clear name, description, argument names, and argument descriptions. These aren’t just metadata—they guide the model’s reasoning about when and how to use the tool.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "import getpass\nimport os\n\nif not os.environ.get(\"OPENAI_API_KEY\"):\n  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n\nfrom langchain_openai import OpenAIEmbeddings\n\nembeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Build a real-world agent",
        "type": "text",
        "content": "Set up your language model with the right parameters for your use case:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/quickstart",
        "head_menu_name": "LangChain",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Partial execution",
        "type": "code",
        "content": "import pytest\n\nfrom typing_extensions import TypedDict\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.checkpoint.memory import MemorySaver\n\ndef create_graph() -> StateGraph:\n    class MyState(TypedDict):\n        my_key: str\n\n    graph = StateGraph(MyState)\n    graph.add_node(\"node1\", lambda state: {\"my_key\": \"hello from node1\"})\n    graph.add_node(\"node2\", lambda state: {\"my_key\": \"hello from node2\"})\n    graph.add_node(\"node3\", lambda state: {\"my_key\": \"hello from node3\"})\n    graph.add_node(\"node4\", lambda state: {\"my_key\": \"hello from node4\"})\n    graph.add_edge(START, \"node1\")\n    graph.add_edge(\"node1\", \"node2\")\n    graph.add_edge(\"node2\", \"node3\")\n    graph.add_edge(\"node3\", \"node4\")\n    graph.add_edge(\"node4\", END)\n    return graph\n\ndef test_partial_execution_from_node2_to_node3() -> None:\n    checkpointer = MemorySaver()\n    graph = create_graph()\n    compiled_graph = graph.compile(checkpointer=checkpointer)\n    compiled_graph.update_state(\n        config={\n          \"configurable\": {\n            \"thread_id\": \"1\"\n          }\n        },\n        # The state passed into node 2 - simulating the state at\n        # the end of node 1\n        values={\"my_key\": \"initial_value\"},\n        # Update saved state as if it came from node 1\n        # Execution will resume at node 2\n        as_node=\"node1\",\n    )\n    result = compiled_graph.invoke(\n        # Resume execution by passing None\n        None,\n        config={\"configurable\": {\"thread_id\": \"1\"}},\n        # Stop after node 3 so that node 4 doesn't run\n        interrupt_after=\"node3\",\n    )\n    assert result[\"my_key\"] == \"hello from node3\"\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/test",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Test"
    },
    {
        "title": "Checkpoints",
        "type": "code",
        "content": "{'foo': 'a', 'bar': ['a']}",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Tool calling",
        "type": "text",
        "content": "In tool calling , one agent (the “ controller ”) treats other agents as tools to be invoked when needed. The controller manages orchestration, while tool agents perform specific tasks and return results.\n\nFlow:\n\nAgents used as tools are generally not expected to continue conversation with the user.\nTheir role is to perform a task and return results to the controller agent.\nIf you need subagents to be able to converse with the user, use handoffs instead.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/multi-agent",
        "head_menu_name": "LangChain",
        "side_menu_name": "Multi-agent"
    },
    {
        "title": "Custom RAG Agent",
        "type": "text",
        "content": "Build a RAG agent using LangGraph primitives for fine-grained control.",
        "side_link": "https://docs.langchain.com/oss/python/learn",
        "head_menu_name": "Learn",
        "side_menu_name": "Learn"
    },
    {
        "title": "Azure Cognitive Services",
        "type": "code",
        "content": "from langchain_community.agent_toolkits import AzureCognitiveServicesToolkit\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Basic configuration",
        "type": "code",
        "content": "{\"allowed_decisions\": [...]}",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/human-in-the-loop",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Add short-term memory",
        "type": "text",
        "content": "Short-term memory (thread-level persistence ) enables agents to track multi-turn conversations. To add short-term memory:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Bedrock Converse",
        "type": "text",
        "content": "AWS Bedrock maintains a Converse API that provides a unified conversational interface for Bedrock models. This API does not\nyet support custom models. You can see a list of all models that are supported here .\n\nWe recommend the Converse API for users who do not need to use custom models. It can be accessed using ChatBedrockConverse .\n\nSee a usage example .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "See also",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/releases/langgraph-v1",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Streaming",
        "type": "text",
        "content": "LangGraph implements a streaming system to surface real-time updates. Streaming is crucial for enhancing the responsiveness of applications built on LLMs. By displaying output progressively, even before a complete response is ready, streaming significantly improves user experience (UX), particularly when dealing with the latency of LLMs.\n\nWhat’s possible with LangGraph streaming:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Parameters",
        "type": "text",
        "content": "Each chat model integration may have additional params used to control provider-specific functionality. For example, ChatOpenAI has use_responses_api to dictate whether to use the OpenAI Responses or Completions API.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Google Translate",
        "type": "code",
        "content": "langchain-google-community",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Stream subgraph outputs",
        "type": "code",
        "content": "from typing_extensions import TypedDict\nfrom langgraph.graph.state import StateGraph, START\n\n# Define subgraph\nclass SubgraphState(TypedDict):\n    foo: str\n    bar: str\n\ndef subgraph_node_1(state: SubgraphState):\n    return {\"bar\": \"bar\"}\n\ndef subgraph_node_2(state: SubgraphState):\n    # note that this node is using a state key ('bar') that is only available in the subgraph\n    # and is sending update on the shared state key ('foo')\n    return {\"foo\": state[\"foo\"] + state[\"bar\"]}\n\nsubgraph_builder = StateGraph(SubgraphState)\nsubgraph_builder.add_node(subgraph_node_1)\nsubgraph_builder.add_node(subgraph_node_2)\nsubgraph_builder.add_edge(START, \"subgraph_node_1\")\nsubgraph_builder.add_edge(\"subgraph_node_1\", \"subgraph_node_2\")\nsubgraph = subgraph_builder.compile()\n\n# Define parent graph\nclass ParentState(TypedDict):\n    foo: str\n\ndef node_1(state: ParentState):\n    return {\"foo\": \"hi! \" + state[\"foo\"]}\n\nbuilder = StateGraph(ParentState)\nbuilder.add_node(\"node_1\", node_1)\nbuilder.add_node(\"node_2\", subgraph)\nbuilder.add_edge(START, \"node_1\")\nbuilder.add_edge(\"node_1\", \"node_2\")\ngraph = builder.compile()\n\nfor chunk in graph.stream(\n    {\"foo\": \"foo\"},\n    stream_mode=\"updates\",\n    subgraphs=True, \n):\n    print(chunk)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-subgraphs",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Subgraphs"
    },
    {
        "title": "Structured outputs",
        "type": "code",
        "content": "from pydantic import BaseModel, Field\n\nclass Movie(BaseModel):\n    \"\"\"A movie with details.\"\"\"\n    title: str = Field(..., description=\"The title of the movie\")\n    year: int = Field(..., description=\"The year the movie was released\")\n    director: str = Field(..., description=\"The director of the movie\")\n    rating: float = Field(..., description=\"The movie's rating out of 10\")\n\nmodel_with_structure = model.with_structured_output(Movie, include_raw=True)  \nresponse = model_with_structure.invoke(\"Provide details about the movie Inception\")\nresponse\n# {\n#     \"raw\": AIMessage(...),\n#     \"parsed\": Movie(title=..., year=..., ...),\n#     \"parsing_error\": None,\n# }\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Custom MCP servers",
        "type": "text",
        "content": "To create your own MCP servers, you can use the mcp library. This library provides a simple way to define tools and run them as servers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/mcp",
        "head_menu_name": "LangChain",
        "side_menu_name": "Model Context Protocol (MCP)"
    },
    {
        "title": "Custom MCP servers",
        "type": "code",
        "content": "from mcp.server.fastmcp import FastMCP\n\nmcp = FastMCP(\"Weather\")\n\n@mcp.tool()\nasync def get_weather(location: str) -> str:\n    \"\"\"Get weather for location.\"\"\"\n    return \"It's always sunny in New York\"\n\nif __name__ == \"__main__\":\n    mcp.run(transport=\"streamable-http\")\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/mcp",
        "head_menu_name": "LangChain",
        "side_menu_name": "Model Context Protocol (MCP)"
    },
    {
        "title": "Vertex AI Vector Search",
        "type": "code",
        "content": "pip install langchain-google-vertexai\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Planning middleware",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import TodoListMiddleware\n\n# TodoListMiddleware is included by default in create_deep_agent\n# You can customize it if building a custom agent\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    # Custom planning instructions can be added via middleware\n    middleware=[\n        TodoListMiddleware(\n            system_prompt=\"Use the write_todos tool to...\"  # Optional: Custom addition to the system prompt\n        ),\n    ],\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/middleware",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Middleware"
    },
    {
        "title": "PlayWright Browser individual tools",
        "type": "code",
        "content": "from langchain_community.tools.playwright import ClickTool\nfrom langchain_community.tools.playwright import CurrentWebPageTool\nfrom langchain_community.tools.playwright import ExtractHyperlinksTool\nfrom langchain_community.tools.playwright import ExtractTextTool\nfrom langchain_community.tools.playwright import GetElementsTool\nfrom langchain_community.tools.playwright import NavigateTool\nfrom langchain_community.tools.playwright import NavigateBackTool\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Create multimodal messages",
        "type": "code",
        "content": "from langchain.messages import HumanMessage\n\nmessage = HumanMessage(content_blocks=[\n    {\"type\": \"text\", \"text\": \"Describe this image.\"},\n    {\"type\": \"image\", \"url\": \"https://example.com/image.jpg\"},\n])\nres = model.invoke([message])\n",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "PII detection",
        "type": "text",
        "content": "Detect and handle Personally Identifiable Information in conversations.\n\nPerfect for:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Model",
        "type": "text",
        "content": "Different models have different strengths, costs, and context windows. Select the right model for the task at hand, which\nmight change during an agent run.\n\nUse different models based on conversation length from State:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Custom MCP servers",
        "type": "text",
        "content": "Use the following reference implementations to test your agent with MCP tool servers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/mcp",
        "head_menu_name": "LangChain",
        "side_menu_name": "Model Context Protocol (MCP)"
    },
    {
        "title": "Wrong subagent being selected",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "YouTube Audio Loader",
        "type": "code",
        "content": "pip install yt_dlp pydub librosa langchain-community # Requires langchain-community\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "from langchain_mongodb import MongoDBAtlasVectorSearch\n\nvector_store = MongoDBAtlasVectorSearch(\n    embedding=embeddings,\n    collection=MONGODB_COLLECTION,\n    index_name=ATLAS_VECTOR_SEARCH_INDEX_NAME,\n    relevance_score_fn=\"cosine\",\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Short-term vs. long-term filesystem",
        "type": "code",
        "content": "use_longterm_memory=True",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/middleware",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Use in production",
        "type": "text",
        "content": "You need to call checkpointer.setup() the first time you’re using Redis checkpointer",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "from langchain_azure_ai.vectorstores.azure_cosmos_db_no_sql import (\n    AzureCosmosDBNoSqlVectorSearch,\n)\nvector_search = AzureCosmosDBNoSqlVectorSearch.from_documents(\n    documents=docs,\n    embedding=openai_embeddings,\n    cosmos_client=cosmos_client,\n    database_name=database_name,\n    container_name=container_name,\n    vector_embedding_policy=vector_embedding_policy,\n    full_text_policy=full_text_policy,\n    indexing_policy=indexing_policy,\n    cosmos_container_properties=cosmos_container_properties,\n    cosmos_database_properties={},\n    full_text_search_enabled=True,\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Summarize messages",
        "type": "text",
        "content": "The problem with trimming or removing messages, as shown above, is that you may lose information from culling of the message queue. Because of this, some applications benefit from a more sophisticated approach of summarizing the message history using a chat model.\n\nPrompting and orchestration logic can be used to summarize the message history. For example, in LangGraph you can extend the MessagesState to include a summary key:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Dropped Python 3.9 support",
        "type": "text",
        "content": "All LangChain packages now require Python 3.10 or higher . Python 3.9 reached end of life in October 2025.\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langgraph-v1",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Initialize a model",
        "type": "code",
        "content": "import os\nfrom langchain.chat_models import init_chat_model\n\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n\nmodel = init_chat_model(\"gpt-4.1\")\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "View subgraph state",
        "type": "code",
        "content": "graph.get_state(config)",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-subgraphs",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Subgraphs"
    },
    {
        "title": "Dictionary format",
        "type": "code",
        "content": "messages = [\n    {\"role\": \"system\", \"content\": \"You are a poetry expert\"},\n    {\"role\": \"user\", \"content\": \"Write a haiku about spring\"},\n    {\"role\": \"assistant\", \"content\": \"Cherry blossoms bloom...\"}\n]\nresponse = model.invoke(messages)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Zilliz",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Additional resources",
        "type": "code",
        "content": "langchain-mcp-adapters",
        "side_link": "https://docs.langchain.com/oss/python/langchain/mcp",
        "head_menu_name": "LangChain",
        "side_menu_name": "Model Context Protocol (MCP)"
    },
    {
        "title": "Azure AI Document Intelligence",
        "type": "code",
        "content": "from langchain.document_loaders import AzureAIDocumentIntelligenceLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Context still getting bloated",
        "type": "text",
        "content": "Problem : Context fills up despite using subagents.\n\nSolutions :\n\nInstruct subagent to return concise results:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Access memory",
        "type": "text",
        "content": "You can access and modify the short-term memory (state) of an agent in several ways:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "LLM-as-Judge Evaluator",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.tools import tool\nfrom langchain.messages import HumanMessage, AIMessage, ToolMessage\nfrom agentevals.trajectory.llm import create_trajectory_llm_as_judge, TRAJECTORY_ACCURACY_PROMPT\n\n\n@tool\ndef get_weather(city: str):\n    \"\"\"Get weather information for a city.\"\"\"\n    return f\"It's 75 degrees and sunny in {city}.\"\n\nagent = create_agent(\"gpt-4o\", tools=[get_weather])\n\nevaluator = create_trajectory_llm_as_judge(  \n    model=\"openai:o3-mini\",  \n    prompt=TRAJECTORY_ACCURACY_PROMPT,  \n)  \n\ndef test_trajectory_quality():\n    result = agent.invoke({\n        \"messages\": [HumanMessage(content=\"What's the weather in Seattle?\")]\n    })\n\n    evaluation = evaluator(\n        outputs=result[\"messages\"],\n    )\n    # {\n    #     'key': 'trajectory_accuracy',\n    #     'score': True,\n    #     'comment': 'The provided agent trajectory is reasonable...'\n    # }\n    assert evaluation[\"score\"] is True\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Token usage",
        "type": "text",
        "content": "A number of model providers return token usage information as part of the invocation response. When available, this information will be included on the AIMessage objects produced by the corresponding model. For more details, see the messages guide.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Reliability, by default",
        "type": "text",
        "content": "Durable execution with checkpointing, persistence, streaming, and human-in-the-loop continues to be first-class.",
        "side_link": "https://docs.langchain.com/oss/python/releases/langgraph-v1",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Install",
        "type": "code",
        "content": "pip install langchain-mcp-adapters\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/mcp",
        "head_menu_name": "LangChain",
        "side_menu_name": "Model Context Protocol (MCP)"
    },
    {
        "title": "Protocol reference",
        "type": "code",
        "content": "edit(file_path: str, old_string: str, new_string: str, replace_all: bool = False) -> EditResult",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Length-based",
        "type": "text",
        "content": "An intuitive strategy is to split documents based on their length. This simple yet effective approach ensures that each chunk doesn’t exceed a specified size limit. Key benefits of length-based splitting:\n\nTypes of length-based splitting:\n\nExample implementation using LangChain’s CharacterTextSplitter with token-based splitting:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/splitters",
        "head_menu_name": "Integrations",
        "side_menu_name": "Text splitters"
    },
    {
        "title": "Basic usage",
        "type": "text",
        "content": "Models can be utilized in two ways:\n\nThe same model interface works in both contexts, which gives you the flexibility to start simple and scale up to more complex agent-based workflows as needed.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Listing files",
        "type": "code",
        "content": "agent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"List all files\"}]\n})\n\n# Example output:\n# Transient files:\n# - /draft.txt\n# - /temp_notes.txt\n#\n# Long-term files:\n# - /memories/user_preferences.txt\n# - /memories/project_status.txt\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Provider strategy",
        "type": "code",
        "content": "class ProviderStrategy(Generic[SchemaT]):\n    schema: type[SchemaT]\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Configurable models",
        "type": "code",
        "content": "from langchain.chat_models import init_chat_model\n\nconfigurable_model = init_chat_model(temperature=0)\n\nconfigurable_model.invoke(\n    \"what's your name\",\n    config={\"configurable\": {\"model\": \"gpt-5-nano\"}},  # Run with GPT-5-Nano\n)\nconfigurable_model.invoke(\n    \"what's your name\",\n    config={\"configurable\": {\"model\": \"claude-sonnet-4-5-20250929\"}},  # Run with Claude\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Deep Agents Middleware",
        "type": "text",
        "content": "Deep agents are built with a modular middleware architecture. Deep agents have access to:\n\nEach feature is implemented as separate middleware. When you create a deep agent with create_deep_agent , we automatically attach TodoListMiddleware , FilesystemMiddleware , and SubAgentMiddleware to your agent.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/middleware",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Spanner",
        "type": "code",
        "content": "from langchain_google_spanner import SpannerVectorStore\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Async with Python < 3.11",
        "type": "code",
        "content": "from typing import TypedDict\nfrom langgraph.types import StreamWriter\n\nclass State(TypedDict):\n      topic: str\n      joke: str\n\n# Add writer as an argument in the function signature of the async node or tool\n# LangGraph will automatically pass the stream writer to the function\nasync def generate_joke(state: State, writer: StreamWriter):  \n      writer({\"custom_key\": \"Streaming custom data while generating a joke\"})\n      return {\"joke\": f\"This is a joke about {state['topic']}\"}\n\ngraph = (\n      StateGraph(State)\n      .add_node(generate_joke)\n      .add_edge(START, \"generate_joke\")\n      .compile()\n)\n\n# Set stream_mode=\"custom\" to receive the custom data in the stream  #\nasync for chunk in graph.astream(\n      {\"topic\": \"ice cream\"},\n      stream_mode=\"custom\",\n):\n      print(chunk)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Add metadata to traces",
        "type": "text",
        "content": "You can annotate your traces with custom metadata and tags:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/observability",
        "head_menu_name": "LangChain",
        "side_menu_name": "Observability"
    },
    {
        "title": "Time travel",
        "type": "text",
        "content": "Rewind conversations to any point and explore alternate paths and prompts\n\nYou don’t need to learn LangGraph to use these features—they work out of the box.",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Full development IDE setup",
        "type": "text",
        "content": "For larger changes or ongoing contributions, it’s important to set up a local development environment on your machine. Our documentation build pipeline offers local preview and live reload as you edit, important for ensuring your changes appear as intended before submitting.\n\nPlease review the steps to set up your environment outlined in the docs repo README.md .",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "YouTube Search Tool",
        "type": "code",
        "content": "pip install youtube_search langchain # Requires base langchain\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "BigQuery Vector Search",
        "type": "text",
        "content": "Google Cloud BigQuery ,\nBigQuery is a serverless and cost-effective enterprise data warehouse in Google Cloud.\n\nGoogle Cloud BigQuery Vector Search BigQuery vector search lets you use GoogleSQL to do semantic search, using vector indexes for fast but approximate results, or using brute force for exact results.\n\nIt can calculate Euclidean or Cosine distance. With LangChain, we default to use Euclidean distance.\n\nWe need to install several python packages.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Connect to your agent",
        "type": "text",
        "content": "Agent Chat UI can connect to both local and deployed agents .\n\nAfter starting Agent Chat UI, you’ll need to configure it to connect to your agent:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/ui",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agent Chat UI"
    },
    {
        "title": "Pre-model hook",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import SummarizationMiddleware\n\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    tools=tools,\n    middleware=[\n        SummarizationMiddleware(  \n            model=\"claude-sonnet-4-5-20250929\",  \n            max_tokens_before_summary=1000\n        )  \n    ]  \n)\n",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Delete messages",
        "type": "text",
        "content": "For RemoveMessage to work, you need to use a state key with add_messages reducer .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Stream multiple modes",
        "type": "code",
        "content": "for mode, chunk in graph.stream(inputs, stream_mode=[\"updates\", \"custom\"]):\n    print(chunk)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Dependencies",
        "type": "text",
        "content": "Any additional binaries or system libraries can be specified using dockerfile_lines key in the LangGraph configuration file .",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/application-structure",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Application structure"
    },
    {
        "title": "Protocol reference",
        "type": "code",
        "content": "glob_info(pattern: str, path: str = \"/\") -> list[FileInfo]",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "The /memories/ path convention",
        "type": "text",
        "content": "The key to long-term memory is the /memories/ path prefix:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Cloud SQL for PostgreSQL",
        "type": "code",
        "content": "from langchain_google_cloud_sql_pg import PostgresLoader # PostgresEngine also available\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Server-side tool use",
        "type": "text",
        "content": "This represents a single conversational turn; there are no associated ToolMessage objects that need to be passed in as in client-side tool-calling .\n\nSee the integration page for your given provider for available tools and usage details.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Fault-tolerance",
        "type": "text",
        "content": "Lastly, checkpointing also provides fault-tolerance and error recovery: if one or more nodes fail at a given superstep, you can restart your graph from the last successful step. Additionally, when a graph node fails mid-execution at a given superstep, LangGraph stores pending checkpoint writes from any other nodes that completed successfully at that superstep, so that whenever we resume graph execution from that superstep we don’t re-run the successful nodes.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Filesystem middleware",
        "type": "text",
        "content": "Context engineering is a main challenge in building effective agents. This is particularly difficult when using tools that return variable-length results (for example, web_search and rag), as long tool results can quickly fill your context window.\n\nFilesystemMiddleware provides four tools for interacting with both short-term and long-term memory:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/middleware",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Agentic RAG",
        "type": "text",
        "content": "Agentic Retrieval-Augmented Generation (RAG) combines the strengths of Retrieval-Augmented Generation with agent-based reasoning. Instead of retrieving documents before answering, an agent (powered by an LLM) reasons step-by-step and decides when and how to retrieve information during the interaction.\n\nThe only thing an agent needs to enable RAG behavior is access to one or more tools that can fetch external knowledge — such as documentation loaders, web APIs, or database queries.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/retrieval",
        "head_menu_name": "LangChain",
        "side_menu_name": "Retrieval"
    },
    {
        "title": "Hugging Face Text-to-Speech Model Inference.",
        "type": "code",
        "content": "from langchain_community.tools.audio import HuggingFaceTextToSpeechModelInference\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Common File Types",
        "type": "text",
        "content": "The below document loaders allow you to load data from common data formats.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/document_loaders",
        "head_menu_name": "Integrations",
        "side_menu_name": "Document loaders"
    },
    {
        "title": "Prebuilt middleware",
        "type": "text",
        "content": "LangChain provides a few prebuilt middlewares for common patterns, including:",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Document AI Warehouse",
        "type": "code",
        "content": "from langchain_google_community.documentai_warehouse import DocumentAIWarehouseRetriever\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Defining state viastate_schema",
        "type": "code",
        "content": "from langchain.agents import AgentState\n\n\nclass CustomState(AgentState):\n    user_preferences: dict\n\nagent = create_agent(\n    model,\n    tools=[tool1, tool2],\n    state_schema=CustomState\n)\n# The agent can now track additional state beyond messages\nresult = agent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"I prefer technical explanations\"}],\n    \"user_preferences\": {\"style\": \"technical\", \"verbosity\": \"detailed\"},\n})\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Azure AI Document Intelligence",
        "type": "text",
        "content": "Document Intelligence supports PDF , JPEG/JPG , PNG , BMP , TIFF , HEIF , DOCX , XLSX , PPTX and HTML .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Combine multiple guardrails",
        "type": "text",
        "content": "You can stack multiple guardrails by adding them to the middleware array. They execute in order, allowing you to build layered protection:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/guardrails",
        "head_menu_name": "LangChain",
        "side_menu_name": "Guardrails"
    },
    {
        "title": "Implementing our email agent nodes",
        "type": "code",
        "content": "from typing import Literal\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.types import interrupt, Command, RetryPolicy\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.messages import HumanMessage\n\nllm = ChatOpenAI(model=\"gpt-4\")\n\ndef read_email(state: EmailAgentState) -> dict:\n    \"\"\"Extract and parse email content\"\"\"\n    # In production, this would connect to your email service\n    return {\n        \"messages\": [HumanMessage(content=f\"Processing email: {state['email_content']}\")]\n    }\n\ndef classify_intent(state: EmailAgentState) -> Command[Literal[\"search_documentation\", \"human_review\", \"draft_response\", \"bug_tracking\"]]:\n    \"\"\"Use LLM to classify email intent and urgency, then route accordingly\"\"\"\n\n    # Create structured LLM that returns EmailClassification dict\n    structured_llm = llm.with_structured_output(EmailClassification)\n\n    # Format the prompt on-demand, not stored in state\n    classification_prompt = f\"\"\"\n    Analyze this customer email and classify it:\n\n    Email: {state['email_content']}\n    From: {state['sender_email']}\n\n    Provide classification including intent, urgency, topic, and summary.\n    \"\"\"\n\n    # Get structured response directly as dict\n    classification = structured_llm.invoke(classification_prompt)\n\n    # Determine next node based on classification\n    if classification['intent'] == 'billing' or classification['urgency'] == 'critical':\n        goto = \"human_review\"\n    elif classification['intent'] in ['question', 'feature']:\n        goto = \"search_documentation\"\n    elif classification['intent'] == 'bug':\n        goto = \"bug_tracking\"\n    else:\n        goto = \"draft_response\"\n\n    # Store classification as a single dict in state\n    return Command(\n        update={\"classification\": classification},\n        goto=goto\n    )\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Using in LangGraph",
        "type": "code",
        "content": "def update_memory(state: MessagesState, config: RunnableConfig, *, store: BaseStore):\n\n    # Get the user id from the config\n    user_id = config[\"configurable\"][\"user_id\"]\n\n    # Namespace the memory\n    namespace = (user_id, \"memories\")\n\n    # ... Analyze conversation and create a new memory\n\n    # Create a new memory ID\n    memory_id = str(uuid.uuid4())\n\n    # We create a new memory\n    store.put(namespace, memory_id, {\"memory\": memory})\n\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Standard content blocks",
        "type": "text",
        "content": "See the integrations guides to get started with the\ninference provider of your choice.\n\nSerializing standard content\n\nIf an application outside of LangChain needs access to the standard content block\nrepresentation, you can opt-in to storing content blocks in message content.\n\nTo do this, you can set the LC_OUTPUT_VERSION environment variable to v1 . Or,\ninitialize any chat model with output_version=\"v1\" :",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Wrap-style hooks",
        "type": "code",
        "content": "from langchain.tools.tool_node import ToolCallRequest\nfrom langchain.agents.middleware import AgentMiddleware\nfrom langchain_core.messages import ToolMessage\nfrom langgraph.types import Command\nfrom typing import Callable\n\nclass ToolMonitoringMiddleware(AgentMiddleware):\n    def wrap_tool_call(\n        self,\n        request: ToolCallRequest,\n        handler: Callable[[ToolCallRequest], ToolMessage | Command],\n    ) -> ToolMessage | Command:\n        print(f\"Executing tool: {request.tool_call['name']}\")\n        print(f\"Arguments: {request.tool_call['args']}\")\n\n        try:\n            result = handler(request)\n            print(f\"Tool completed successfully\")\n            return result\n        except Exception as e:\n            print(f\"Tool failed: {e}\")\n            raise\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Do not wrapinterruptcalls in try/except",
        "type": "text",
        "content": "The way that interrupt pauses execution at the point of the call is by throwing a special exception. If you wrap the interrupt call in a try/except block, you will catch this exception and the interrupt will not be passed back to the graph.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Durability modes",
        "type": "text",
        "content": "A higher durability mode adds more overhead to the workflow execution.\n\nAdded in v0.6.0 Use the durability parameter instead of checkpoint_during (deprecated in v0.6.0) for persistence policy management:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/durable-execution",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Durable execution"
    },
    {
        "title": "Vertex AI Search",
        "type": "text",
        "content": "Build generative AI powered search engines using Vertex AI Search .\nfrom Google Cloud allows developers to quickly build generative AI powered search engines for customers and employees.\n\nSee a usage example .\n\nNote: GoogleVertexAISearchRetriever is deprecated. Use the components below from langchain-google-community .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Simplified namespace",
        "type": "text",
        "content": "For a complete list of changes, see the migration guide .",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "How it works",
        "type": "text",
        "content": "LangChain middleware is the mechanism under the hood that makes context engineering practical for developers using LangChain.\n\nMiddleware allows you to hook into any step in the agent lifecycle and:\n\nThroughout this guide, you’ll see frequent use of the middleware API as a means to the context engineering end.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "LLM tokens",
        "type": "code",
        "content": "(message_chunk, metadata)",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Development environment",
        "type": "code",
        "content": "cd libs/community/langchain_community/path/to/integration\nuv sync --all-groups\nmake test  # Ensure tests pass before starting development\n",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Google Places",
        "type": "code",
        "content": "# Note: GooglePlacesTool might be in langchain or langchain_community depending on version\nfrom langchain.tools import GooglePlacesTool # Or langchain_community.tools\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "values",
        "type": "code",
        "content": "{\"foo\": 2, \"bar\": [\"a\", \"b\"]}\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Provider strategy",
        "type": "code",
        "content": "response_format=ProductReview",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Custom updates",
        "type": "text",
        "content": "If you add get_stream_writer inside your tool, you won’t be able to invoke the tool outside of a LangGraph execution context.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/streaming",
        "head_menu_name": "LangChain",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Caching",
        "type": "text",
        "content": "In production, you would typically use a more robust persistent store, such as a database or cloud storage. Please see stores integrations for options.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/text_embedding",
        "head_menu_name": "Integrations",
        "side_menu_name": "Embedding models"
    },
    {
        "title": "Azure AI Data",
        "type": "text",
        "content": "First, you need to install several python packages.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "3. Environment variables",
        "type": "text",
        "content": "Be sure not to commit your .env to version control systems such as Git!",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/studio",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Studio"
    },
    {
        "title": "5. Launch LangGraph server 🚀",
        "type": "code",
        "content": ">    Ready!\n>\n>    - API: [http://localhost:2024](http://localhost:2024/)\n>\n>    - Docs: http://localhost:2024/docs\n>\n>    - LangGraph Studio Web UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/local-server",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Local server"
    },
    {
        "title": "3. Update the state",
        "type": "code",
        "content": "new_config = graph.update_state(selected_state.config, values={\"topic\": \"chickens\"})\nprint(new_config)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-time-travel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Time travel"
    },
    {
        "title": "Using in LangGraph",
        "type": "code",
        "content": "# Invoke the graph\nuser_id = \"1\"\nconfig = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": user_id}}\n\n# First let's just say hi to the AI\nfor update in graph.stream(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"hi\"}]}, config, stream_mode=\"updates\"\n):\n    print(update)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Amazon Bedrock (Knowledge Bases)",
        "type": "code",
        "content": "from langchain_aws import AmazonKnowledgeBasesRetriever\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Tool Integration",
        "type": "text",
        "content": "Integrate more tools for web search, database queries, and API calls",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "PII detection",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import PIIMiddleware\n\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[customer_service_tool, email_tool],\n    middleware=[\n        # Redact emails in user input before sending to model\n        PIIMiddleware(\n            \"email\",\n            strategy=\"redact\",\n            apply_to_input=True,\n        ),\n        # Mask credit cards in user input\n        PIIMiddleware(\n            \"credit_card\",\n            strategy=\"mask\",\n            apply_to_input=True,\n        ),\n        # Block API keys - raise error if detected\n        PIIMiddleware(\n            \"api_key\",\n            detector=r\"sk-[a-zA-Z0-9]{32}\",\n            strategy=\"block\",\n            apply_to_input=True,\n        ),\n    ],\n)\n\n# When user provides PII, it will be handled according to the strategy\nresult = agent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"My email is john.doe@example.com and card is 4532-1234-5678-9010\"}]\n})\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/guardrails",
        "head_menu_name": "LangChain",
        "side_menu_name": "Guardrails"
    },
    {
        "title": "Prompt caching",
        "type": "code",
        "content": "AnthropicPromptCachingMiddleware",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Google Finance",
        "type": "text",
        "content": "Query financial data. Requires google-search-results package and SerpApi key.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "4. Create a LangGraph config file",
        "type": "text",
        "content": "See the LangGraph configuration file reference for detailed explanations of each key in the JSON object of the configuration file.\n\nSo far, our project structure looks like this:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/studio",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Studio"
    },
    {
        "title": "1. Define tools and model",
        "type": "text",
        "content": "In this example, we’ll use the Claude Sonnet 4.5 model and define tools for addition, multiplication, and division.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/quickstart",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Azure Blob Storage",
        "type": "code",
        "content": "pip install langchain-azure-storage\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "InMemorySaver Checkpointer",
        "type": "text",
        "content": "To enable persistence during testing, you can use the InMemorySaver checkpointer. This allows you to simulate multiple turns to test state-dependent behavior:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "4. Define tool node",
        "type": "text",
        "content": "The tool node is used to call the tools and return the results.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/quickstart",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Decision types",
        "type": "code",
        "content": "agent.invoke(\n    Command(\n        # Decisions are provided as a list, one per action under review.\n        # The order of decisions must match the order of actions\n        # listed in the `__interrupt__` request.\n        resume={\n            \"decisions\": [\n                {\n                    \"type\": \"approve\",\n                }\n            ]\n        }\n    ),\n    config=config  # Same thread ID to resume the paused conversation\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/human-in-the-loop",
        "head_menu_name": "LangChain",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "LLM-as-Judge Evaluator",
        "type": "text",
        "content": "You can also use an LLM to evaluate the agent’s execution path with the create_trajectory_llm_as_judge function. Unlike the trajectory match evaluators, it doesn’t require a reference trajectory, but one can be provided if available.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "In the background",
        "type": "text",
        "content": "Creating memories as a separate background task offers several advantages. It eliminates latency in the primary application, separates application logic from memory management, and allows for more focused task completion by the agent. This approach also provides flexibility in timing memory creation to avoid redundant work.\n\nHowever, this method has its own challenges. Determining the frequency of memory writing becomes crucial, as infrequent updates may leave other threads without new context. Deciding when to trigger memory formation is also important. Common strategies include scheduling after a set time period (with rescheduling if new events occur), using a cron schedule, or allowing manual triggers by users or the application logic.\n\nSee our memory-service template as an reference implementation.",
        "side_link": "https://docs.langchain.com/oss/python/concepts/memory",
        "head_menu_name": "Learn",
        "side_menu_name": "Memory"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "from langchain_postgres import PGEngine, PGVectorStore\n\n$engine = PGEngine.from_connection_string(\n    url=\"postgresql+psycopg://...\"\n)\n\nvector_store = PGVectorStore.create_sync(\n    engine=pg_engine,\n    table_name='test_table',\n    embedding_service=embedding\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Azure AI Data",
        "type": "text",
        "content": "Azure AI Foundry (formerly Azure AI Studio provides the capability to upload data assets\nto cloud storage and register existing data assets from the following sources:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Streaming",
        "type": "text",
        "content": "We’ve seen how the agent can be called with invoke to get a final response. If the agent executes multiple steps, this may take a while. To show intermediate progress, we can stream back messages as they occur.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Return concise results",
        "type": "code",
        "content": "data_analyst = {\n    \"system_prompt\": \"\"\"Analyze the data and return:\n    1. Key insights (3-5 bullet points)\n    2. Overall confidence score\n    3. Recommended next actions\n\n    Do NOT include:\n    - Raw data\n    - Intermediate calculations\n    - Detailed tool outputs\n\n    Keep response under 300 words.\"\"\"\n}\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Log to a project",
        "type": "text",
        "content": "You can set the project name programmatically for specific operations:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/observability",
        "head_menu_name": "LangChain",
        "side_menu_name": "Observability"
    },
    {
        "title": "History",
        "type": "text",
        "content": "For users still using old LangChain chains/agents who do NOT want to upgrade (note: we recommend you do), you can continue using old LangChain by installing the langchain-classic package.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/philosophy",
        "head_menu_name": "LangChain",
        "side_menu_name": "Philosophy"
    },
    {
        "title": "Custom tool message content",
        "type": "code",
        "content": "from pydantic import BaseModel, Field\nfrom typing import Literal\nfrom langchain.agents import create_agent\nfrom langchain.agents.structured_output import ToolStrategy\n\n\nclass MeetingAction(BaseModel):\n    \"\"\"Action items extracted from a meeting transcript.\"\"\"\n    task: str = Field(description=\"The specific task to be completed\")\n    assignee: str = Field(description=\"Person responsible for the task\")\n    priority: Literal[\"low\", \"medium\", \"high\"] = Field(description=\"Priority level\")\n\nagent = create_agent(\n    model=\"gpt-5\",\n    tools=[],\n    response_format=ToolStrategy(\n        schema=MeetingAction,\n        tool_message_content=\"Action item captured and added to meeting notes!\"\n    )\n)\n\nagent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"From our meeting: Sarah needs to update the project timeline as soon as possible\"}]\n})\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Messages",
        "type": "text",
        "content": "For persistent updates that modify state (like the summarization example in Life-cycle Context ), use life-cycle hooks like before_model or after_model to permanently update the conversation history. See the middleware documentation for more details.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Return concise results",
        "type": "text",
        "content": "Instruct subagents to return summaries, not raw data:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Custom HITL logic",
        "type": "text",
        "content": "For more specialized workflows, you can build custom HITL logic directly using the interrupt primitive and middleware abstraction.\n\nReview the execution lifecycle above to understand how to integrate interrupts into the agent’s operation.\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/human-in-the-loop",
        "head_menu_name": "LangChain",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Human-in-the-loop",
        "type": "text",
        "content": "Some tool operations may be sensitive and require human approval before execution. Deep agents support human-in-the-loop workflows through LangGraph’s interrupt capabilities. You can configure which tools require approval using the interrupt_on parameter.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/human-in-the-loop",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Azure OpenAI",
        "type": "code",
        "content": "pip install langchain-openai\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Model",
        "type": "code",
        "content": "from langchain.chat_models import init_chat_model\nfrom deepagents import create_deep_agent\n\nmodel = init_chat_model(\n    model=\"gpt-5\",\n)\nagent = create_deep_agent(\n    model=model,\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/customization",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Customization"
    },
    {
        "title": "Content block reference",
        "type": "text",
        "content": "Identifier of the corresponding server tool call.\n\nIdentifier associated with the server tool result.\n\nExecution status of the server-side tool. \"success\" or \"error\" .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "PlayWright Browser Toolkit",
        "type": "text",
        "content": "Playwright is an open-source automation tool\ndeveloped by Microsoft that allows you to programmatically control and automate\nweb browsers. It is designed for end-to-end testing, scraping, and automating\ntasks across various web browsers such as Chromium , Firefox , and WebKit .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Checkpointer interface",
        "type": "text",
        "content": "For running your graph asynchronously, you can use InMemorySaver , or async versions of Sqlite/Postgres checkpointers — AsyncSqliteSaver / AsyncPostgresSaver checkpointers.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Vertex AI Search",
        "type": "code",
        "content": "GoogleVertexAISearchRetriever",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "pip install -qU langchain-huggingface\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Multiple specialized subagents",
        "type": "code",
        "content": "from deepagents import create_deep_agent\n\nsubagents = [\n    {\n        \"name\": \"data-collector\",\n        \"description\": \"Gathers raw data from various sources\",\n        \"system_prompt\": \"Collect comprehensive data on the topic\",\n        \"tools\": [web_search, api_call, database_query],\n    },\n    {\n        \"name\": \"data-analyzer\",\n        \"description\": \"Analyzes collected data for insights\",\n        \"system_prompt\": \"Analyze data and extract key insights\",\n        \"tools\": [statistical_analysis],\n    },\n    {\n        \"name\": \"report-writer\",\n        \"description\": \"Writes polished reports from analysis\",\n        \"system_prompt\": \"Create professional reports from insights\",\n        \"tools\": [format_document],\n    },\n]\n\nagent = create_deep_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    system_prompt=\"You coordinate data analysis and reporting. Use subagents for specialized tasks.\",\n    subagents=subagents\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Azure AI Services",
        "type": "code",
        "content": "from langchain_community.agent_toolkits import azure_ai_services\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Use decorators when",
        "type": "text",
        "content": "• You need a single hook • No complex configuration",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "LLM tokens",
        "type": "text",
        "content": "The streamed output from messages mode is a tuple (message_chunk, metadata) where:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Tool retry",
        "type": "text",
        "content": "Automatically retry failed tool calls with configurable exponential backoff.\n\nPerfect for:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Built on top of LangGraph",
        "type": "text",
        "content": "LangChain’s agents are built on top of LangGraph. This allows us to take advantage of LangGraph’s durable execution, human-in-the-loop support, persistence, and more.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/overview",
        "head_menu_name": "LangChain",
        "side_menu_name": "Overview"
    },
    {
        "title": "3. Install dependencies",
        "type": "text",
        "content": "In the root of your new LangGraph app, install the dependencies in edit mode so your local changes are used by the server:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/local-server",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Local server"
    },
    {
        "title": "Model",
        "type": "text",
        "content": "Dynamic model selection allows you to choose different models based on runtime context (e.g., task complexity, cost constraints, or user preferences). create_react_agent released in v0.6 of langgraph-prebuilt supported dynamic model and tool selection via a callable passed to the model parameter.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Custom updates",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langgraph.config import get_stream_writer  \n\n\ndef get_weather(city: str) -> str:\n    \"\"\"Get weather for a given city.\"\"\"\n    writer = get_stream_writer()  \n    # stream any arbitrary data\n    writer(f\"Looking up data for city: {city}\")\n    writer(f\"Acquired data for city: {city}\")\n    return f\"It's always sunny in {city}!\"\n\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    tools=[get_weather],\n)\n\nfor chunk in agent.stream(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n    stream_mode=\"custom\"\n):\n    print(chunk)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/streaming",
        "head_menu_name": "LangChain",
        "side_menu_name": "Streaming"
    },
    {
        "title": "2. Identify a checkpoint",
        "type": "code",
        "content": "()\n1f02ac4a-ec9f-6524-8002-8f7b0bbeed0e\n\n('write_joke',)\n1f02ac4a-ce2a-6494-8001-cb2e2d651227\n\n('generate_topic',)\n1f02ac4a-a4e0-630d-8000-b73c254ba748\n\n('__start__',)\n1f02ac4a-a4dd-665e-bfff-e6c8c44315d9\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-time-travel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Time travel"
    },
    {
        "title": "Write clear descriptions",
        "type": "code",
        "content": "\"Analyzes financial data and generates investment insights with confidence scores\"",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Content block reference",
        "type": "text",
        "content": "URL pointing to the audio location.\n\nBase64-encoded audio data.\n\nReference ID to an externally stored audio file (e.g., in a provider’s file system or in a bucket).\n\nAudio MIME type (e.g., audio/mpeg , audio/wav )",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Trim messages",
        "type": "code",
        "content": "from langchain.messages import RemoveMessage\nfrom langgraph.graph.message import REMOVE_ALL_MESSAGES\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langchain.agents import create_agent, AgentState\nfrom langchain.agents.middleware import before_model\nfrom langgraph.runtime import Runtime\nfrom langchain_core.runnables import RunnableConfig\nfrom typing import Any\n\n\n@before_model\ndef trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n    messages = state[\"messages\"]\n\n    if len(messages) <= 3:\n        return None  # No changes needed\n\n    first_msg = messages[0]\n    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]\n    new_messages = [first_msg] + recent_messages\n\n    return {\n        \"messages\": [\n            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n            *new_messages\n        ]\n    }\n\nagent = create_agent(\n    model,\n    tools=tools,\n    middleware=[trim_messages],\n    checkpointer=InMemorySaver(),\n)\n\nconfig: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n\nagent.invoke({\"messages\": \"hi, my name is bob\"}, config)\nagent.invoke({\"messages\": \"write a short poem about cats\"}, config)\nagent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\nfinal_response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n\nfinal_response[\"messages\"][-1].pretty_print()\n\"\"\"\n================================== Ai Message ==================================\n\nYour name is Bob. You told me that earlier.\nIf you'd like me to call you a nickname or use a different name, just say the word.\n\"\"\"\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Overview",
        "type": "text",
        "content": "You can access the runtime information within tools and middleware .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/runtime",
        "head_menu_name": "LangChain",
        "side_menu_name": "Runtime"
    },
    {
        "title": "Filter by LLM invocation",
        "type": "code",
        "content": "from langchain.chat_models import init_chat_model\n\n# model_1 is tagged with \"joke\"\nmodel_1 = init_chat_model(model=\"gpt-4o-mini\", tags=['joke'])\n# model_2 is tagged with \"poem\"\nmodel_2 = init_chat_model(model=\"gpt-4o-mini\", tags=['poem'])\n\ngraph = ... # define a graph that uses these LLMs\n\n# The stream_mode is set to \"messages\" to stream LLM tokens\n# The metadata contains information about the LLM invocation, including the tags\nasync for msg, metadata in graph.astream(\n    {\"topic\": \"cats\"},\n    stream_mode=\"messages\",  \n):\n    # Filter the streamed tokens by the tags field in the metadata to only include\n    # the tokens from the LLM invocation with the \"joke\" tag\n    if metadata[\"tags\"] == [\"joke\"]:\n        print(msg.content, end=\"|\", flush=True)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Do not reorderinterruptcalls within a node",
        "type": "text",
        "content": "It’s common to use multiple interrupts in a single node, however this can lead to unexpected behavior if not handled carefully.\n\nWhen a node contains multiple interrupt calls, LangGraph keeps a list of resume values specific to the task executing the node. Whenever execution resumes, it starts at the beginning of the node. For each interrupt encountered, LangGraph checks if a matching value exists in the task’s resume list. Matching is strictly index-based , so the order of interrupt calls within the node is important.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Repository structure",
        "type": "text",
        "content": "Many partner packages are in external repositories. Please check the list of integrations for details.",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Memory storage",
        "type": "text",
        "content": "LangGraph stores long-term memories as JSON documents in a store . Each memory is organized under a custom namespace (similar to a folder) and a distinct key (like a file name). Namespaces often include user or org IDs or other labels that makes it easier to organize information. This structure enables hierarchical organization of memories. Cross-namespace searching is then supported through content filters.",
        "side_link": "https://docs.langchain.com/oss/python/concepts/memory",
        "head_menu_name": "Learn",
        "side_menu_name": "Memory"
    },
    {
        "title": "ZHIPU AI",
        "type": "text",
        "content": "If you’d like to contribute an integration, see Contributing integrations .\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/chat",
        "head_menu_name": "Integrations",
        "side_menu_name": "Chat models"
    },
    {
        "title": "Evaluators",
        "type": "code",
        "content": "langchain-google-vertexai",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Vertex AI",
        "type": "text",
        "content": "Generate embeddings using models deployed on Vertex AI. Requires langchain-google-vertexai .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Stream",
        "type": "code",
        "content": "for chunk in model.stream(\"Why do parrots have colorful feathers?\"):\n    print(chunk.text, end=\"|\", flush=True)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Model",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\nfrom langchain.chat_models import init_chat_model\nfrom typing import Callable\n\n# Initialize models once outside the middleware\nlarge_model = init_chat_model(\"claude-sonnet-4-5-20250929\")\nstandard_model = init_chat_model(\"gpt-4o\")\nefficient_model = init_chat_model(\"gpt-4o-mini\")\n\n@wrap_model_call\ndef state_based_model(\n    request: ModelRequest,\n    handler: Callable[[ModelRequest], ModelResponse]\n) -> ModelResponse:\n    \"\"\"Select model based on State conversation length.\"\"\"\n    # request.messages is a shortcut for request.state[\"messages\"]\n    message_count = len(request.messages)  \n\n    if message_count > 20:\n        # Long conversation - use model with larger context window\n        model = large_model\n    elif message_count > 10:\n        # Medium conversation\n        model = standard_model\n    else:\n        # Short conversation - use efficient model\n        model = efficient_model\n\n    request = request.override(model=model)  \n\n    return handler(request)\n\nagent = create_agent(\n    model=\"gpt-4o-mini\",\n    tools=[...],\n    middleware=[state_based_model]\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Access",
        "type": "text",
        "content": "When invoking the agent, pass the context argument with the relevant configuration for the run:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/runtime",
        "head_menu_name": "LangChain",
        "side_menu_name": "Runtime"
    },
    {
        "title": "Review and edit state",
        "type": "code",
        "content": "import sqlite3\nfrom typing import TypedDict\n\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.types import Command, interrupt\n\n\nclass ReviewState(TypedDict):\n    generated_text: str\n\n\ndef review_node(state: ReviewState):\n    # Ask a reviewer to edit the generated content\n    updated = interrupt({\n        \"instruction\": \"Review and edit this content\",\n        \"content\": state[\"generated_text\"],\n    })\n    return {\"generated_text\": updated}\n\n\nbuilder = StateGraph(ReviewState)\nbuilder.add_node(\"review\", review_node)\nbuilder.add_edge(START, \"review\")\nbuilder.add_edge(\"review\", END)\n\ncheckpointer = MemorySaver()\ngraph = builder.compile(checkpointer=checkpointer)\n\nconfig = {\"configurable\": {\"thread_id\": \"review-42\"}}\ninitial = graph.invoke({\"generated_text\": \"Initial draft\"}, config=config)\nprint(initial[\"__interrupt__\"])  # -> [Interrupt(value={'instruction': ..., 'content': ...})]\n\n# Resume with the edited text from the reviewer\nfinal_state = graph.invoke(\n    Command(resume=\"Improved draft after review\"),\n    config=config,\n)\nprint(final_state[\"generated_text\"])  # -> \"Improved draft after review\"\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Azure AI Search",
        "type": "text",
        "content": "Azure AI Search (formerly known as Azure Search or Azure Cognitive Search ) is a cloud search service that gives developers infrastructure, APIs, and tools for building a rich search experience over private, heterogeneous content in web, mobile, and enterprise applications.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Replay",
        "type": "text",
        "content": "Importantly, LangGraph knows whether a particular step has been executed previously. If it has, LangGraph simply re-plays that particular step in the graph and does not re-execute the step, but only for the steps before the provided checkpoint_id . All of the steps after checkpoint_id will be executed (i.e., a new fork), even if they have been executed previously. See this how to guide on time-travel to learn more about replaying .",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Google Cloud",
        "type": "text",
        "content": "Google Cloud integrations typically use Application Default Credentials (ADC). Refer to the Google Cloud authentication documentation for setup instructions (e.g., using gcloud auth application-default login ).",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Language and style",
        "type": "text",
        "content": "Use Google-style docstrings with complete type hints for all public functions.\n\nFollow these standards for all documentation:",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "Removal of deprecated APIs",
        "type": "text",
        "content": "Methods, functions, and other objects that were already deprecated and slated for removal in 1.0 have been deleted. Check the deprecation notices from previous versions for replacement APIs.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "System Message",
        "type": "code",
        "content": "system_msg = SystemMessage(\"You are a helpful coding assistant.\")\n\nmessages = [\n    system_msg,\n    HumanMessage(\"How do I create a REST API?\")\n]\nresponse = model.invoke(messages)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Anthropic on Vertex AI Model Garden",
        "type": "code",
        "content": "from langchain_google_vertexai.model_garden import ChatAnthropicVertex\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "import getpass\nimport os\n\nif not os.environ.get(\"XAI_API_KEY\"):\n  os.environ[\"XAI_API_KEY\"] = getpass.getpass(\"Enter API key for xAI: \")\n\nfrom langchain.chat_models import init_chat_model\n\nmodel = init_chat_model(\"grok-2\", model_provider=\"xai\")\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Route to different backends",
        "type": "text",
        "content": "Route parts of the namespace to different backends. Commonly used to persist /memories/* and keep everything else ephemeral.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "4. Create a LangGraph config file",
        "type": "text",
        "content": "Inside your app’s directory, create a configuration file langgraph.json :",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/studio",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Studio"
    },
    {
        "title": "Caching",
        "type": "code",
        "content": "import time\nfrom langchain_classic.embeddings import CacheBackedEmbeddings  \nfrom langchain_classic.storage import LocalFileStore \nfrom langchain_core.vectorstores import InMemoryVectorStore\n\n# Create your underlying embeddings model\nunderlying_embeddings = ... # e.g., OpenAIEmbeddings(), HuggingFaceEmbeddings(), etc.\n\n# Store persists embeddings to the local filesystem\n# This isn't for production use, but is useful for local\nstore = LocalFileStore(\"./cache/\") \n\ncached_embedder = CacheBackedEmbeddings.from_bytes_store(\n    underlying_embeddings,\n    store,\n    namespace=underlying_embeddings.model\n)\n\n# Example: caching a query embedding\ntic = time.time()\nprint(cached_embedder.embed_query(\"Hello, world!\"))\nprint(f\"First call took: {time.time() - tic:.2f} seconds\")\n\n# Subsequent calls use the cache\ntic = time.time()\nprint(cached_embedder.embed_query(\"Hello, world!\"))\nprint(f\"Second call took: {time.time() - tic:.2f} seconds\")\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/text_embedding",
        "head_menu_name": "Integrations",
        "side_menu_name": "Embedding models"
    },
    {
        "title": "AnthropicLLM",
        "type": "text",
        "content": "(Legacy) Anthropic text completion models.\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/anthropic",
        "head_menu_name": "Integrations",
        "side_menu_name": "Anthropic (Claude)"
    },
    {
        "title": "See also",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/concepts/context",
        "head_menu_name": "Learn",
        "side_menu_name": "Context"
    },
    {
        "title": "Tool use in the ReAct loop",
        "type": "code",
        "content": "================================== Ai Message ==================================\n\nI found wireless headphones (model WH-1000XM5) with 10 units in stock...\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Mocking Chat Model",
        "type": "text",
        "content": "For logic not requiring API calls, you can use an in-memory stub for mocking responses.\n\nLangChain provides GenericFakeChatModel for mocking text responses. It accepts an iterator of responses (AIMessages or strings) and returns one per invocation. It supports both regular and streaming usage.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Get state",
        "type": "text",
        "content": "In our example, the output of get_state will look like this:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Vertex AI image captioning",
        "type": "code",
        "content": "from langchain_google_vertexai.vision_models import VertexAIImageCaptioning\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Approve or reject",
        "type": "code",
        "content": "import sqlite3\nfrom typing import Literal, Optional, TypedDict\n\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.types import Command, interrupt\n\n\nclass ApprovalState(TypedDict):\n    action_details: str\n    status: Optional[Literal[\"pending\", \"approved\", \"rejected\"]]\n\n\ndef approval_node(state: ApprovalState) -> Command[Literal[\"proceed\", \"cancel\"]]:\n    # Expose details so the caller can render them in a UI\n    decision = interrupt({\n        \"question\": \"Approve this action?\",\n        \"details\": state[\"action_details\"],\n    })\n\n    # Route to the appropriate node after resume\n    return Command(goto=\"proceed\" if decision else \"cancel\")\n\n\ndef proceed_node(state: ApprovalState):\n    return {\"status\": \"approved\"}\n\n\ndef cancel_node(state: ApprovalState):\n    return {\"status\": \"rejected\"}\n\n\nbuilder = StateGraph(ApprovalState)\nbuilder.add_node(\"approval\", approval_node)\nbuilder.add_node(\"proceed\", proceed_node)\nbuilder.add_node(\"cancel\", cancel_node)\nbuilder.add_edge(START, \"approval\")\nbuilder.add_edge(\"approval\", \"proceed\")\nbuilder.add_edge(\"approval\", \"cancel\")\nbuilder.add_edge(\"proceed\", END)\nbuilder.add_edge(\"cancel\", END)\n\n# Use a more durable checkpointer in production\ncheckpointer = MemorySaver()\ngraph = builder.compile(checkpointer=checkpointer)\n\nconfig = {\"configurable\": {\"thread_id\": \"approval-123\"}}\ninitial = graph.invoke(\n    {\"action_details\": \"Transfer $500\", \"status\": \"pending\"},\n    config=config,\n)\nprint(initial[\"__interrupt__\"])  # -> [Interrupt(value={'question': ..., 'details': ...})]\n\n# Resume with the decision; True routes to proceed, False to cancel\nresumed = graph.invoke(Command(resume=True), config=config)\nprint(resumed[\"status\"])  # -> \"approved\"\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Serper.dev",
        "type": "text",
        "content": "See a usage example and authorization instructions .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Delete messages",
        "type": "code",
        "content": "[('human', \"hi! I'm bob\")]\n[('human', \"hi! I'm bob\"), ('ai', 'Hi Bob! How are you doing today? Is there anything I can help you with?')]\n[('human', \"hi! I'm bob\"), ('ai', 'Hi Bob! How are you doing today? Is there anything I can help you with?'), ('human', \"what's my name?\")]\n[('human', \"hi! I'm bob\"), ('ai', 'Hi Bob! How are you doing today? Is there anything I can help you with?'), ('human', \"what's my name?\"), ('ai', 'Your name is Bob.')]\n[('human', \"what's my name?\"), ('ai', 'Your name is Bob.')]\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Parameters",
        "type": "text",
        "content": "To find all the parameters supported by a given chat model, head to the chat model integrations page.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "How it works",
        "type": "text",
        "content": "When you invoke() a chat model, LangChain will automatically switch to an internal streaming mode if it detects that you are trying to stream the overall application. The result of the invocation will be the same as far as the code that was using invoke is concerned; however, while the chat model is being streamed, LangChain will take care of invoking on_llm_new_token events in LangChain’s callback system.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Batch",
        "type": "text",
        "content": "When using batch_as_completed() , results may arrive out of order. Each includes the input index for matching to reconstruct the original order as needed.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "In production",
        "type": "text",
        "content": "In production, use a checkpointer backed by a database:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Selecting tools",
        "type": "text",
        "content": "Not every tool is appropriate for every situation. Too many tools may overwhelm the model (overload context) and increase errors; too few limit capabilities. Dynamic tool selection adapts the available toolset based on authentication state, user permissions, feature flags, or conversation stage.\n\nEnable advanced tools only after certain conversation milestones:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Memory storage",
        "type": "code",
        "content": "from langgraph.store.memory import InMemoryStore\n\n\ndef embed(texts: list[str]) -> list[list[float]]:\n    # Replace with an actual embedding function or LangChain embeddings object\n    return [[1.0, 2.0] * len(texts)]\n\n\n# InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production use.\nstore = InMemoryStore(index={\"embed\": embed, \"dims\": 2})\nuser_id = \"my-user\"\napplication_context = \"chitchat\"\nnamespace = (user_id, application_context)\nstore.put(\n    namespace,\n    \"a-memory\",\n    {\n        \"rules\": [\n            \"User likes short, direct language\",\n            \"User only speaks English & python\",\n        ],\n        \"my-key\": \"my-value\",\n    },\n)\n# get the \"memory\" by ID\nitem = store.get(namespace, \"a-memory\")\n# search for \"memories\" within this namespace, filtering on content equivalence, sorted by vector similarity\nitems = store.search(\n    namespace, filter={\"my-key\": \"my-value\"}, query=\"language preferences\"\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/concepts/memory",
        "head_menu_name": "Learn",
        "side_menu_name": "Memory"
    },
    {
        "title": "Handling tool errors",
        "type": "text",
        "content": "You can now configure the handling of tool errors with middleware implementing the wrap_tool_call method.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Checkpoints",
        "type": "text",
        "content": "After we run the graph, we expect to see exactly 4 checkpoints:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "pip install -qU langchain-astradb\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Amazon Athena",
        "type": "code",
        "content": "from langchain_community.document_loaders.athena import AthenaLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Recording & Replaying HTTP Calls",
        "type": "code",
        "content": "import pytest\n\n@pytest.fixture(scope=\"session\")\ndef vcr_config():\n    return {\n        \"filter_headers\": [\n            (\"authorization\", \"XXXX\"),\n            (\"x-api-key\", \"XXXX\"),\n            # ... other headers you want to mask\n        ],\n        \"filter_query_parameters\": [\n            (\"api_key\", \"XXXX\"),\n            (\"key\", \"XXXX\"),\n        ],\n    }\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "State type restrictions",
        "type": "text",
        "content": "Simply inherit from langchain.agents.AgentState instead of BaseModel or decorating with dataclass .\nIf you need to perform validation, handle it in middleware hooks instead.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "langchain-classic",
        "type": "text",
        "content": "If you were using any of the following from the langchain package, you’ll need to install langchain-classic and update your imports:",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Custom strategies",
        "type": "text",
        "content": "Custom strategies (e.g., message filtering, etc.)\n\nThis allows the agent to keep track of the conversation without exceeding the LLM’s context window.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Google Lens",
        "type": "code",
        "content": "pip install google-search-results langchain-community # Requires langchain-community\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Vector Stores",
        "type": "text",
        "content": "Store and search vectors using Google Cloud databases and Vertex AI Vector Search.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Context still getting bloated",
        "type": "code",
        "content": "system_prompt=\"\"\"...\n\nIMPORTANT: Return only the essential summary.\nDo NOT include raw data, intermediate search results, or detailed tool outputs.\nYour response should be under 500 words.\"\"\"\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Base URL or proxy",
        "type": "text",
        "content": "For many chat model integrations, you can configure the base URL for API requests, which allows you to use model providers that have OpenAI-compatible APIs or to use a proxy server.\n\nMany model providers offer OpenAI-compatible APIs (e.g., Together AI , vLLM ). You can use init_chat_model with these providers by specifying the appropriate base_url parameter:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Quickstart",
        "type": "text",
        "content": "This guide walks you through creating your first deep agent with planning, file system tools, and subagent capabilities. You’ll build a research agent that can conduct research and write reports.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/quickstart",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Code Interpreter",
        "type": "text",
        "content": "The following table shows tools that can be used as code interpreters:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/tools",
        "head_menu_name": "Integrations",
        "side_menu_name": "Tools and toolkits"
    },
    {
        "title": "AI Message",
        "type": "text",
        "content": "The text content of the message.\n\nThe raw content of the message.\n\nThe standardized content blocks of the message.\n\nThe tool calls made by the model. Empty if no tools are called.\n\nA unique identifier for the message (either automatically generated by LangChain or returned in the provider response)\n\nThe usage metadata of the message, which can contain token counts when available.\n\nThe response metadata of the message.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Error handling strategies",
        "type": "code",
        "content": "ToolStrategy(\n    schema=ProductRating,\n    handle_errors=\"Please provide a valid rating between 1-5 and include a comment.\"\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Text structure-based",
        "type": "code",
        "content": "from langchain_text_splitters import RecursiveCharacterTextSplitter\n\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=0)\ntexts = text_splitter.split_text(document)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/splitters",
        "head_menu_name": "Integrations",
        "side_menu_name": "Text splitters"
    },
    {
        "title": "Google Drive",
        "type": "code",
        "content": "pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib langchain-googledrive\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Specify a backend",
        "type": "code",
        "content": "BackendFactory = Callable[[ToolRuntime], BackendProtocol]",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "PowerBI individual tools",
        "type": "code",
        "content": "from langchain_community.tools.powerbi.tool import InfoPowerBITool\nfrom langchain_community.tools.powerbi.tool import ListPowerBITool\nfrom langchain_community.tools.powerbi.tool import QueryPowerBITool\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "LangGraph",
        "type": "text",
        "content": "LangChain’s agent implementations use LangGraph primitives.\nIf deeper customization is required, agents can be implemented directly in LangGraph.",
        "side_link": "https://docs.langchain.com/oss/python/learn",
        "head_menu_name": "Learn",
        "side_menu_name": "Learn"
    },
    {
        "title": "Pending writes",
        "type": "text",
        "content": "Additionally, when a graph node fails mid-execution at a given superstep, LangGraph stores pending checkpoint writes from any other nodes that completed successfully at that superstep, so that whenever we resume graph execution from that superstep we don’t re-run the successful nodes.\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Use anonymizers to prevent logging of sensitive data in traces",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/observability",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Observability"
    },
    {
        "title": "Tools and toolkits",
        "type": "text",
        "content": "Tools are utilities designed to be called by a model: their inputs are designed to be generated by models, and their outputs are designed to be passed back to models.\n\nA toolkit is a collection of tools meant to be used together.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/tools",
        "head_menu_name": "Integrations",
        "side_menu_name": "Tools and toolkits"
    },
    {
        "title": "Reasoning",
        "type": "text",
        "content": "Depending on the model, you can sometimes specify the level of effort it should put into reasoning. Similarly, you can request that the model turn off reasoning entirely. This may take the form of categorical “tiers” of reasoning (e.g., 'low' or 'high' ) or integer token budgets.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "PostgresStore (production)",
        "type": "code",
        "content": "from langgraph.store.postgres import PostgresStore\nimport os\n\nstore = PostgresStore(connection_string=os.environ[\"DATABASE_URL\"])\nagent = create_deep_agent(store=store, use_longterm_memory=True)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Life-cycle Context",
        "type": "text",
        "content": "Control what happens between the core agent steps - intercepting data flow to implement cross-cutting concerns like summarization, guardrails, and logging.\n\nAs you’ve seen in Model Context and Tool Context , middleware is the mechanism that makes context engineering practical. Middleware allows you to hook into any step in the agent lifecycle and either:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "LangSmith Integration",
        "type": "text",
        "content": "LangSmith offers two main approaches for running evaluations: pytest integration and the evaluate function.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Edit tool arguments",
        "type": "code",
        "content": "if result.get(\"__interrupt__\"):\n    interrupts = result[\"__interrupt__\"][0].value\n    action_request = interrupts[\"action_requests\"][0]\n\n    # Original args from the agent\n    print(action_request[\"args\"])  # {\"to\": \"everyone@company.com\", ...}\n\n    # User decides to edit the recipient\n    decisions = [{\n        \"type\": \"edit\",\n        \"edited_action\": {\n            \"name\": action_request[\"name\"],  # Must include the tool name\n            \"args\": {\"to\": \"team@company.com\", \"subject\": \"...\", \"body\": \"...\"}\n        }\n    }]\n\n    result = agent.invoke(\n        Command(resume={\"decisions\": decisions}),\n        config=config\n    )\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/human-in-the-loop",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Vertex AI visual QnA",
        "type": "text",
        "content": "Chat implementation of a visual QnA model. Requires langchain-google-vertexai .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Do not return complex values ininterruptcalls",
        "type": "text",
        "content": "Depending on which checkpointer is used, complex values may not be serializable (e.g. you can’t serialize a function). To make your graphs adaptable to any deployment, it’s best practice to only use values that can be reasonably serialized.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Standard content blocks",
        "type": "code",
        "content": "from langchain_anthropic import ChatAnthropic\n\nmodel = ChatAnthropic(model=\"claude-sonnet-4-5-20250929\")\nresponse = model.invoke(\"What's the capital of France?\")\n\n# Unified access to content blocks\nfor block in response.content_blocks:\n    if block[\"type\"] == \"reasoning\":\n        print(f\"Model reasoning: {block['reasoning']}\")\n    elif block[\"type\"] == \"text\":\n        print(f\"Response: {block['text']}\")\n    elif block[\"type\"] == \"tool_call\":\n        print(f\"Tool call: {block['name']}({block['args']})\")\n",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Interrupts",
        "type": "text",
        "content": "The thread_id you choose is effectively your persistent cursor. Reusing it resumes the same checkpoint; using a new value starts a brand-new thread with an empty state.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "SearchApi",
        "type": "code",
        "content": "from langchain_community.utilities import SearchApiAPIWrapper\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Implementation",
        "type": "text",
        "content": "Below is a minimal example where the main agent is given access to a single subagent via a tool definition:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/multi-agent",
        "head_menu_name": "LangChain",
        "side_menu_name": "Multi-agent"
    },
    {
        "title": "Enforce",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import SummarizationMiddleware, HumanInTheLoopMiddleware\n\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[...],\n    middleware=[SummarizationMiddleware(), HumanInTheLoopMiddleware()],\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Agentic RAG",
        "type": "text",
        "content": "This example implements an Agentic RAG system to assist users in querying LangGraph documentation. The agent begins by loading llms.txt , which lists available documentation URLs, and can then dynamically use a fetch_documentation tool to retrieve and process the relevant content based on the user’s question.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/retrieval",
        "head_menu_name": "LangChain",
        "side_menu_name": "Retrieval"
    },
    {
        "title": "How it works",
        "type": "code",
        "content": "async for event in model.astream_events(\"Hello\"):\n\n    if event[\"event\"] == \"on_chat_model_start\":\n        print(f\"Input: {event['data']['input']}\")\n\n    elif event[\"event\"] == \"on_chat_model_stream\":\n        print(f\"Token: {event['data']['chunk'].text}\")\n\n    elif event[\"event\"] == \"on_chat_model_end\":\n        print(f\"Full message: {event['data']['output'].text}\")\n\n    else:\n        pass\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Built-in middleware",
        "type": "text",
        "content": "LangChain provides prebuilt middleware for common use cases:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Vertex AI Search",
        "type": "code",
        "content": "# Note: The example code shows VertexAIMultiTurnSearchRetriever, confirm if VertexAISearchRetriever is separate or related.\n# Assuming it might be related or a typo in the original doc:\nfrom langchain_google_community import VertexAISearchRetriever # Verify class name if needed\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Serper.dev",
        "type": "code",
        "content": "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Debug with LangSmith",
        "type": "text",
        "content": "Gain deep visibility into complex agent behavior with visualization tools that trace execution paths, capture state transitions, and provide detailed runtime metrics.\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/overview",
        "head_menu_name": "LangChain",
        "side_menu_name": "Overview"
    },
    {
        "title": "Stream Writer",
        "type": "code",
        "content": "runtime.stream_writer",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "Bedrock Converse",
        "type": "code",
        "content": "from langchain_aws import ChatBedrockConverse\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Microsoft Presidio",
        "type": "code",
        "content": "from langchain_experimental.data_anonymizer import PresidioAnonymizer, PresidioReversibleAnonymizer\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Localization",
        "type": "text",
        "content": "We are working to add support for other languages, thanks to our LangChain Ambassadors!",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "Debugging with interrupts",
        "type": "text",
        "content": "Static interrupts are not recommended for human-in-the-loop workflows. Use the interrupt method instead.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Using with subgraphs called as functions",
        "type": "code",
        "content": "def node_in_parent_graph(state: State):\n    some_code()  # <-- This will re-execute when resumed\n    # Invoke a subgraph as a function.\n    # The subgraph contains an `interrupt` call.\n    subgraph_result = subgraph.invoke(some_input)\n\nasync function node_in_subgraph(state: State) {\n    someOtherCode(); # <-- This will also re-execute when resumed\n    result = interrupt(\"What's your name?\")\n    ...\n}\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Setup",
        "type": "code",
        "content": "import uuid\n\nfrom typing_extensions import TypedDict, NotRequired\nfrom langgraph.graph import StateGraph, START, END\nfrom langchain.chat_models import init_chat_model\nfrom langgraph.checkpoint.memory import InMemorySaver\n\n\nclass State(TypedDict):\n    topic: NotRequired[str]\n    joke: NotRequired[str]\n\n\nmodel = init_chat_model(\n    \"claude-sonnet-4-5-20250929\",\n    temperature=0,\n)\n\n\ndef generate_topic(state: State):\n    \"\"\"LLM call to generate a topic for the joke\"\"\"\n    msg = model.invoke(\"Give me a funny topic for a joke\")\n    return {\"topic\": msg.content}\n\n\ndef write_joke(state: State):\n    \"\"\"LLM call to write a joke based on the topic\"\"\"\n    msg = model.invoke(f\"Write a short joke about {state['topic']}\")\n    return {\"joke\": msg.content}\n\n\n# Build workflow\nworkflow = StateGraph(State)\n\n# Add nodes\nworkflow.add_node(\"generate_topic\", generate_topic)\nworkflow.add_node(\"write_joke\", write_joke)\n\n# Add edges to connect nodes\nworkflow.add_edge(START, \"generate_topic\")\nworkflow.add_edge(\"generate_topic\", \"write_joke\")\nworkflow.add_edge(\"write_joke\", END)\n\n# Compile\ncheckpointer = InMemorySaver()\ngraph = workflow.compile(checkpointer=checkpointer)\ngraph\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-time-travel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Time travel"
    },
    {
        "title": "Ads4GPTs",
        "type": "text",
        "content": "Advertising platform for GPT applications and AI services.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/all_providers",
        "head_menu_name": "Integrations",
        "side_menu_name": "All providers"
    },
    {
        "title": "Amazon Comprehend Moderation Chain",
        "type": "code",
        "content": "from langchain_experimental.comprehend_moderation import AmazonComprehendModerationChain\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "LLMs and augmentations",
        "type": "code",
        "content": "# Schema for structured output\nfrom pydantic import BaseModel, Field\n\n\nclass SearchQuery(BaseModel):\n    search_query: str = Field(None, description=\"Query that is optimized web search.\")\n    justification: str = Field(\n        None, description=\"Why this query is relevant to the user's request.\"\n    )\n\n\n# Augment the LLM with schema for structured output\nstructured_llm = llm.with_structured_output(SearchQuery)\n\n# Invoke the augmented LLM\noutput = structured_llm.invoke(\"How does Calcium CT score relate to high cholesterol?\")\n\n# Define a tool\ndef multiply(a: int, b: int) -> int:\n    return a * b\n\n# Augment the LLM with tools\nllm_with_tools = llm.bind_tools([multiply])\n\n# Invoke the LLM with input that triggers the tool call\nmsg = llm_with_tools.invoke(\"What is 2 times 3?\")\n\n# Get the tool call\nmsg.tool_calls\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/workflows-agents",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Workflows + agents"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "import faiss\nfrom langchain_community.docstore.in_memory import InMemoryDocstore\nfrom langchain_community.vectorstores import FAISS\n\nembedding_dim = len(embeddings.embed_query(\"hello world\"))\nindex = faiss.IndexFlatL2(embedding_dim)\n\nvector_store = FAISS(\n    embedding_function=embeddings,\n    index=index,\n    docstore=InMemoryDocstore(),\n    index_to_docstore_id={},\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "SerpApi",
        "type": "code",
        "content": "from langchain_community.utilities import SerpAPIWrapper\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Reads",
        "type": "code",
        "content": "from langchain.tools import tool, ToolRuntime\nfrom langchain.agents import create_agent\n\n@tool\ndef check_authentication(\n    runtime: ToolRuntime\n) -> str:\n    \"\"\"Check if user is authenticated.\"\"\"\n    # Read from State: check current auth status\n    current_state = runtime.state\n    is_authenticated = current_state.get(\"authenticated\", False)\n\n    if is_authenticated:\n        return \"User is authenticated\"\n    else:\n        return \"User is not authenticated\"\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[check_authentication]\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Common patterns",
        "type": "text",
        "content": "The key thing that interrupts unlock is the ability to pause execution and wait for external input. This is useful for a variety of use cases, including:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Before agent guardrails",
        "type": "code",
        "content": "from typing import Any\n\nfrom langchain.agents.middleware import AgentMiddleware, AgentState, hook_config\nfrom langgraph.runtime import Runtime\n\nclass ContentFilterMiddleware(AgentMiddleware):\n    \"\"\"Deterministic guardrail: Block requests containing banned keywords.\"\"\"\n\n    def __init__(self, banned_keywords: list[str]):\n        super().__init__()\n        self.banned_keywords = [kw.lower() for kw in banned_keywords]\n\n    @hook_config(can_jump_to=[\"end\"])\n    def before_agent(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n        # Get the first user message\n        if not state[\"messages\"]:\n            return None\n\n        first_message = state[\"messages\"][0]\n        if first_message.type != \"human\":\n            return None\n\n        content = first_message.content.lower()\n\n        # Check for banned keywords\n        for keyword in self.banned_keywords:\n            if keyword in content:\n                # Block execution before any processing\n                return {\n                    \"messages\": [{\n                        \"role\": \"assistant\",\n                        \"content\": \"I cannot process requests containing inappropriate content. Please rephrase your request.\"\n                    }],\n                    \"jump_to\": \"end\"\n                }\n\n        return None\n\n# Use the custom guardrail\nfrom langchain.agents import create_agent\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[search_tool, calculator_tool],\n    middleware=[\n        ContentFilterMiddleware(\n            banned_keywords=[\"hack\", \"exploit\", \"malware\"]\n        ),\n    ],\n)\n\n# This request will be blocked before any processing\nresult = agent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"How do I hack into a database?\"}]\n})\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/guardrails",
        "head_menu_name": "LangChain",
        "side_menu_name": "Guardrails"
    },
    {
        "title": "HuggingFaceEmbeddings",
        "type": "code",
        "content": "HuggingFaceEmbeddings",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Get state",
        "type": "code",
        "content": "StateSnapshot(\n    values={'foo': 'b', 'bar': ['a', 'b']},\n    next=(),\n    config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef663ba-28fe-6528-8002-5a559208592c'}},\n    metadata={'source': 'loop', 'writes': {'node_b': {'foo': 'b', 'bar': ['b']}}, 'step': 2},\n    created_at='2024-08-29T19:19:38.821749+00:00',\n    parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef663ba-28f9-6ec4-8001-31981c2c39f8'}}, tasks=()\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "YouTube Transcripts Loader",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Cloud SQL for SQL Server",
        "type": "text",
        "content": "Google Cloud SQL for SQL Server is a fully-managed SQL Server database service.\n\nInstall the python package:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Repository structure",
        "type": "code",
        "content": "langchain-google-genai",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Document AI Warehouse",
        "type": "text",
        "content": "Search, store, and manage documents using Document AI Warehouse .\n\nNote: GoogleDocumentAIWarehouseRetriever (from langchain ) is deprecated. Use DocumentAIWarehouseRetriever from langchain-google-community .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Summarization",
        "type": "text",
        "content": "Model for generating summaries\n\nToken threshold for triggering summarization\n\nRecent messages to preserve\n\nCustom token counting function. Defaults to character-based counting.\n\nCustom prompt template. Uses built-in template if not specified.\n\nPrefix for summary messages",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "All providers",
        "type": "text",
        "content": "See all providers or search for a provider using the search field.\n\nIf you’d like to contribute an integration, see our contributing guide .\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/overview",
        "head_menu_name": "Integrations",
        "side_menu_name": "Overview"
    },
    {
        "title": "Dropped Python 3.9 support",
        "type": "text",
        "content": "All LangChain packages now require Python 3.10 or higher . Python 3.9 reaches end of life in October 2025.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "YouTube Transcripts Loader",
        "type": "code",
        "content": "youtube-transcript-api",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "VertexPairWiseStringEvaluator",
        "type": "code",
        "content": "from langchain_google_vertexai.evaluators.evaluation import VertexPairWiseStringEvaluator\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Repository structure",
        "type": "code",
        "content": "langchain-standard-tests",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Static model",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain_openai import ChatOpenAI\n\nmodel = ChatOpenAI(\n    model=\"gpt-5\",\n    temperature=0.1,\n    max_tokens=1000,\n    timeout=30\n    # ... (other params)\n)\nagent = create_agent(model, tools=tools)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Tool error handling",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import wrap_tool_call\nfrom langchain_core.messages import ToolMessage\n\n\n@wrap_tool_call\ndef handle_tool_errors(request, handler):\n    \"\"\"Handle tool execution errors with custom messages.\"\"\"\n    try:\n        return handler(request)\n    except Exception as e:\n        # Return a custom error message to the model\n        return ToolMessage(\n            content=f\"Tool error: Please check your input and try again. ({str(e)})\",\n            tool_call_id=request.tool_call[\"id\"]\n        )\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[search, get_weather],\n    middleware=[handle_tool_errors]\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Agents",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/workflows-agents",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Workflows + agents"
    },
    {
        "title": "Dynamic model",
        "type": "text",
        "content": "Dynamic models are selected at runtime based on the current state and context. This enables sophisticated routing logic and cost optimization.\n\nTo use a dynamic model, create middleware using the @wrap_model_call decorator that modifies the model in the request:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Microsoft OneDrive File",
        "type": "text",
        "content": "Microsoft OneDrive (formerly SkyDrive ) is a file-hosting service operated by Microsoft.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Recording & Replaying HTTP Calls",
        "type": "code",
        "content": "test_agent_trajectory.yaml",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Quick fix: submit a bugfix",
        "type": "text",
        "content": "Fix the bug while following our code quality standards\n\nInclude unit tests that fail without your fix. This allows us to verify the bug is resolved and prevents regressions\n\nEnsure all tests pass locally before submitting your PR",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Vertex AI Vector Search",
        "type": "text",
        "content": "Vector search using Datastore for document storage.\n\nSee usage example .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Standard content blocks",
        "type": "code",
        "content": "from langchain.chat_models import init_chat_model\n\nmodel = init_chat_model(\"gpt-5-nano\", output_version=\"v1\")\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Deploy",
        "type": "text",
        "content": "LangSmith is the fastest way to turn agents into production systems. Traditional hosting platforms are built for stateless, short-lived web apps, while LangGraph is purpose-built for stateful, long-running agents , so you can go from repo to reliable cloud deployment in minutes.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/deploy",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Deploy"
    },
    {
        "title": "Memory storage",
        "type": "text",
        "content": "For more information about the memory store, see the Persistence guide.\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/concepts/memory",
        "head_menu_name": "Learn",
        "side_menu_name": "Memory"
    },
    {
        "title": "Tool calling strategy",
        "type": "code",
        "content": "class ToolStrategy(Generic[SchemaT]):\n    schema: type[SchemaT]\n    tool_message_content: str | None\n    handle_errors: Union[\n        bool,\n        str,\n        type[Exception],\n        tuple[type[Exception], ...],\n        Callable[[Exception], str],\n    ]\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Log probabilities",
        "type": "code",
        "content": "model = init_chat_model(\n    model=\"gpt-4o\",\n    model_provider=\"openai\"\n).bind(logprobs=True)\n\nresponse = model.invoke(\"Why do parrots talk?\")\nprint(response.response_metadata[\"logprobs\"])\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "The agent loop",
        "type": "text",
        "content": "A typical agent loop consists of two main steps:\n\nThis loop continues until the LLM decides to finish.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Encryption",
        "type": "text",
        "content": "When running on LangSmith, encryption is automatically enabled whenever LANGGRAPH_AES_KEY is present, so you only need to provide the environment variable. Other encryption schemes can be used by implementing CipherProtocol and supplying it to EncryptedSerializer .",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Before agent guardrails",
        "type": "text",
        "content": "Use “before agent” hooks to validate requests once at the start of each invocation. This is useful for session-level checks like authentication, rate limiting, or blocking inappropriate requests before any processing begins.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/guardrails",
        "head_menu_name": "LangChain",
        "side_menu_name": "Guardrails"
    },
    {
        "title": "Vertex AI Search",
        "type": "code",
        "content": "google-cloud-discoveryengine",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Microsoft Word",
        "type": "text",
        "content": "Microsoft Word is a word processor developed by Microsoft.\n\nSee a usage example .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Inside middleware",
        "type": "text",
        "content": "You can access runtime information in middleware to create dynamic prompts, modify messages, or control agent behavior based on user context.\n\nUse request.runtime to access the Runtime object inside middleware decorators. The runtime object is available in the ModelRequest parameter passed to middleware functions.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/runtime",
        "head_menu_name": "LangChain",
        "side_menu_name": "Runtime"
    },
    {
        "title": "Install",
        "type": "code",
        "content": "from langgraph.graph import StateGraph, MessagesState, START, END\n\ndef mock_llm(state: MessagesState):\n    return {\"messages\": [{\"role\": \"ai\", \"content\": \"hello world\"}]}\n\ngraph = StateGraph(MessagesState)\ngraph.add_node(mock_llm)\ngraph.add_edge(START, \"mock_llm\")\ngraph.add_edge(\"mock_llm\", END)\ngraph = graph.compile()\n\ngraph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"hi!\"}]})\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/overview",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Overview"
    },
    {
        "title": "Specify a backend",
        "type": "code",
        "content": "create_deep_agent(backend=...)",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Middleware",
        "type": "text",
        "content": "Great agents require context engineering : getting the right information to the model at the right time. Middleware helps you control dynamic prompts, conversation summarization, selective tool access, state management, and guardrails through a composable abstraction.",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Checkpoints",
        "type": "text",
        "content": "The state of a thread at a particular point in time is called a checkpoint. Checkpoint is a snapshot of the graph state saved at each super-step and is represented by StateSnapshot object with the following key properties:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Using in LangGraph",
        "type": "text",
        "content": "See the deployment guide for more details and configuration options.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Hugging Face dataset",
        "type": "code",
        "content": "pip install datasets\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Post-model hook",
        "type": "text",
        "content": "Common use cases include:\n\nv1 has a built in middleware for human in the loop approval for tool calls:",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Add metadata to traces",
        "type": "text",
        "content": "This custom metadata and tags will be attached to the trace in LangSmith.\n\nTo learn more about how to use traces to debug, evaluate, and monitor your agents, see the LangSmith documentation .\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/observability",
        "head_menu_name": "LangChain",
        "side_menu_name": "Observability"
    },
    {
        "title": "Use in production",
        "type": "code",
        "content": "from langchain.chat_models import init_chat_model\nfrom langgraph.graph import StateGraph, MessagesState, START\nfrom langgraph.checkpoint.postgres import PostgresSaver  \n\nmodel = init_chat_model(model=\"claude-haiku-4-5-20251001\")\n\nDB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\nwith PostgresSaver.from_conn_string(DB_URI) as checkpointer:  \n    # checkpointer.setup()\n\n    def call_model(state: MessagesState):\n        response = model.invoke(state[\"messages\"])\n        return {\"messages\": response}\n\n    builder = StateGraph(MessagesState)\n    builder.add_node(call_model)\n    builder.add_edge(START, \"call_model\")\n\n    graph = builder.compile(checkpointer=checkpointer)  \n\n    config = {\n        \"configurable\": {\n            \"thread_id\": \"1\"\n        }\n    }\n\n    for chunk in graph.stream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"hi! I'm bob\"}]},\n        config,  \n        stream_mode=\"values\"\n    ):\n        chunk[\"messages\"][-1].pretty_print()\n\n    for chunk in graph.stream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what's my name?\"}]},\n        config,  \n        stream_mode=\"values\"\n    ):\n        chunk[\"messages\"][-1].pretty_print()\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Microsoft Azure PowerBI",
        "type": "code",
        "content": "pip install azure-identity\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Basic usage",
        "type": "text",
        "content": "The simplest way to use messages is to create message objects and pass them to a model when invoking .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Checkpoints",
        "type": "text",
        "content": "Checkpoints are persisted and can be used to restore the state of a thread at a later time.\n\nLet’s see what checkpoints are saved when a simple graph is invoked as follows:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Log to a project",
        "type": "code",
        "content": "export LANGSMITH_PROJECT=my-agent-project\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/observability",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Observability"
    },
    {
        "title": "Stream custom data",
        "type": "code",
        "content": "from typing import TypedDict\nfrom langgraph.config import get_stream_writer\nfrom langgraph.graph import StateGraph, START\n\nclass State(TypedDict):\n    query: str\n    answer: str\n\ndef node(state: State):\n    # Get the stream writer to send custom data\n    writer = get_stream_writer()\n    # Emit a custom key-value pair (e.g., progress update)\n    writer({\"custom_key\": \"Generating custom data inside node\"})\n    return {\"answer\": \"some data\"}\n\ngraph = (\n    StateGraph(State)\n    .add_node(node)\n    .add_edge(START, \"node\")\n    .compile()\n)\n\ninputs = {\"query\": \"example\"}\n\n# Set stream_mode=\"custom\" to receive the custom data in the stream\nfor chunk in graph.stream(inputs, stream_mode=\"custom\"):\n    print(chunk)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Document loaders",
        "type": "text",
        "content": "Document loaders provide a standard interface for reading data from different sources (such as Slack, Notion, or Google Drive) into LangChain’s Document format.\nThis ensures that data can be handled consistently regardless of the source.\n\nAll document loaders implement the BaseLoader interface.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/document_loaders",
        "head_menu_name": "Integrations",
        "side_menu_name": "Document loaders"
    },
    {
        "title": "Reasoning",
        "type": "text",
        "content": "For details, see the integrations page or reference for your respective chat model.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Example: Summarization",
        "type": "text",
        "content": "The summarized conversation history is permanently updated - future turns will see the summary instead of the original messages.\n\nFor a complete list of built-in middleware, available hooks, and how to create custom middleware, see the Middleware documentation .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "System prompt",
        "type": "code",
        "content": "from deepagents import create_deep_agent\n\nresearch_instructions = \"\"\"\\\nYou are an expert researcher. Your job is to conduct \\\nthorough research, and then write a polished report. \\\n\"\"\"\n\nagent = create_deep_agent(\n    system_prompt=research_instructions,\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/customization",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Customization"
    },
    {
        "title": "Human input is first-class",
        "type": "text",
        "content": "The interrupt() function pauses execution indefinitely, saves all state, and resumes exactly where it left off when you provide input. When combined with other operations in a node, it must come first.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Amazon Bedrock (Knowledge Bases)",
        "type": "code",
        "content": "pip install langchain-aws\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "3. Update the state",
        "type": "code",
        "content": "{'configurable': {'thread_id': 'c62e2e03-c27b-4cb6-8cea-ea9bfedae006', 'checkpoint_ns': '', 'checkpoint_id': '1f02ac4a-ecee-600b-8002-a1d21df32e4c'}}\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-time-travel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Time travel"
    },
    {
        "title": "HuggingFaceEndpointEmbeddings",
        "type": "text",
        "content": "We can use the HuggingFaceEndpointEmbeddings class to run open source embedding models via a dedicated Inference Endpoint .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Full development setup",
        "type": "text",
        "content": "For ongoing development or larger contributions:\n\nSet up your environment following our setup guide below\n\nUnderstand the repository structure and package organization\n\nLearn our development workflow including testing and linting\n\nReview our contribution guidelines for features, bugfixes, and integrations",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Stream Writer",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "Namespace",
        "type": "code",
        "content": "langchain.chat_models",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Stream",
        "type": "text",
        "content": "As opposed to invoke() , which returns a single AIMessage after the model has finished generating its full response, stream() returns multiple AIMessageChunk objects, each containing a portion of the output text. Importantly, each chunk in a stream is designed to be gathered into a full message via summation:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Azure SQL Database",
        "type": "code",
        "content": "!pip install langchain-sqlserver==0.1.1\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Use a virtual filesystem",
        "type": "code",
        "content": "WHERE path LIKE $1 || '%'",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Basic Usage",
        "type": "code",
        "content": "user_id = \"1\"\nnamespace_for_memory = (user_id, \"memories\")\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Build a real-world agent",
        "type": "text",
        "content": "Add memory to your agent to maintain state across interactions. This allows\nthe agent to remember previous conversations and context.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/quickstart",
        "head_menu_name": "LangChain",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Basic Usage",
        "type": "code",
        "content": "memory_id = str(uuid.uuid4())\nmemory = {\"food_preference\" : \"I like pizza\"}\nin_memory_store.put(namespace_for_memory, memory_id, memory)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "4. Create a LangGraph config file",
        "type": "text",
        "content": "create_agent automatically returns a compiled LangGraph graph that we can pass to the graphs key in our configuration file.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/studio",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Studio"
    },
    {
        "title": "Accessing Context",
        "type": "text",
        "content": "Why this matters: Tools are most powerful when they can access agent state, runtime context, and long-term memory. This enables tools to make context-aware decisions, personalize responses, and maintain information across conversations.\n\nTools can access runtime information through the ToolRuntime parameter, which provides:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "6. Test your application in Studio",
        "type": "code",
        "content": "langgraph dev --tunnel\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/local-server",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Local server"
    },
    {
        "title": "Use MCP tools",
        "type": "code",
        "content": "langchain-mcp-adapters",
        "side_link": "https://docs.langchain.com/oss/python/langchain/mcp",
        "head_menu_name": "LangChain",
        "side_menu_name": "Model Context Protocol (MCP)"
    },
    {
        "title": "File structure",
        "type": "code",
        "content": "my-app/\n├── my_agent # all project code lies within here\n│   ├── utils # utilities for your graph\n│   │   ├── __init__.py\n│   │   ├── tools.py # tools for your graph\n│   │   ├── nodes.py # node functions for your graph\n│   │   └── state.py # state definition of your graph\n│   ├── __init__.py\n│   └── agent.py # code for constructing your graph\n├── .env # environment variables\n├── requirements.txt # package dependencies\n└── langgraph.json # configuration file for LangGraph\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/application-structure",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Application structure"
    },
    {
        "title": "Quick edit: fix a typo",
        "type": "text",
        "content": "GitHub will redirect you to create a pull request. Give it a title (often the same as the commit) and follow the PR template checklist, if present\n\nDocs PRs are typically reviewed within a few days. Keep an eye on your PR to address any feedback from maintainers. Do not bump the PR unless you have new information to provide - maintainers will address it as their availability permits.",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "ZhipuAI",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/text_embedding",
        "head_menu_name": "Integrations",
        "side_menu_name": "Embedding models"
    },
    {
        "title": "CompositeBackend (router)",
        "type": "code",
        "content": "from deepagents import create_deep_agent\nfrom deepagents.backends import FilesystemBackend\nfrom deepagents.backends.composite import build_composite_state_backend\n\ncomposite_backend = lambda rt: CompositeBackend(\n    default=StateBackend(rt)\n    routes={\n        \"/memories/\": StoreBackend(rt),\n        \"/docs/\": CustomBackend()\n    }\n)\n\nagent = create_deep_agent(backend=composite_backend)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "LangGraph",
        "type": "text",
        "content": "If no issue exists, create a new one. When writing, be sure to follow the template provided and to include a minimal, reproducible, example . Attach any relevant labels to the final issue once created. If a project maintainer is unable to reproduce the issue, it is unlikely to be addressed in a timely manner.\n\nA project maintainer will triage the issue and may ask for additional information. Please be patient as we manage a high volume of issues. Do not bump the issue unless you have new information to provide.\n\nIf you are adding an issue, please try to keep it focused on a single topic. If two issues are related, or blocking, please link them rather than combining them. For example,",
        "side_link": "https://docs.langchain.com/oss/python/contributing/overview",
        "head_menu_name": "Contribute",
        "side_menu_name": "Overview"
    },
    {
        "title": "Write short-term memory from tools",
        "type": "text",
        "content": "To modify the agent’s short-term memory (state) during execution, you can return state updates directly from the tools.\n\nThis is useful for persisting intermediate results or making information accessible to subsequent tools or prompts.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Dynamically selecting tools",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import AgentMiddleware, ModelRequest\nfrom typing import Callable\n\n\nclass ToolSelectorMiddleware(AgentMiddleware):\n    def wrap_model_call(\n        self,\n        request: ModelRequest,\n        handler: Callable[[ModelRequest], ModelResponse],\n    ) -> ModelResponse:\n        \"\"\"Middleware to select relevant tools based on state/context.\"\"\"\n        # Select a small, relevant subset of tools based on state/context\n        relevant_tools = select_relevant_tools(request.state, request.runtime)\n        request.tools = relevant_tools\n        return handler(request)\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=all_tools,  # All available tools need to be registered upfront\n    # Middleware can be used to select a smaller subset that's relevant for the given run.\n    middleware=[ToolSelectorMiddleware()],\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Agent progress",
        "type": "text",
        "content": "To stream agent progress, use the stream or astream methods with stream_mode=\"updates\" . This emits an event after every agent step.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/streaming",
        "head_menu_name": "LangChain",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Simplified package",
        "type": "text",
        "content": "LangChain v1 streamlines the langchain package namespace to focus on essential building blocks for agents. The refined namespace exposes the most useful and relevant functionality:",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Invocation",
        "type": "code",
        "content": "result = agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"What's the weather in San Francisco?\"}]}\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Agent jumps",
        "type": "code",
        "content": "from langchain.agents.middleware import AgentMiddleware, hook_config\nfrom typing import Any\n\nclass ConditionalMiddleware(AgentMiddleware):\n    @hook_config(can_jump_to=[\"end\", \"tools\"])\n    def after_model(self, state: AgentState, runtime) -> dict[str, Any] | None:\n        if some_condition(state):\n            return {\"jump_to\": \"end\"}\n        return None\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Stateful tool usage",
        "type": "text",
        "content": "For stateful servers that maintain context between tool calls, use client.session() to create a persistent ClientSession .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/mcp",
        "head_menu_name": "LangChain",
        "side_menu_name": "Model Context Protocol (MCP)"
    },
    {
        "title": "LLM-as-Judge Evaluator",
        "type": "code",
        "content": "evaluator = create_trajectory_llm_as_judge(\n    model=\"openai:o3-mini\",\n    prompt=TRAJECTORY_ACCURACY_PROMPT_WITH_REFERENCE,\n)\nevaluation = judge_with_reference(\n    outputs=result[\"messages\"],\n    reference_outputs=reference_trajectory,\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Overview",
        "type": "text",
        "content": "The hard part of building agents (or any LLM application) is making them reliable enough. While they may work for a prototype, they often fail in real-world use cases.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "Popular providers",
        "type": "code",
        "content": "langchain-nvidia-ai-endpoints",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/overview",
        "head_menu_name": "Integrations",
        "side_menu_name": "Overview"
    },
    {
        "title": "Handle interrupts",
        "type": "code",
        "content": "import uuid\nfrom langgraph.types import Command\n\n# Create config with thread_id for state persistence\nconfig = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n\n# Invoke the agent\nresult = agent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"Delete the file temp.txt\"}]\n}, config=config)\n\n# Check if execution was interrupted\nif result.get(\"__interrupt__\"):\n    # Extract interrupt information\n    interrupts = result[\"__interrupt__\"][0].value\n    action_requests = interrupts[\"action_requests\"]\n    review_configs = interrupts[\"review_configs\"]\n\n    # Create a lookup map from tool name to review config\n    config_map = {cfg[\"action_name\"]: cfg for cfg in review_configs}\n\n    # Display the pending actions to the user\n    for action in action_requests:\n        review_config = config_map[action[\"name\"]]\n        print(f\"Tool: {action['name']}\")\n        print(f\"Arguments: {action['args']}\")\n        print(f\"Allowed decisions: {review_config['allowed_decisions']}\")\n\n    # Get user decisions (one per action_request, in order)\n    decisions = [\n        {\"type\": \"approve\"}  # User approved the deletion\n    ]\n\n    # Resume execution with decisions\n    result = agent.invoke(\n        Command(resume={\"decisions\": decisions}),\n        config=config  # Must use the same config!\n    )\n\n# Process final result\nprint(result[\"messages\"][-1][\"content\"])\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/human-in-the-loop",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Acknowledgements",
        "type": "text",
        "content": "LangGraph is inspired by Pregel and Apache Beam . The public interface draws inspiration from NetworkX . LangGraph is built by LangChain Inc, the creators of LangChain, but can be used without LangChain.\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/overview",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Overview"
    },
    {
        "title": "Tool Message",
        "type": "text",
        "content": "The stringified output of the tool call.\n\nThe ID of the tool call that this message is responding to. (this must match the ID of the tool call in the AIMessage )",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "config",
        "type": "text",
        "content": "The config should contain thread_id specifying which thread to update. When only the thread_id is passed, we update (or fork) the current state. Optionally, if we include checkpoint_id field, then we fork that selected checkpoint.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Checkpointer libraries",
        "type": "code",
        "content": "langgraph-checkpoint-sqlite",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Agent Chat UI",
        "type": "text",
        "content": "LangChain provides a powerful prebuilt user interface that work seamlessly with agents created using create_agent . This UI is designed to provide rich, interactive experiences for your agents with minimal setup, whether you’re running locally or in a deployed context (such as LangSmith ).",
        "side_link": "https://docs.langchain.com/oss/python/langchain/ui",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agent Chat UI"
    },
    {
        "title": "Manage checkpoints",
        "type": "text",
        "content": "You can view and delete the information stored by the checkpointer.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Chat models",
        "type": "text",
        "content": "Use the ChatGoogleGenerativeAI class to interact with Gemini models. See\ndetails in this guide .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "3. Environment variables",
        "type": "code",
        "content": "LANGSMITH_API_KEY=lsv2...\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/studio",
        "head_menu_name": "LangChain",
        "side_menu_name": "Studio"
    },
    {
        "title": "Vertex AI visual QnA",
        "type": "code",
        "content": "langchain-google-vertexai",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Review and edit state",
        "type": "text",
        "content": "Sometimes you want to let a human review and edit part of the graph state before continuing. This is useful for correcting LLMs, adding missing information, or making adjustments.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Handle errors appropriately",
        "type": "code",
        "content": "from langgraph.types import RetryPolicy\n\nworkflow.add_node(\n    \"search_documentation\",\n    search_documentation,\n    retry_policy=RetryPolicy(max_attempts=3, initial_interval=1.0)\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Google Trends",
        "type": "code",
        "content": "google-search-results",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Delete messages",
        "type": "code",
        "content": "from langchain.messages import RemoveMessage  \n\ndef delete_messages(state):\n    messages = state[\"messages\"]\n    if len(messages) > 2:\n        # remove the earliest two messages\n        return {\"messages\": [RemoveMessage(id=m.id) for m in messages[:2]]}  \n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Cloud Providers",
        "type": "code",
        "content": "AzureBlobStorageLoader",
        "side_link": "https://docs.langchain.com/oss/python/integrations/document_loaders",
        "head_menu_name": "Integrations",
        "side_menu_name": "Document loaders"
    },
    {
        "title": "Simplified namespace",
        "type": "code",
        "content": "pip install -U langchain\n",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "UpstashRedisByteStore",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/stores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Key-value stores"
    },
    {
        "title": "Tool calls",
        "type": "code",
        "content": "from langchain.chat_models import init_chat_model\n\nmodel = init_chat_model(\"gpt-5-nano\")\n\ndef get_weather(location: str) -> str:\n    \"\"\"Get the weather at a location.\"\"\"\n    ...\n\nmodel_with_tools = model.bind_tools([get_weather])\nresponse = model_with_tools.invoke(\"What's the weather in Paris?\")\n\nfor tool_call in response.tool_calls:\n    print(f\"Tool: {tool_call['name']}\")\n    print(f\"Args: {tool_call['args']}\")\n    print(f\"ID: {tool_call['id']}\")\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Filter by node",
        "type": "code",
        "content": "# The \"messages\" stream mode returns a tuple of (message_chunk, metadata)\n# where message_chunk is the token streamed by the LLM and metadata is a dictionary\n# with information about the graph node where the LLM was called and other information\nfor msg, metadata in graph.stream(\n    inputs,\n    stream_mode=\"messages\",  \n):\n    # Filter the streamed tokens by the langgraph_node field in the metadata\n    # to only include the tokens from the specified node\n    if msg.content and metadata[\"langgraph_node\"] == \"some_node_name\":\n        ...\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Document AI Warehouse",
        "type": "code",
        "content": "GoogleDocumentAIWarehouseRetriever",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Content block reference",
        "type": "code",
        "content": "{\n    \"type\": \"reasoning\",\n    \"reasoning\": \"The user is asking about...\",\n    \"extras\": {\"signature\": \"abc123\"},\n}\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Import path",
        "type": "text",
        "content": "The import path for the agent prebuilt has changed from langgraph.prebuilt to langchain.agents .\nThe name of the function has changed from create_react_agent to create_agent :",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Approve or reject",
        "type": "code",
        "content": "# To approve\ngraph.invoke(Command(resume=True), config=config)\n\n# To reject\ngraph.invoke(Command(resume=False), config=config)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Serialization withpickle",
        "type": "code",
        "content": "from langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.checkpoint.serde.jsonplus import JsonPlusSerializer\n\n# ... Define the graph ...\ngraph.compile(\n    checkpointer=InMemorySaver(serde=JsonPlusSerializer(pickle_fallback=True))\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Getting help",
        "type": "text",
        "content": "Our goal is to have the most accessible developer setup possible. Should you experience any difficulty getting setup, please ask in the community slack or open a forum post .\n\nYou’re now ready to contribute high-quality code to LangChain!\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Llama on Vertex AI Model Garden",
        "type": "code",
        "content": "from langchain_google_vertexai.model_garden_maas.llama import VertexModelGardenLlama\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Parallelization",
        "type": "text",
        "content": "With parallelization, LLMs work simultaneously on a task. This is either done by running multiple independent subtasks at the same time, or running the same task multiple times to check for different outputs. Parallelization is commonly used to:\n\nSome examples include:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/workflows-agents",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Workflows + agents"
    },
    {
        "title": "ProviderStrategy",
        "type": "code",
        "content": "response_format=ContactInfo",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Gemma local from Hugging Face",
        "type": "code",
        "content": "langchain-google-vertexai",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "2. Create a LangGraph app 🌱",
        "type": "code",
        "content": "langgraph new path/to/your/app --template new-langgraph-project-python\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/local-server",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Local server"
    },
    {
        "title": "Gemma local from Hugging Face",
        "type": "code",
        "content": "from langchain_google_vertexai.gemma import GemmaLocalHF\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "LLM Steps",
        "type": "text",
        "content": "Use when you need to understand, analyze, generate text, or make reasoning decisions",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Error handling strategies",
        "type": "text",
        "content": "You can customize how errors are handled using the handle_errors parameter:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Text property",
        "type": "text",
        "content": "Existing usage patterns (i.e., .text() ) will continue to function but now emit a warning. The method form will be removed in v2.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Summarize messages",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import SummarizationMiddleware\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langchain_core.runnables import RunnableConfig\n\n\ncheckpointer = InMemorySaver()\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[],\n    middleware=[\n        SummarizationMiddleware(\n            model=\"gpt-4o-mini\",\n            max_tokens_before_summary=4000,  # Trigger summarization at 4000 tokens\n            messages_to_keep=20,  # Keep last 20 messages after summary\n        )\n    ],\n    checkpointer=checkpointer,\n)\n\nconfig: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\nagent.invoke({\"messages\": \"hi, my name is bob\"}, config)\nagent.invoke({\"messages\": \"write a short poem about cats\"}, config)\nagent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\nfinal_response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n\nfinal_response[\"messages\"][-1].pretty_print()\n\"\"\"\n================================== Ai Message ==================================\n\nYour name is Bob!\n\"\"\"\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Azure AI",
        "type": "text",
        "content": "Azure AI Foundry provides access to a wide range of models from various providers including Azure OpenAI, DeepSeek R1, Cohere, Phi and Mistral through the AzureAIChatCompletionsModel class.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Running tests locally",
        "type": "text",
        "content": "Before submitting your PR, ensure you have completed the following steps. Note that the requirements differ slightly between LangChain and LangGraph.",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Retry Logic",
        "type": "text",
        "content": "Implement retry logic with exponential backoff for failed operations\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Model fallback",
        "type": "text",
        "content": "First fallback model to try when the primary model fails. Can be a model string (e.g., \"openai:gpt-4o-mini\" ) or a BaseChatModel instance.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Do not reorderinterruptcalls within a node",
        "type": "code",
        "content": "def node_a(state: State):\n    # ❌ Bad: conditionally skipping interrupts changes the order\n    name = interrupt(\"What's your name?\")\n\n    # On first run, this might skip the interrupt\n    # On resume, it might not skip it - causing index mismatch\n    if state.get(\"needs_age\"):\n        age = interrupt(\"What's your age?\")\n\n    city = interrupt(\"What's your city?\")\n\n    return {\"name\": name, \"city\": city}\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "AzureCosmosDBNoSqlVectorStore",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Interface",
        "type": "code",
        "content": "embed_query(text: str) → List[float]",
        "side_link": "https://docs.langchain.com/oss/python/integrations/text_embedding",
        "head_menu_name": "Integrations",
        "side_menu_name": "Embedding models"
    },
    {
        "title": "Response Format",
        "type": "code",
        "content": "ToolStrategy[StructuredResponseT]",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Starting Points for Resuming Workflows",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/durable-execution",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Durable execution"
    },
    {
        "title": "Configuration file",
        "type": "text",
        "content": "The langgraph.json file is a JSON file that specifies the dependencies, graphs, environment variables, and other settings required to deploy a LangGraph application.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/application-structure",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Application structure"
    },
    {
        "title": "2. Identify a checkpoint",
        "type": "code",
        "content": "# The states are returned in reverse chronological order.\nstates = list(graph.get_state_history(config))\n\nfor state in states:\n    print(state.next)\n    print(state.config[\"configurable\"][\"checkpoint_id\"])\n    print()\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-time-travel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Time travel"
    },
    {
        "title": "6. View your agent in Studio",
        "type": "code",
        "content": "https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024",
        "side_link": "https://docs.langchain.com/oss/python/langchain/studio",
        "head_menu_name": "LangChain",
        "side_menu_name": "Studio"
    },
    {
        "title": "Stateful tool usage",
        "type": "code",
        "content": "from langchain_mcp_adapters.tools import load_mcp_tools\n\nclient = MultiServerMCPClient({...})\nasync with client.session(\"math\") as session:\n    tools = await load_mcp_tools(session)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/mcp",
        "head_menu_name": "LangChain",
        "side_menu_name": "Model Context Protocol (MCP)"
    },
    {
        "title": "Azure Database for PostgreSQL",
        "type": "text",
        "content": "Azure Database for PostgreSQL - Flexible Server is a relational database service based on the open-source Postgres database engine. It’s a fully managed database-as-a-service that can handle mission-critical workloads with predictable performance, security, high availability, and dynamic scalability.\n\nSee set up instructions for Azure Database for PostgreSQL.\n\nSimply use the connection string from your Azure Portal.\n\nSince Azure Database for PostgreSQL is open-source Postgres, you can use the LangChain’s Postgres support to connect to Azure Database for PostgreSQL.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Image captions",
        "type": "code",
        "content": "pip install transformers pillow\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "1. Install the LangGraph CLI",
        "type": "code",
        "content": "# Python >= 3.11 is required.\npip install -U \"langgraph-cli[inmem]\"\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/local-server",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Local server"
    },
    {
        "title": "Search",
        "type": "text",
        "content": "The following table shows tools that execute online searches in some shape or form:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/tools",
        "head_menu_name": "Integrations",
        "side_menu_name": "Tools and toolkits"
    },
    {
        "title": "Build a real-world agent",
        "type": "text",
        "content": "Optionally, define a structured response format if you need the agent responses to match\na specific schema.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/quickstart",
        "head_menu_name": "LangChain",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Implementing our email agent nodes",
        "type": "text",
        "content": "We’ll implement each node as a simple function. Remember: nodes take state, do work, and return updates.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Do not reorderinterruptcalls within a node",
        "type": "code",
        "content": "def node_a(state: State):\n    # ✅ Good: interrupt calls happen in the same order every time\n    name = interrupt(\"What's your name?\")\n    age = interrupt(\"What's your age?\")\n    city = interrupt(\"What's your city?\")\n\n    return {\n        \"name\": name,\n        \"age\": age,\n        \"city\": city\n    }\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "pip install -qU langchain-pinecone\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Microsoft PowerPoint",
        "type": "code",
        "content": "from langchain_community.document_loaders import UnstructuredPowerPointLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Custom tool description",
        "type": "text",
        "content": "Override the auto-generated tool description for clearer model guidance:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "Bigtable",
        "type": "code",
        "content": "pip install langchain-google-bigtable\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Minor changes",
        "type": "code",
        "content": "LanguageModelOutputVar",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Google Drive",
        "type": "code",
        "content": "pip install langchain-google-community[drive]\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Keep system prompts detailed",
        "type": "code",
        "content": "research_subagent = {\n    \"name\": \"research-agent\",\n    \"description\": \"Conducts in-depth research using web search and synthesizes findings\",\n    \"system_prompt\": \"\"\"You are a thorough researcher. Your job is to:\n\n    1. Break down the research question into searchable queries\n    2. Use internet_search to find relevant information\n    3. Synthesize findings into a comprehensive but concise summary\n    4. Cite sources when making claims\n\n    Output format:\n    - Summary (2-3 paragraphs)\n    - Key findings (bullet points)\n    - Sources (with URLs)\n\n    Keep your response under 500 words to maintain clean context.\"\"\",\n    \"tools\": [internet_search],\n}\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Azure Container Apps dynamic sessions",
        "type": "code",
        "content": "POOL_MANAGEMENT_ENDPOINT",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Use classes when",
        "type": "text",
        "content": "• Multiple hooks needed • Complex configuration • Reuse across projects (config on init)",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Co-locate Python and JavaScript/TypeScript content",
        "type": "text",
        "content": "All documentation must be written in both Python and JavaScript/TypeScript when possible. To do so, we use a custom in-line syntax to differentiate between sections that should appear in one or both languages:",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "Base URL or proxy",
        "type": "text",
        "content": "Proxy support varies by integration. Check the specific model provider’s reference for proxy configuration options.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Handling tool errors",
        "type": "code",
        "content": "# Example coming soon\n",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Model-based guardrails",
        "type": "text",
        "content": "Use LLMs or classifiers to evaluate content with semantic understanding. Catch subtle issues that rules miss, but are slower and more expensive.\n\nLangChain provides both built-in guardrails (e.g., PII detection , human-in-the-loop ) and a flexible middleware system for building custom guardrails using either approach.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/guardrails",
        "head_menu_name": "LangChain",
        "side_menu_name": "Guardrails"
    },
    {
        "title": "Advanced schema definition",
        "type": "text",
        "content": "Define complex inputs with Pydantic models or JSON schemas:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "Orchestrator-worker",
        "type": "text",
        "content": "In an orchestrator-worker configuration, the orchestrator:\n\nOrchestrator-worker workflows provide more flexibility and are often used when subtasks cannot be predefined the way they can with parallelization . This is common with workflows that write code or need to update content across multiple files. For example, a workflow that needs to update installation instructions for multiple Python libraries across an unknown number of documents might use this pattern.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/workflows-agents",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Workflows + agents"
    },
    {
        "title": "Microsoft Azure PowerBI",
        "type": "code",
        "content": "from langchain_community.agent_toolkits import PowerBIToolkit\nfrom langchain_community.utilities.powerbi import PowerBIDataset\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Text-to-Speech",
        "type": "code",
        "content": "from langchain_google_community import TextToSpeechTool\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "pip install -qU langchain-postgres\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Reads",
        "type": "text",
        "content": "Most real-world tools need more than just the LLM’s parameters. They need user IDs for database queries, API keys for external services, or current session state to make decisions. Tools read from state, store, and runtime context to access this information.\n\nRead from State to check current session information:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "langchain-classic",
        "type": "code",
        "content": "pip install langchain-classic\n",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Documentation types",
        "type": "text",
        "content": "Where applicable, all documentation must have translations in both Python and JavaScript/TypeScript. See our localization guide for details.",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "Tool Message",
        "type": "text",
        "content": "For models that support tool calling , AI messages can contain tool calls. Tool messages are used to pass the results of a single tool execution back to the model.\n\nTools can generate ToolMessage objects directly. Below, we show a simple example. Read more in the tools guide .",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Namespace",
        "type": "code",
        "content": "# Agent building\nfrom langchain.agents import create_agent\n\n# Messages and content\nfrom langchain.messages import AIMessage, HumanMessage\n\n# Tools\nfrom langchain.tools import tool\n\n# Model initialization\nfrom langchain.chat_models import init_chat_model\nfrom langchain.embeddings import init_embeddings\n",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Vectara",
        "type": "text",
        "content": "Neural search platform with built-in understanding.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/all_providers",
        "head_menu_name": "Integrations",
        "side_menu_name": "All providers"
    },
    {
        "title": "Interface",
        "type": "text",
        "content": "This abstraction lets you switch between different implementations without altering your application logic.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Testing and validation",
        "type": "text",
        "content": "Before submitting documentation:\n\nRun all code examples to ensure they work correctly",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "Streaming",
        "type": "code",
        "content": "for chunk in agent.stream({\n    \"messages\": [{\"role\": \"user\", \"content\": \"Search for AI news and summarize the findings\"}]\n}, stream_mode=\"values\"):\n    # Each chunk contains the full state at that point\n    latest_message = chunk[\"messages\"][-1]\n    if latest_message.content:\n        print(f\"Agent: {latest_message.content}\")\n    elif latest_message.tool_calls:\n        print(f\"Calling tools: {[tc['name'] for tc in latest_message.tool_calls]}\")\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Observability",
        "type": "text",
        "content": "Traces are a series of steps that your application takes to go from input to output. Each of these individual steps is represented by a run. You can use LangSmith to visualize these execution steps. To use it, enable tracing for your application . This enables you to do the following:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/observability",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Observability"
    },
    {
        "title": "Retrieval",
        "type": "text",
        "content": "Large language models (LLMs) are powerful, but they have two key limitations:\n\nRetrieval addresses these problems by fetching relevant external knowledge at query time. This is the foundation of Retrieval-Augmented Generation (RAG) : enhancing an LLM’s answers with context-specific information.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/retrieval",
        "head_menu_name": "LangChain",
        "side_menu_name": "Retrieval"
    },
    {
        "title": "Tool calling strategy",
        "type": "text",
        "content": "For models that don’t support native structured output, LangChain uses tool calling to achieve the same result. This works with all models that support tool calling, which is most modern models.\n\nTo use this strategy, configure a ToolStrategy :",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Handle errors appropriately",
        "type": "text",
        "content": "Different errors need different handling strategies:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Use in production",
        "type": "code",
        "content": "pip install -U \"psycopg[binary,pool]\" langgraph langgraph-checkpoint-postgres\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Tool call limit",
        "type": "text",
        "content": "Limit the number of tool calls to specific tools or all tools.\n\nPerfect for:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Google Places",
        "type": "code",
        "content": "pip install googlemaps langchain # Requires base langchain\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Agent Chat UI",
        "type": "text",
        "content": "Agent Chat UI is a Next.js application that provides a conversational interface for interacting with any LangChain agent. It supports real-time chat, tool visualization, and advanced features like time-travel debugging and state forking.\n\nAgent Chat UI is open source and can be adapted to your application needs.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/ui",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Agent Chat UI"
    },
    {
        "title": "Summarize messages",
        "type": "code",
        "content": "from langgraph.graph import MessagesState\nclass State(MessagesState):\n    summary: str\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Tool error handling",
        "type": "text",
        "content": "The agent will return a ToolMessage with the custom error message when a tool fails:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Streaming",
        "type": "text",
        "content": "Stream tokens, tool calls, and reasoning traces in real-time",
        "side_link": "https://docs.langchain.com/oss/python/releases/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Release notes"
    },
    {
        "title": "Workflows and agents",
        "type": "text",
        "content": "This guide reviews common workflow and agent patterns.\n\nLangGraph offers several benefits when building agents and workflows, including persistence , streaming , and support for debugging as well as deployment .",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/workflows-agents",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Workflows + agents"
    },
    {
        "title": "System Message",
        "type": "code",
        "content": "from langchain.messages import SystemMessage, HumanMessage\n\nsystem_msg = SystemMessage(\"\"\"\nYou are a senior Python developer with expertise in web frameworks.\nAlways provide code examples and explain your reasoning.\nBe concise but thorough in your explanations.\n\"\"\")\n\nmessages = [\n    system_msg,\n    HumanMessage(\"How do I create a REST API?\")\n]\nresponse = model.invoke(messages)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "BigQuery",
        "type": "code",
        "content": "from langchain_google_community import BigQueryLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Recording & Replaying HTTP Calls",
        "type": "text",
        "content": "Set up your conftest.py file to filter out sensitive information from the cassettes:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Multiple tool calls",
        "type": "code",
        "content": "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n\nresult = agent.invoke({\n    \"messages\": [{\n        \"role\": \"user\",\n        \"content\": \"Delete temp.txt and send an email to admin@example.com\"\n    }]\n}, config=config)\n\nif result.get(\"__interrupt__\"):\n    interrupts = result[\"__interrupt__\"][0].value\n    action_requests = interrupts[\"action_requests\"]\n\n    # Two tools need approval\n    assert len(action_requests) == 2\n\n    # Provide decisions in the same order as action_requests\n    decisions = [\n        {\"type\": \"approve\"},  # First tool: delete_file\n        {\"type\": \"reject\"}    # Second tool: send_email\n    ]\n\n    result = agent.invoke(\n        Command(resume={\"decisions\": decisions}),\n        config=config\n    )\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/human-in-the-loop",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "Memory",
        "type": "text",
        "content": "Defining custom state via middleware is preferred over defining it via state_schema on create_agent because it allows you to keep state extensions conceptually scoped to the relevant middleware and tools.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Interrupts",
        "type": "text",
        "content": "Unlike static breakpoints (which pause before or after specific nodes), interrupts are dynamic —they can be placed anywhere in your code and can be conditional based on your application logic.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Azure Cognitive Services",
        "type": "code",
        "content": "pip install azure-ai-formrecognizer azure-cognitiveservices-speech azure-ai-vision-imageanalysis\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Connect to your agent",
        "type": "code",
        "content": "http://localhost:2024",
        "side_link": "https://docs.langchain.com/oss/python/langchain/ui",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agent Chat UI"
    },
    {
        "title": "Defining state viastate_schema",
        "type": "text",
        "content": "As of langchain 1.0 , custom state schemas must be TypedDict types. Pydantic models and dataclasses are no longer supported. See the v1 migration guide for more details.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/agents",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agents"
    },
    {
        "title": "Collection",
        "type": "text",
        "content": "Finally, using a collection of memories can make it challenging to provide comprehensive context to the model. While individual memories may follow a specific schema, this structure might not capture the full context or relationships between memories. As a result, when using these memories to generate responses, the model may lack important contextual information that would be more readily available in a unified profile approach.\n\nRegardless of memory management approach, the central point is that the agent will use the semantic memories to ground its responses , which often leads to more personalized and relevant interactions.",
        "side_link": "https://docs.langchain.com/oss/python/concepts/memory",
        "head_menu_name": "Learn",
        "side_menu_name": "Memory"
    },
    {
        "title": "Caching",
        "type": "code",
        "content": "document_embedding_cache",
        "side_link": "https://docs.langchain.com/oss/python/integrations/text_embedding",
        "head_menu_name": "Integrations",
        "side_menu_name": "Embedding models"
    },
    {
        "title": "Azure Cosmos DB for MongoDB (vCore)",
        "type": "text",
        "content": "Azure Cosmos DB for MongoDB vCore provides developers with a fully managed MongoDB-compatible database service for building modern applications with a familiar architecture.\n\nWith Cosmos DB for MongoDB vCore, developers can enjoy the benefits of native Azure integrations, low total cost of ownership (TCO), and the familiar vCore architecture when migrating existing applications or building new ones.\n\nSign Up for free to get started today.\n\nSee a usage example .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Deprecations",
        "type": "code",
        "content": "langchain.agents.middleware.human_in_the_loop.HITLRequest",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langgraph-v1",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Inside tools",
        "type": "text",
        "content": "You can access the runtime information inside tools to:\n\nUse the ToolRuntime parameter to access the Runtime object inside a tool.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/runtime",
        "head_menu_name": "LangChain",
        "side_menu_name": "Runtime"
    },
    {
        "title": "Running tests locally",
        "type": "code",
        "content": "make integration_tests\n",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Amazon Bedrock (Knowledge Bases)",
        "type": "text",
        "content": "Knowledge bases for Amazon Bedrock is an Amazon Web Services ( AWS ) offering which lets you quickly build RAG applications by using your\nprivate data to customize foundation model response.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "6. View your agent in Studio",
        "type": "text",
        "content": "Safari blocks localhost connections to Studio. To work around this, run the above command with --tunnel to access Studio via a secure tunnel.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/studio",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Studio"
    },
    {
        "title": "Message prompts",
        "type": "text",
        "content": "Alternatively, you can pass in a list of messages to the model by providing a list of message objects.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Interface",
        "type": "code",
        "content": "mdelete(key: Sequence[str]) -> None",
        "side_link": "https://docs.langchain.com/oss/python/integrations/stores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Key-value stores"
    },
    {
        "title": "Getting started",
        "type": "text",
        "content": "Because many LangGraph agents depend on state, a useful pattern is to create your graph before each test where you use it, then compile it within tests with a new checkpointer instance.\n\nThe below example shows how this works with a simple, linear graph that progresses through node1 and node2 . Each node updates the single state key my_key :",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/test",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Test"
    },
    {
        "title": "YouTube Transcripts Loader",
        "type": "text",
        "content": "Load video transcripts. Requires youtube-transcript-api .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Migrate tocreate_agent",
        "type": "text",
        "content": "The table below outlines what functionality has changed from create_react_agent to create_agent :",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "ScaNN (Local Index)",
        "type": "text",
        "content": "ScaNN includes search space pruning and quantization for Maximum Inner\nProduct Search and also supports other distance functions such as\nEuclidean distance. The implementation is optimized for x86 processors\nwith AVX2 support. See its Google Research github for more details.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "In production",
        "type": "code",
        "content": "pip install langgraph-checkpoint-postgres\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/short-term-memory",
        "head_menu_name": "LangChain",
        "side_menu_name": "Short-term memory"
    },
    {
        "title": "Tool calling strategy",
        "type": "text",
        "content": "The schema defining the structured output format. Supports:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "CompiledSubAgent",
        "type": "text",
        "content": "For complex workflows, use a pre-built LangGraph graph:\n\nFields:",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Hugging Face model loader",
        "type": "code",
        "content": "Hugging Face Models API",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/huggingface",
        "head_menu_name": "Integrations",
        "side_menu_name": "Hugging Face"
    },
    {
        "title": "Conceptual guides",
        "type": "text",
        "content": "Explanations that provide deeper understanding and insights",
        "side_link": "https://docs.langchain.com/oss/python/contributing/documentation",
        "head_menu_name": "Contribute",
        "side_menu_name": "Documentation"
    },
    {
        "title": "4. Resume execution from the checkpoint",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-time-travel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Time travel"
    },
    {
        "title": "Serializer",
        "type": "text",
        "content": "When checkpointers save the graph state, they need to serialize the channel values in the state. This is done using serializer objects.\n\nlanggraph_checkpoint defines protocol for implementing serializers provides a default implementation ( JsonPlusSerializer ) that handles a wide variety of types, including LangChain and LangGraph primitives, datetimes, enums and more.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/persistence",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Persistence"
    },
    {
        "title": "Content we’re excited to promote",
        "type": "text",
        "content": "Blogs, YouTube videos and other media showcasing educational content. Note that we prefer content that is NOT framed as “here’s how to use integration XYZ”, but rather “here’s how to do ABC”, as we find that is more educational and helpful for developers.\n\nEnd-to-end applications are great resources for developers looking to build. We prefer to highlight applications that are more complex/agentic in nature, and that use LangGraph as the orchestration framework. We get particularly excited about anything involving:\n\nWe love highlighting novel research! Whether it is research built on top of LangChain or that integrates with it.\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/contributing/comarketing",
        "head_menu_name": "Contribute",
        "side_menu_name": "Co-marketing"
    },
    {
        "title": "5. Test the API",
        "type": "code",
        "content": "from langgraph_sdk import get_sync_client # or get_client for async\n\nclient = get_sync_client(url=\"your-deployment-url\", api_key=\"your-langsmith-api-key\")\n\nfor chunk in client.runs.stream(\n    None,    # Threadless run\n    \"agent\", # Name of agent. Defined in langgraph.json.\n    input={\n        \"messages\": [{\n            \"role\": \"human\",\n            \"content\": \"What is LangGraph?\",\n        }],\n    },\n    stream_mode=\"updates\",\n):\n    print(f\"Receiving new event of type: {chunk.event}...\")\n    print(chunk.data)\n    print(\"\\n\\n\")\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/deploy",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Deploy"
    },
    {
        "title": "Google Scholar",
        "type": "code",
        "content": "from langchain_community.tools.google_scholar import GoogleScholarQueryRun\nfrom langchain_community.utilities.google_scholar import GoogleScholarAPIWrapper\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "from langchain_aws import BedrockEmbeddings\n\nembeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v2:0\")\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Azure AI Services individual tools",
        "type": "text",
        "content": "The azure_ai_services toolkit includes the tools that queries the Azure Cognitive Services :",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Write clear descriptions",
        "type": "text",
        "content": "The main agent uses descriptions to decide which subagent to call. Be specific:\n\n✅ Good: \"Analyzes financial data and generates investment insights with confidence scores\"",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Add policy hooks",
        "type": "code",
        "content": "from deepagents.backends.filesystem import FilesystemBackend\nfrom deepagents.backends.protocol import WriteResult, EditResult\n\nclass GuardedBackend(FilesystemBackend):\n    def __init__(self, *, deny_prefixes: list[str], **kwargs):\n        super().__init__(**kwargs)\n        self.deny_prefixes = [p if p.endswith(\"/\") else p + \"/\" for p in deny_prefixes]\n\n    def write(self, file_path: str, content: str) -> WriteResult:\n        if any(file_path.startswith(p) for p in self.deny_prefixes):\n            return WriteResult(error=f\"Writes are not allowed under {file_path}\")\n        return super().write(file_path, content)\n\n    def edit(self, file_path: str, old_string: str, new_string: str, replace_all: bool = False) -> EditResult:\n        if any(file_path.startswith(p) for p in self.deny_prefixes):\n            return EditResult(error=f\"Edits are not allowed under {file_path}\")\n        return super().edit(file_path, old_string, new_string, replace_all)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Build a real-world agent",
        "type": "text",
        "content": "To learn how to trace your agent with LangSmith, see the LangSmith documentation .\n\nCongratulations! You now have an AI agent that can:\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/quickstart",
        "head_menu_name": "LangChain",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Use a virtual filesystem",
        "type": "code",
        "content": "from deepagents.backends.protocol import BackendProtocol, WriteResult, EditResult\nfrom deepagents.backends.utils import FileInfo, GrepMatch\n\nclass S3Backend(BackendProtocol):\n    def __init__(self, bucket: str, prefix: str = \"\"):\n        self.bucket = bucket\n        self.prefix = prefix.rstrip(\"/\")\n\n    def _key(self, path: str) -> str:\n        return f\"{self.prefix}{path}\"\n\n    def ls_info(self, path: str) -> list[FileInfo]:\n        # List objects under _key(path); build FileInfo entries (path, size, modified_at)\n        ...\n\n    def read(self, file_path: str, offset: int = 0, limit: int = 2000) -> str:\n        # Fetch object; return numbered content or an error string\n        ...\n\n    def grep_raw(self, pattern: str, path: str | None = None, glob: str | None = None) -> list[GrepMatch] | str:\n        # Optionally filter server‑side; else list and scan content\n        ...\n\n    def glob_info(self, pattern: str, path: str = \"/\") -> list[FileInfo]:\n        # Apply glob relative to path across keys\n        ...\n\n    def write(self, file_path: str, content: str) -> WriteResult:\n        # Enforce create‑only semantics; return WriteResult(path=file_path, files_update=None)\n        ...\n\n    def edit(self, file_path: str, old_string: str, new_string: str, replace_all: bool = False) -> EditResult:\n        # Read → replace (respect uniqueness vs replace_all) → write → return occurrences\n        ...\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Azure OpenAI",
        "type": "code",
        "content": "from langchain_openai import AzureOpenAIEmbeddings\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Azure Blob Storage",
        "type": "text",
        "content": "Azure Blob Storage is Microsoft’s object storage solution for the cloud. Blob Storage is optimized for storing massive amounts of unstructured data. Unstructured data is data that doesn’t adhere to a particular data model or definition, such as text or binary data.\n\nAzure Blob Storage is designed for:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "LangGraph v1 migration guide",
        "type": "code",
        "content": "pip install -U langgraph langchain-core\n",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langgraph-v1",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Batch",
        "type": "text",
        "content": "When processing a large number of inputs using batch() or batch_as_completed() , you may want to control the maximum number of parallel calls. This can be done by setting the max_concurrency attribute in the RunnableConfig dictionary.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "PII detection",
        "type": "text",
        "content": "Custom detector function or regex pattern. If not provided, uses built-in detector for the PII type.\n\nCheck user messages before model call\n\nCheck AI messages after model call\n\nCheck tool result messages after execution",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Token usage",
        "type": "code",
        "content": "from langchain.chat_models import init_chat_model\nfrom langchain_core.callbacks import UsageMetadataCallbackHandler\n\nmodel_1 = init_chat_model(model=\"gpt-4o-mini\")\nmodel_2 = init_chat_model(model=\"claude-haiku-4-5-20251001\")\n\ncallback = UsageMetadataCallbackHandler()\nresult_1 = model_1.invoke(\"Hello\", config={\"callbacks\": [callback]})\nresult_2 = model_2.invoke(\"Hello\", config={\"callbacks\": [callback]})\ncallback.usage_metadata\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Subagent middleware",
        "type": "code",
        "content": "from langchain_core.tools import tool\nfrom langchain.agents import create_agent\nfrom deepagents.middleware.subagents import SubAgentMiddleware\n\n\n@tool\ndef get_weather(city: str) -> str:\n    \"\"\"Get the weather in a city.\"\"\"\n    return f\"The weather in {city} is sunny.\"\n\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    middleware=[\n        SubAgentMiddleware(\n            default_model=\"claude-sonnet-4-5-20250929\",\n            default_tools=[],\n            subagents=[\n                {\n                    \"name\": \"weather\",\n                    \"description\": \"This subagent can get weather in cities.\",\n                    \"system_prompt\": \"Use the get_weather tool to get the weather in a city.\",\n                    \"tools\": [get_weather],\n                    \"model\": \"gpt-4.1\",\n                    \"middleware\": [],\n                }\n            ],\n        )\n    ],\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/middleware",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Routing",
        "type": "text",
        "content": "Routing workflows process inputs and then directs them to context-specific tasks. This allows you to define specialized flows for complex tasks. For example, a workflow built to answer product related questions might process the type of question first, and then route the request to specific processes for pricing, refunds, returns, etc.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/workflows-agents",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Workflows + agents"
    },
    {
        "title": "Post-model hook",
        "type": "text",
        "content": "Post-model hooks are now implemented as middleware with the after_model method.\nThis new pattern is more extensible—you can define multiple middlewares to run after the model is called,\nreusing common patterns across different agents.",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Configurable models",
        "type": "code",
        "content": "with_structured_output",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "AlloyDB for PostgreSQL",
        "type": "text",
        "content": "Google Cloud AlloyDB is a fully managed PostgreSQL-compatible database service.\n\nInstall the python package:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Recording & Replaying HTTP Calls",
        "type": "text",
        "content": "Then configure your project to recognise the vcr marker:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "Execution order",
        "type": "code",
        "content": "middleware1.wrap_model_call()",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "PlayWright Browser Toolkit",
        "type": "code",
        "content": "pip install playwright lxml\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "import getpass\nimport os\n\nif not os.environ.get(\"WATSONX_APIKEY\"):\n  os.environ[\"WATSONX_APIKEY\"] = getpass.getpass(\"Enter API key for IBM watsonx: \")\n\nfrom langchain_ibm import WatsonxEmbeddings\n\nembeddings = WatsonxEmbeddings(\n    model_id=\"ibm/slate-125m-english-rtrvr\",\n    url=\"https://us-south.ml.cloud.ibm.com\",\n    project_id=\"<WATSONX PROJECT_ID>\",\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Add metadata to traces",
        "type": "code",
        "content": "response = agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"Send a welcome email\"}]},\n    config={\n        \"tags\": [\"production\", \"email-assistant\", \"v1.0\"],\n        \"metadata\": {\n            \"user_id\": \"user_123\",\n            \"session_id\": \"session_456\",\n            \"environment\": \"production\"\n        }\n    }\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/observability",
        "head_menu_name": "LangChain",
        "side_menu_name": "Observability"
    },
    {
        "title": "Features",
        "type": "text",
        "content": "Studio automatically renders tool calls and results in an intuitive interface.\n\nNavigate through conversation history and fork from any point\n\nView and modify agent state at any point during execution\n\nBuilt-in support for reviewing and responding to agent requests\n\nYou can use generative UI in the Agent Chat UI. For more information, see Implement generative user interfaces with LangGraph .",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/ui",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Agent Chat UI"
    },
    {
        "title": "Agent jumps",
        "type": "code",
        "content": "@hook_config(can_jump_to=[...])",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Configurable models",
        "type": "code",
        "content": "from pydantic import BaseModel, Field\n\n\nclass GetWeather(BaseModel):\n    \"\"\"Get the current weather in a given location\"\"\"\n\n        location: str = Field(..., description=\"The city and state, e.g. San Francisco, CA\")\n\n\nclass GetPopulation(BaseModel):\n    \"\"\"Get the current population in a given location\"\"\"\n\n        location: str = Field(..., description=\"The city and state, e.g. San Francisco, CA\")\n\n\nmodel = init_chat_model(temperature=0)\nmodel_with_tools = model.bind_tools([GetWeather, GetPopulation])\n\nmodel_with_tools.invoke(\n    \"what's bigger in 2024 LA or NYC\", config={\"configurable\": {\"model\": \"gpt-4.1-mini\"}}\n).tool_calls\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Advanced considerations",
        "type": "text",
        "content": "This section explores the trade-offs in node granularity design. Most applications can skip this and use the patterns shown above.\n\nYou might wonder: why not combine Read Email and Classify Intent into one node?",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Azure Cosmos DB",
        "type": "text",
        "content": "AI agents can rely on Azure Cosmos DB as a unified memory system solution, enjoying speed, scale, and simplicity. This service successfully enabled OpenAI’s ChatGPT service to scale dynamically with high reliability and low maintenance. Powered by an atom-record-sequence engine, it is the world’s first globally distributed NoSQL , relational , and vector database service that offers a serverless mode.\n\nBelow are two available Azure Cosmos DB APIs that can provide vector store functionalities.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Error handling strategies",
        "type": "text",
        "content": "If handle_errors is a tuple of exceptions, the agent will only retry (using the default error message) if the exception raised is one of the specified types. In all other cases, the exception will be raised.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Response Format",
        "type": "text",
        "content": "When a schema type is provided directly, LangChain automatically chooses:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Overview",
        "type": "text",
        "content": "LangGraph exposes a Runtime object with the following information:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/runtime",
        "head_menu_name": "LangChain",
        "side_menu_name": "Runtime"
    },
    {
        "title": "6. Build and compile the agent",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/quickstart",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Add persistence",
        "type": "code",
        "content": "subgraph_builder = StateGraph(...)\nsubgraph = subgraph_builder.compile(checkpointer=True)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/use-subgraphs",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Subgraphs"
    },
    {
        "title": "Static runtime context",
        "type": "code",
        "content": "@dataclass\nclass ContextSchema:\n    user_name: str\n\ngraph.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"hi!\"}]},\n    context={\"user_name\": \"John Smith\"}  \n)\n",
        "side_link": "https://docs.langchain.com/oss/python/concepts/context",
        "head_menu_name": "Learn",
        "side_menu_name": "Context"
    },
    {
        "title": "View thread state",
        "type": "code",
        "content": "config = {\n    \"configurable\": {\n        \"thread_id\": \"1\",  \n        # optionally provide an ID for a specific checkpoint,\n        # otherwise the latest checkpoint is shown\n        # \"checkpoint_id\": \"1f029ca3-1f5b-6704-8004-820c16b69a5a\"  #\n\n    }\n}\ngraph.get_state(config)  \n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Step 5: Run the agent",
        "type": "code",
        "content": "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What is langgraph?\"}]})\n\n# Print the agent's response\nprint(result[\"messages\"][-1].content)\n",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/quickstart",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Trajectory Match Evaluator",
        "type": "text",
        "content": "The superset and subset modes match partial trajectories. The superset mode verifies that the agent called at least the tools in the reference trajectory, allowing additional tool calls. The subset mode ensures the agent did not call any tools beyond those in the reference.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/test",
        "head_menu_name": "LangChain",
        "side_menu_name": "Test"
    },
    {
        "title": "SageMaker Endpoint",
        "type": "text",
        "content": "Amazon SageMaker is a system that can build, train, and deploy\nmachine learning (ML) models with fully managed infrastructure, tools, and workflows.\n\nWe use SageMaker to host our model and expose it as the SageMaker Endpoint .",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Use MCP tools",
        "type": "text",
        "content": "MultiServerMCPClient is stateless by default . Each tool invocation creates a fresh MCP ClientSession , executes the tool, and then cleans up.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/mcp",
        "head_menu_name": "LangChain",
        "side_menu_name": "Model Context Protocol (MCP)"
    },
    {
        "title": "Text-to-Speech",
        "type": "text",
        "content": "Google Cloud Text-to-Speech is a Google Cloud service that enables developers to\nsynthesize natural-sounding speech with 100+ voices, available in multiple languages and variants.\nIt applies DeepMind’s groundbreaking research in WaveNet and Google’s powerful neural networks\nto deliver the highest fidelity possible.\n\nInstall required packages:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Example",
        "type": "code",
        "content": "task(name=\"general-purpose\", task=\"Research quantum computing trends\")",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/subagents",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Subagents"
    },
    {
        "title": "Response Format",
        "type": "text",
        "content": "Structured output transforms unstructured text into validated, structured data. When extracting specific fields or returning data for downstream systems, free-form text isn’t sufficient.\n\nHow it works: When you provide a schema as the response format, the model’s final response is guaranteed to conform to that schema. The agent runs the model / tool calling loop until the model is done calling tools, then the final response is coerced into the provided format.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "ToolRuntime",
        "type": "text",
        "content": "The tool_runtime parameter is hidden from the model. For the example above, the model only sees pref_name in the tool schema - tool_runtime is not included in the request.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "Azure AI Data",
        "type": "code",
        "content": "from langchain.document_loaders import AzureAIDataLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Microsoft OneDrive File",
        "type": "code",
        "content": "from langchain_community.document_loaders import OneDriveFileLoader\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/microsoft",
        "head_menu_name": "Integrations",
        "side_menu_name": "Microsoft"
    },
    {
        "title": "Self-improving instructions",
        "type": "text",
        "content": "Over time, the instructions file accumulates user preferences, helping the agent improve.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/long-term-memory",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Long-term memory"
    },
    {
        "title": "Backwards compatibility",
        "type": "text",
        "content": "Maintain stable public interfaces and avoid breaking changes",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Multimodal",
        "type": "text",
        "content": "Not all models support all file types. Check the model provider’s reference for supported formats and size limits.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Content block reference",
        "type": "text",
        "content": "Name of the tool that failed to be called\n\nArguments to pass to the tool\n\nDescription of what went wrong\n\nPurpose: Tool call that is executed server-side.\n\nAlways \"server_tool_call\"",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Batch",
        "type": "text",
        "content": "This section describes a chat model method batch() , which parallelizes model calls client-side.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Security guidelines",
        "type": "text",
        "content": "Security is paramount. Never introduce vulnerabilities or unsafe patterns.\n\nSecurity checklist:",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "Tool and provider strategies",
        "type": "text",
        "content": "In v1, there are two new structured output strategies:",
        "side_link": "https://docs.langchain.com/oss/python/migrate/langchain-v1",
        "head_menu_name": "LangChain",
        "side_menu_name": "Migration guide"
    },
    {
        "title": "Amazon Comprehend Moderation Chain",
        "type": "text",
        "content": "Edit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Deploy DocumentDB on AWS",
        "type": "code",
        "content": "from langchain_community.vectorstores import DocumentDBVectorSearch\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/aws",
        "head_menu_name": "Integrations",
        "side_menu_name": "AWS (Amazon)"
    },
    {
        "title": "Manual formatting and linting",
        "type": "text",
        "content": "Both commands will show you any formatting or linting issues that need to be addressed before committing.",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "2. Prepare your agent",
        "type": "code",
        "content": "from langchain.agents import create_agent\n\ndef send_email(to: str, subject: str, body: str):\n    \"\"\"Send an email\"\"\"\n    email = {\n        \"to\": to,\n        \"subject\": subject,\n        \"body\": body\n    }\n    # ... email sending logic\n\n    return f\"Email sent to {to}\"\n\nagent = create_agent(\n    \"gpt-4o\",\n    tools=[send_email],\n    system_prompt=\"You are an email assistant. Always use the send_email tool.\",\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/studio",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Studio"
    },
    {
        "title": "Agent progress",
        "type": "code",
        "content": "from langchain.agents import create_agent\n\n\ndef get_weather(city: str) -> str:\n    \"\"\"Get weather for a given city.\"\"\"\n\n    return f\"It's always sunny in {city}!\"\n\nagent = create_agent(\n    model=\"gpt-5-nano\",\n    tools=[get_weather],\n)\nfor chunk in agent.stream(  \n    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n    stream_mode=\"updates\",\n):\n    for step, data in chunk.items():\n        print(f\"step: {step}\")\n        print(f\"content: {data['messages'][-1].content_blocks}\")\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/streaming",
        "head_menu_name": "LangChain",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Productivity",
        "type": "text",
        "content": "The following table shows tools that can be used to automate tasks in productivity tools:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/tools",
        "head_menu_name": "Integrations",
        "side_menu_name": "Tools and toolkits"
    },
    {
        "title": "Step 4: Build your nodes",
        "type": "text",
        "content": "Now we implement each step as a function. A node in LangGraph is just a Python function that takes the current state and returns updates to it.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Thinking in LangGraph"
    },
    {
        "title": "Message content",
        "type": "code",
        "content": "from langchain.messages import HumanMessage\n\n# String content\nhuman_message = HumanMessage(\"Hello, how are you?\")\n\n# Provider-native format (e.g., OpenAI)\nhuman_message = HumanMessage(content=[\n    {\"type\": \"text\", \"text\": \"Hello, how are you?\"},\n    {\"type\": \"image_url\", \"image_url\": {\"url\": \"https://example.com/image.jpg\"}}\n])\n\n# List of standard content blocks\nhuman_message = HumanMessage(content_blocks=[\n    {\"type\": \"text\", \"text\": \"Hello, how are you?\"},\n    {\"type\": \"image\", \"url\": \"https://example.com/image.jpg\"},\n])\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/messages",
        "head_menu_name": "LangChain",
        "side_menu_name": "Messages"
    },
    {
        "title": "Do not wrapinterruptcalls in try/except",
        "type": "code",
        "content": "def node_a(state: State):\n    # ❌ Bad: wrapping interrupt in bare try/except\n    # will catch the interrupt exception\n    try:\n        interrupt(\"What's your name?\")\n    except Exception as e:\n        print(e)\n    return state\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "High-level API",
        "type": "code",
        "content": "print(graph.channels)\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/pregel",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Runtime"
    },
    {
        "title": "Using LangGraph Studio",
        "type": "text",
        "content": "You can use LangGraph Studio to set static interrupts in your graph in the UI before running the graph. You can also use the UI to inspect the graph state at any point in the execution.\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "OllamaEmbeddings",
        "type": "text",
        "content": "Ollama embedding models.\n\nEdit the source of this page on GitHub.\n\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/ollama",
        "head_menu_name": "Integrations",
        "side_menu_name": "Ollama"
    },
    {
        "title": "Quick start",
        "type": "text",
        "content": "The fastest way to get started is using the hosted version:",
        "side_link": "https://docs.langchain.com/oss/python/langchain/ui",
        "head_menu_name": "LangChain",
        "side_menu_name": "Agent Chat UI"
    },
    {
        "title": "Featured providers",
        "type": "code",
        "content": "langchain-nvidia-ai-endpoints",
        "side_link": "https://docs.langchain.com/oss/python/integrations/chat",
        "head_menu_name": "Integrations",
        "side_menu_name": "Chat models"
    },
    {
        "title": "Use semantic search",
        "type": "code",
        "content": "\nfrom langchain.embeddings import init_embeddings\nfrom langchain.chat_models import init_chat_model\nfrom langgraph.store.base import BaseStore\nfrom langgraph.store.memory import InMemoryStore\nfrom langgraph.graph import START, MessagesState, StateGraph\n\nmodel = init_chat_model(\"gpt-4o-mini\")\n\n# Create store with semantic search enabled\nembeddings = init_embeddings(\"openai:text-embedding-3-small\")\nstore = InMemoryStore(\n    index={\n        \"embed\": embeddings,\n        \"dims\": 1536,\n    }\n)\n\nstore.put((\"user_123\", \"memories\"), \"1\", {\"text\": \"I love pizza\"})\nstore.put((\"user_123\", \"memories\"), \"2\", {\"text\": \"I am a plumber\"})\n\ndef chat(state, *, store: BaseStore):\n    # Search based on user's last message\n    items = store.search(\n        (\"user_123\", \"memories\"), query=state[\"messages\"][-1].content, limit=2\n    )\n    memories = \"\\n\".join(item.value[\"text\"] for item in items)\n    memories = f\"## Memories of user\\n{memories}\" if memories else \"\"\n    response = model.invoke(\n        [\n            {\"role\": \"system\", \"content\": f\"You are a helpful assistant.\\n{memories}\"},\n            *state[\"messages\"],\n        ]\n    )\n    return {\"messages\": [response]}\n\n\nbuilder = StateGraph(MessagesState)\nbuilder.add_node(chat)\nbuilder.add_edge(START, \"chat\")\ngraph = builder.compile(store=store)\n\nfor message, metadata in graph.stream(\n    input={\"messages\": [{\"role\": \"user\", \"content\": \"I'm hungry\"}]},\n    stream_mode=\"messages\",\n):\n    print(message.content, end=\"\")\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/add-memory",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Memory"
    },
    {
        "title": "Static runtime context",
        "type": "text",
        "content": "Static runtime context represents immutable data like user metadata, tools, and database connections that are passed to an application at the start of a run via the context argument to invoke / stream . This data does not change during execution.",
        "side_link": "https://docs.langchain.com/oss/python/concepts/context",
        "head_menu_name": "Learn",
        "side_menu_name": "Context"
    },
    {
        "title": "Create an agent",
        "type": "code",
        "content": "# pip install -qU \"langchain[anthropic]\" to call the model\n\nfrom langchain.agents import create_agent\n\ndef get_weather(city: str) -> str:\n    \"\"\"Get weather for a given city.\"\"\"\n    return f\"It's always sunny in {city}!\"\n\nagent = create_agent(\n    model=\"claude-sonnet-4-5-20250929\",\n    tools=[get_weather],\n    system_prompt=\"You are a helpful assistant\",\n)\n\n# Run the agent\nagent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/overview",
        "head_menu_name": "LangChain",
        "side_menu_name": "Overview"
    },
    {
        "title": "6. Build and compile the agent",
        "type": "text",
        "content": "The agent is built using the StateGraph class and compiled using the compile method.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/quickstart",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "Structured output",
        "type": "code",
        "content": "def create_agent(\n    ...\n    response_format: Union[\n        ToolStrategy[StructuredResponseT],\n        ProviderStrategy[StructuredResponseT],\n        type[StructuredResponseT],\n    ]\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/structured-output",
        "head_menu_name": "LangChain",
        "side_menu_name": "Structured output"
    },
    {
        "title": "Code quality standards",
        "type": "code",
        "content": "def process_documents(\n    docs: list[Document],\n    processor: DocumentProcessor,\n    *,\n    batch_size: int = 100\n) -> ProcessingResult:\n    \"\"\"Process documents in batches.\n\n    Args:\n        docs: List of documents to process.\n        processor: Document processing instance.\n        batch_size: Number of documents per batch.\n\n    Returns:\n        Processing results with success/failure counts.\n    \"\"\"\n",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "When to use deep agents",
        "type": "text",
        "content": "Use deep agents when you need agents that can:\n\nFor simpler use cases, consider using LangChain’s create_agent or building a custom LangGraph workflow.",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/overview",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Overview"
    },
    {
        "title": "Install LangGraph",
        "type": "code",
        "content": "pip install -U langchain\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/install",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Install"
    },
    {
        "title": "Document AI",
        "type": "code",
        "content": "from langchain_core.document_loaders.blob_loaders import Blob\nfrom langchain_google_community import DocAIParser\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Model fallback",
        "type": "code",
        "content": "from langchain.agents import create_agent\nfrom langchain.agents.middleware import ModelFallbackMiddleware\n\n\nagent = create_agent(\n    model=\"gpt-4o\",  # Primary model\n    tools=[...],\n    middleware=[\n        ModelFallbackMiddleware(\n            \"gpt-4o-mini\",  # Try first on error\n            \"claude-3-5-sonnet-20241022\",  # Then this\n        ),\n    ],\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/middleware",
        "head_menu_name": "LangChain",
        "side_menu_name": "Middleware"
    },
    {
        "title": "Parallelization",
        "type": "code",
        "content": "# Graph state\nclass State(TypedDict):\n    topic: str\n    joke: str\n    story: str\n    poem: str\n    combined_output: str\n\n\n# Nodes\ndef call_llm_1(state: State):\n    \"\"\"First LLM call to generate initial joke\"\"\"\n\n    msg = llm.invoke(f\"Write a joke about {state['topic']}\")\n    return {\"joke\": msg.content}\n\n\ndef call_llm_2(state: State):\n    \"\"\"Second LLM call to generate story\"\"\"\n\n    msg = llm.invoke(f\"Write a story about {state['topic']}\")\n    return {\"story\": msg.content}\n\n\ndef call_llm_3(state: State):\n    \"\"\"Third LLM call to generate poem\"\"\"\n\n    msg = llm.invoke(f\"Write a poem about {state['topic']}\")\n    return {\"poem\": msg.content}\n\n\ndef aggregator(state: State):\n    \"\"\"Combine the joke and story into a single output\"\"\"\n\n    combined = f\"Here's a story, joke, and poem about {state['topic']}!\\n\\n\"\n    combined += f\"STORY:\\n{state['story']}\\n\\n\"\n    combined += f\"JOKE:\\n{state['joke']}\\n\\n\"\n    combined += f\"POEM:\\n{state['poem']}\"\n    return {\"combined_output\": combined}\n\n\n# Build workflow\nparallel_builder = StateGraph(State)\n\n# Add nodes\nparallel_builder.add_node(\"call_llm_1\", call_llm_1)\nparallel_builder.add_node(\"call_llm_2\", call_llm_2)\nparallel_builder.add_node(\"call_llm_3\", call_llm_3)\nparallel_builder.add_node(\"aggregator\", aggregator)\n\n# Add edges to connect nodes\nparallel_builder.add_edge(START, \"call_llm_1\")\nparallel_builder.add_edge(START, \"call_llm_2\")\nparallel_builder.add_edge(START, \"call_llm_3\")\nparallel_builder.add_edge(\"call_llm_1\", \"aggregator\")\nparallel_builder.add_edge(\"call_llm_2\", \"aggregator\")\nparallel_builder.add_edge(\"call_llm_3\", \"aggregator\")\nparallel_builder.add_edge(\"aggregator\", END)\nparallel_workflow = parallel_builder.compile()\n\n# Show workflow\ndisplay(Image(parallel_workflow.get_graph().draw_mermaid_png()))\n\n# Invoke\nstate = parallel_workflow.invoke({\"topic\": \"cats\"})\nprint(state[\"combined_output\"])\n",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/workflows-agents",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Workflows + agents"
    },
    {
        "title": "Memory (Store)",
        "type": "code",
        "content": "from typing import Any\nfrom langgraph.store.memory import InMemoryStore\nfrom langchain.agents import create_agent\nfrom langchain.tools import tool, ToolRuntime\n\n\n# Access memory\n@tool\ndef get_user_info(user_id: str, runtime: ToolRuntime) -> str:\n    \"\"\"Look up user info.\"\"\"\n    store = runtime.store\n    user_info = store.get((\"users\",), user_id)\n    return str(user_info.value) if user_info else \"Unknown user\"\n\n# Update memory\n@tool\ndef save_user_info(user_id: str, user_info: dict[str, Any], runtime: ToolRuntime) -> str:\n    \"\"\"Save user info.\"\"\"\n    store = runtime.store\n    store.put((\"users\",), user_id, user_info)\n    return \"Successfully saved user info.\"\n\nstore = InMemoryStore()\nagent = create_agent(\n    model,\n    tools=[get_user_info, save_user_info],\n    store=store\n)\n\n# First session: save user info\nagent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"Save the following user: userid: abc123, name: Foo, age: 25, email: foo@langchain.dev\"}]\n})\n\n# Second session: get user info\nagent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"Get user info for user with id 'abc123'\"}]\n})\n# Here is the user info for user with ID \"abc123\":\n# - Name: Foo\n# - Age: 25\n# - Email: foo@langchain.dev\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/tools",
        "head_menu_name": "LangChain",
        "side_menu_name": "Tools"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "import getpass\nimport os\n\nif not os.environ.get(\"MISTRALAI_API_KEY\"):\n  os.environ[\"MISTRALAI_API_KEY\"] = getpass.getpass(\"Enter API key for MistralAI: \")\n\nfrom langchain_mistralai import MistralAIEmbeddings\n\nembeddings = MistralAIEmbeddings(model=\"mistral-embed\")\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    },
    {
        "title": "Google Cloud",
        "type": "code",
        "content": "gcloud auth application-default login",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Stream custom data",
        "type": "code",
        "content": "[\"updates\", \"custom\"]",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Interrupts in tools",
        "type": "text",
        "content": "You can also place interrupts directly inside tool functions. This makes the tool itself pause for approval whenever it’s called, and allows for human review and editing of the tool call before it is executed.\n\nFirst, define a tool that uses interrupt :",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/interrupts",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Interrupts"
    },
    {
        "title": "Supported stream modes",
        "type": "text",
        "content": "Pass one or more of the following stream modes as a list to the stream or astream methods:",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Stream subgraph outputs",
        "type": "text",
        "content": "Note that we are receiving not just the node updates, but we also the namespaces which tell us what graph (or subgraph) we are streaming from.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Build a real-world agent",
        "type": "code",
        "content": "from dataclasses import dataclass\n\n# We use a dataclass here, but Pydantic models are also supported.\n@dataclass\nclass ResponseFormat:\n    \"\"\"Response schema for the agent.\"\"\"\n    # A punny response (always required)\n    punny_response: str\n    # Any interesting information about the weather if available\n    weather_conditions: str | None = None\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/quickstart",
        "head_menu_name": "LangChain",
        "side_menu_name": "Quickstart"
    },
    {
        "title": "BigQuery",
        "type": "text",
        "content": "Google Cloud BigQuery is a serverless data warehouse.\n\nInstall with BigQuery dependencies:",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Base URL or proxy",
        "type": "code",
        "content": "from langchain_openai import ChatOpenAI\n\nmodel = ChatOpenAI(\n    model=\"gpt-4o\",\n    openai_proxy=\"http://proxy.example.com:8080\"\n)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Subagent interrupts",
        "type": "text",
        "content": "When a subagent triggers an interrupt, the handling is the same – check for __interrupt__ and resume with Command .",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/human-in-the-loop",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Human-in-the-loop"
    },
    {
        "title": "External index",
        "type": "code",
        "content": "TavilySearchAPIRetriever",
        "side_link": "https://docs.langchain.com/oss/python/integrations/retrievers",
        "head_menu_name": "Integrations",
        "side_menu_name": "Retrievers"
    },
    {
        "title": "Running tests locally",
        "type": "code",
        "content": "make format\nmake lint\n",
        "side_link": "https://docs.langchain.com/oss/python/contributing/code",
        "head_menu_name": "Contribute",
        "side_menu_name": "Code"
    },
    {
        "title": "History",
        "type": "text",
        "content": "LangChain releases 1.0 with two major changes:\n\nComplete revamp of all chains and agents in langchain . All chains and agents are now replaced with only one high level abstraction: an agent abstraction built on top of LangGraph. This was the high-level abstraction that was originally created in LangGraph, but just moved to LangChain.",
        "side_link": "https://docs.langchain.com/oss/python/langchain/philosophy",
        "head_menu_name": "LangChain",
        "side_menu_name": "Philosophy"
    },
    {
        "title": "Protocol reference",
        "type": "code",
        "content": "write(file_path: str, content: str) -> WriteResult",
        "side_link": "https://docs.langchain.com/oss/python/deepagents/backends",
        "head_menu_name": "Deep Agents",
        "side_menu_name": "Backends"
    },
    {
        "title": "Messaging Services",
        "type": "text",
        "content": "The below document loaders allow you to load data from different messaging platforms.",
        "side_link": "https://docs.langchain.com/oss/python/integrations/document_loaders",
        "head_menu_name": "Integrations",
        "side_menu_name": "Document loaders"
    },
    {
        "title": "Defining formats",
        "type": "code",
        "content": "from pydantic import BaseModel, Field\n\nclass CustomerSupportTicket(BaseModel):\n    \"\"\"Structured ticket information extracted from customer message.\"\"\"\n\n    category: str = Field(\n        description=\"Issue category: 'billing', 'technical', 'account', or 'product'\"\n    )\n    priority: str = Field(\n        description=\"Urgency level: 'low', 'medium', 'high', or 'critical'\"\n    )\n    summary: str = Field(\n        description=\"One-sentence summary of the customer's issue\"\n    )\n    customer_sentiment: str = Field(\n        description=\"Customer's emotional tone: 'frustrated', 'neutral', or 'satisfied'\"\n    )\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/context-engineering",
        "head_menu_name": "LangChain",
        "side_menu_name": "Context engineering"
    },
    {
        "title": "LLM tokens",
        "type": "text",
        "content": "Manual config required for async in Python < 3.11 When using Python < 3.11 with async code, you must explicitly pass RunnableConfig to ainvoke() to enable proper streaming. See Async with Python < 3.11 for details or upgrade to Python 3.11+.",
        "side_link": "https://docs.langchain.com/oss/python/langgraph/streaming",
        "head_menu_name": "LangGraph",
        "side_menu_name": "Streaming"
    },
    {
        "title": "Long-term memory",
        "type": "text",
        "content": "Long-term memory in LangGraph allows systems to retain information across different conversations or sessions. Unlike short-term memory, which is thread-scoped , long-term memory is saved within custom “namespaces.”\n\nLong-term memory is a complex challenge without a one-size-fits-all solution. However, the following questions provide a framework to help you navigate the different techniques:\n\nDifferent applications require various types of memory. Although the analogy isn’t perfect, examining human memory types can be insightful. Some research (e.g., the CoALA paper ) have even mapped these human memory types to those used in AI agents.",
        "side_link": "https://docs.langchain.com/oss/python/concepts/memory",
        "head_menu_name": "Learn",
        "side_menu_name": "Memory"
    },
    {
        "title": "Vertex AI image captioning",
        "type": "code",
        "content": "from langchain_google_vertexai.vision_models import VertexAIImageCaptioningChat\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/providers/google",
        "head_menu_name": "Integrations",
        "side_menu_name": "Google"
    },
    {
        "title": "Tool calling",
        "type": "code",
        "content": "model.bind_tools([get_weather], parallel_tool_calls=False)\n",
        "side_link": "https://docs.langchain.com/oss/python/langchain/models",
        "head_menu_name": "LangChain",
        "side_menu_name": "Models"
    },
    {
        "title": "Top integrations",
        "type": "code",
        "content": "pip install -qU \"langchain[langchain-xai]\"\n",
        "side_link": "https://docs.langchain.com/oss/python/integrations/vectorstores",
        "head_menu_name": "Integrations",
        "side_menu_name": "Vector stores"
    }
]