{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc40670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.embeddings import HuggingFaceEmbeddings\n",
    "#from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "#from langchain.vectorstores import FAISS\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "#from langchain.schema import Document\n",
    "from langchain_core.documents import Document  # ✅ 최신 위치\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a60fd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"langchain_docs.json\", \"r\", encoding = \"utf-8\") as f:\n",
    "    loaded_docs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9da3be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ✅ loaded_docs 리스트에 dict 데이터가 여러개 있을 때 Document 객체로 변환\n",
    "docs = []\n",
    "for doc_data in loaded_docs:\n",
    "    doc = Document(\n",
    "        page_content=doc_data[\"content\"],\n",
    "        metadata={\n",
    "            \"title\": doc_data[\"title\"],\n",
    "            \"type\": doc_data[\"type\"]\n",
    "        }\n",
    "    )\n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e4619ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'LangChain overview', 'type': 'text'}, page_content='LangChain v1.0 is now available! For a complete list of changes and instructions on how to upgrade your code, see the release notes and migration guide. If you encounter any issues or have feedback, please open an issue so we can improve. To view v0.x documentation, go to the archived content.LangChain is the easiest way to start building agents and applications powered by LLMs. With under 10 lines of code, you can connect to OpenAI, Anthropic, Google, and more. LangChain provides a pre-built agent architecture and model integrations to help you get started quickly and seamlessly incorporate LLMs into your agents and applications.We recommend you use LangChain if you want to quickly build agents and autonomous applications. Use LangGraph, our low-level agent orchestration framework and runtime, when you have more advanced needs that require a combination of deterministic and agentic workflows, heavy customization, and carefully controlled latency.LangChain agents are built on top of LangGraph in order to provide durable execution, streaming, human-in-the-loop, persistence, and more. You do not need to know LangGraph for basic LangChain agent usage.'),\n",
       " Document(metadata={'title': 'Install', 'type': 'code'}, page_content='pip install -U langchain'),\n",
       " Document(metadata={'title': 'Create an agent', 'type': 'code'}, page_content='# pip install -qU \"langchain[anthropic]\" to call the model\\n\\nfrom langchain.agents import create_agent\\n\\ndef get_weather(city: str) -> str:\\n    \"\"\"Get weather for a given city.\"\"\"\\n    return f\"It\\'s always sunny in {city}!\"\\n\\nagent = create_agent(\\n    model=\"anthropic:claude-sonnet-4-5\",\\n    tools=[get_weather],\\n    system_prompt=\"You are a helpful assistant\",\\n)\\n\\n# Run the agent\\nagent.invoke(\\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\\n)'),\n",
       " Document(metadata={'title': 'Easy to use, highly flexible agent', 'type': 'text'}, page_content='LangChain’s agent abstraction is designed to be easy to get started with, letting you build a simple agent in under 10 lines of code. But it also provides enough flexibility to allow you to do all the context engineering your heart desires.'),\n",
       " Document(metadata={'title': 'Standard model interface', 'type': 'text'}, page_content='Different providers have unique APIs for interacting with models, including the format of responses. LangChain standardizes how you interact with models so that you can seamlessly swap providers and avoid lock-in.'),\n",
       " Document(metadata={'title': 'Built on top of LangGraph', 'type': 'text'}, page_content='LangChain’s agents are built on top of LangGraph. This allows us to take advantage of LangGraph’s durable execution, human-in-the-loop support, persistence, and more.'),\n",
       " Document(metadata={'title': 'Debug with LangSmith', 'type': 'text'}, page_content='Gain deep visibility into complex agent behavior with visualization tools that trace execution paths, capture state transitions, and provide detailed runtime metrics.'),\n",
       " Document(metadata={'title': \"What's new in v1\", 'type': 'text'}, page_content='LangChain v1 is a focused, production-ready foundation for building agents. We’ve streamlined the framework around three core improvements:'),\n",
       " Document(metadata={'title': 'create_agent', 'type': 'text'}, page_content='The new standard for building agents in LangChain, replacing '),\n",
       " Document(metadata={'title': 'Standard content blocks', 'type': 'text'}, page_content='A new property that provides unified access to modern LLM features across providers.'),\n",
       " Document(metadata={'title': 'Simplified namespace', 'type': 'text'}, page_content='The namespace has been streamlined to focus on essential building blocks for agents, with legacy functionality moved to langchain-classic')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f502dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1a13d7229a4fa9a074a253b733f9a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading .gitattributes: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325b491006bb4ed38e50e46ecf0d7da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581cf7e7990946528e644d669c266936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af4419dfe834b20a1f502b365f346c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/655 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31b93febbbf46d8941d930472f5262b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40370292bba74137a80731d6e20c1642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/653 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f215963ebdb4e4ebe158cf56a8e1b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.onnx:   0%|          | 0.00/470M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f22a424771447b9f6b35da1e029e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model_O4.onnx:   0%|          | 0.00/235M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb20fc4622b49e8b6af81706ce843a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nt8_avx512_vnni.onnx:   0%|          | 0.00/118M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d675b734129644a68c2297167048e74b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df5b0ea6593d4920bded4dfaf45d2114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f7434d0d059445baffd3fa7c1366b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8e4f80492c4f28a8302e4b34abe06e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c0f245136f4abba8b455c6624fc8e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading openvino_model.bin:   0%|          | 0.00/470M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd047561a19437fa50a9c427c3f170f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading openvino_model.xml: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2a8a68a38e43019bddb575316a21c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f622363200dc4c428148073d831bb72b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd21b3219c4c4b5892097ccbadeea59e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14869a7546d4abf831073253757df72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5aa503e4c144fdbfb22a56ec900204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01428ebf5213406cbff3a2b4061a23f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f3fdde6c1f4cedabfcc6cb2fda7ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ✅ 임베딩 모델 설정 (GPU 서버에서 실행 가능)\n",
    "#embedder = HuggingFaceEmbeddings(model_name=\"jhgan/ko-sbert-nli\")\n",
    "#embedder = HuggingFaceEmbeddings(model_name=\"jhgan/ko-sbert-nli\")\n",
    "\n",
    "embedder = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49159243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ FAISS 벡터 DB 생성\n",
    "db = FAISS.from_documents(docs, embedding=embedder)\n",
    "\n",
    "# ✅ 저장 (선택)\n",
    "db.save_local(\"faiss_langchain_db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77df2bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Retrieved Document 1 ---\n",
      "Title: LangChain overview\n",
      "Type: text\n",
      "Content: LangChain v1.0 is now available! For a complete list of changes and instructions on how to upgrade your code, see the release notes and migration guide. If you encounter any issues or have feedback, p...\n",
      "\n",
      "--- Retrieved Document 2 ---\n",
      "Title: Install\n",
      "Type: code\n",
      "Content: pip install -U langchain...\n",
      "\n",
      "--- Retrieved Document 3 ---\n",
      "Title: What's new in v1\n",
      "Type: text\n",
      "Content: LangChain v1 is a focused, production-ready foundation for building agents. We’ve streamlined the framework around three core improvements:...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is LangChain?\"\n",
    "retrieved_docs = db.similarity_search(query, k=3)\n",
    "\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"--- Retrieved Document {i+1} ---\")\n",
    "    print(f\"Title: {doc.metadata['title']}\")\n",
    "    print(f\"Type: {doc.metadata['type']}\")\n",
    "    print(f\"Content: {doc.page_content[:200]}...\")  # 앞부분 200자만 출력\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "019a52f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Retrieved Document 1 ---\n",
      "Title: LangChain overview\n",
      "Type: text\n",
      "Content: LangChain v1.0 is now available! For a complete list of changes and instructions on how to upgrade your code, see the release notes and migration guide. If you encounter any issues or have feedback, p...\n",
      "Score: 0.22953097522258759\n",
      "\n",
      "--- Retrieved Document 2 ---\n",
      "Title: Install\n",
      "Type: code\n",
      "Content: pip install -U langchain...\n",
      "Score: 0.23582054674625397\n",
      "\n",
      "--- Retrieved Document 3 ---\n",
      "Title: What's new in v1\n",
      "Type: text\n",
      "Content: LangChain v1 is a focused, production-ready foundation for building agents. We’ve streamlined the framework around three core improvements:...\n",
      "Score: 0.23655475676059723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is LangChain?\"\n",
    "retrieved_docs = db.similarity_search_with_score(query, k=3)\n",
    "\n",
    "for i, (doc, score) in enumerate(retrieved_docs, 1):\n",
    "    print(f\"--- Retrieved Document {i} ---\")\n",
    "    print(f\"Title: {doc.metadata['title']}\")\n",
    "    print(f\"Type: {doc.metadata['type']}\")\n",
    "    print(f\"Content: {doc.page_content[:200]}...\")  # 앞부분 200자만 출력\n",
    "    print(f\"Score: {score}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ebe7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
